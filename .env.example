# CLARISSA Environment Configuration
# Copy to .env and adjust as needed: cp .env.example .env
# 
# For local development with docker-compose, defaults work out of the box!

# ============== Environment ==============
ENVIRONMENT=local
LOG_LEVEL=DEBUG
DEBUG=true

# ============== LLM Configuration ==============
# Options: ollama (local, default), anthropic, openai
LLM_PROVIDER=ollama

# Ollama (local LLM - runs in Docker, no API key needed!)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# Anthropic Claude (uncomment to use cloud LLM)
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=sk-ant-api03-...
# ANTHROPIC_MODEL=claude-sonnet-4-20250514

# OpenAI (uncomment to use)
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o

# ============== Database ==============
# Firestore Emulator - leave set for local dev
# Clear/comment out FIRESTORE_EMULATOR_HOST to use real Firestore
FIRESTORE_EMULATOR_HOST=localhost:8080
FIRESTORE_PROJECT=myk8sproject-207017

# ============== Simulator ==============
OPM_FLOW_URL=http://localhost:5000
SIMULATION_TIMEOUT=3600

# ============== Vector Store ==============
QDRANT_HOST=http://localhost:6333
QDRANT_COLLECTION=clarissa_docs

# ============== GitLab (for CI/Admin) ==============
GITLAB_TOKEN=glpat-xxxxxxxxxxxxxxxxxxxx
GITLAB_PROJECT_ID=77260390

# ============== Google Cloud (for production) ==============
# GCP_PROJECT=myk8sproject-207017
# GCP_REGION=europe-west1
# GOOGLE_SERVICE_ACCOUNT_KEY=<base64 encoded JSON>

# ============== Docker (for OPM Flow permissions) ==============
LOCAL_UID=1000
LOCAL_GID=1000
