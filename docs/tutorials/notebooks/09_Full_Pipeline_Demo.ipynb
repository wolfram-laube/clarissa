{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLARISSA Tutorial 09: Full Pipeline Demo\n",
    "\n",
    "**Learning Objectives:**\n",
    "- See all CLARISSA components working together\n",
    "- Walk through a complete conversation-to-simulation flow\n",
    "- Understand the data flow between layers\n",
    "- Execute a real simulation with OPM Flow\n",
    "\n",
    "**Prerequisites:** Notebooks 01-08\n",
    "\n",
    "**Estimated Time:** 60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Overview\n",
    "\n",
    "```\n",
    "User Input \u2192 NL Parser \u2192 Intent/Entities \u2192 Knowledge Layer\n",
    "    \u2193                                           \u2193\n",
    "Conversation \u2190 LLM Layer \u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190 Constraint Engine\n",
    "    \u2193                                           \u2193\n",
    "Deck Generator \u2192 Validation \u2192 OPM Flow \u2192 Results\n",
    "    \u2191                                           \u2193\n",
    "    \u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190 RL Feedback \u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\u2190\n",
    "```\n",
    "\n",
    "This notebook demonstrates the complete flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from previous tutorials (simplified versions)\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import tempfile\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple, Any\n",
    "from enum import Enum, auto\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "print(\"CLARISSA Full Pipeline Demo\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Pipeline Components\n",
    "\n",
    "Bring together all the components from previous tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== From Tutorial 04: Conversation Layer ==========\n",
    "\n",
    "class UserIntent(Enum):\n",
    "    CREATE_MODEL = auto()\n",
    "    MODIFY_MODEL = auto()\n",
    "    ADD_WELL = auto()\n",
    "    RUN_SIMULATION = auto()\n",
    "    SHOW_RESULTS = auto()\n",
    "    EXPLAIN = auto()\n",
    "    UNKNOWN = auto()\n",
    "\n",
    "@dataclass\n",
    "class ExtractedEntities:\n",
    "    well_names: List[str] = field(default_factory=list)\n",
    "    coordinates: List[Tuple[int, int]] = field(default_factory=list)\n",
    "    rates: List[float] = field(default_factory=list)\n",
    "    pressures: List[float] = field(default_factory=list)\n",
    "    depths: List[float] = field(default_factory=list)\n",
    "    time_values: List[Tuple[float, str]] = field(default_factory=list)\n",
    "    porosity: Optional[float] = None\n",
    "    permeability: Optional[float] = None\n",
    "    grid_size: Optional[Tuple[int, int, int]] = None\n",
    "\n",
    "class NLParser:\n",
    "    \"\"\"Parse natural language to intent and entities.\"\"\"\n",
    "    \n",
    "    def parse(self, text: str) -> Tuple[UserIntent, ExtractedEntities]:\n",
    "        text_lower = text.lower()\n",
    "        entities = ExtractedEntities()\n",
    "        \n",
    "        # Intent classification\n",
    "        if any(w in text_lower for w in ['create', 'build', 'new model']):\n",
    "            intent = UserIntent.CREATE_MODEL\n",
    "        elif any(w in text_lower for w in ['add well', 'new well', 'producer', 'injector']):\n",
    "            intent = UserIntent.ADD_WELL\n",
    "        elif any(w in text_lower for w in ['run', 'simulate', 'execute']):\n",
    "            intent = UserIntent.RUN_SIMULATION\n",
    "        else:\n",
    "            intent = UserIntent.UNKNOWN\n",
    "        \n",
    "        # Entity extraction\n",
    "        # Grid size\n",
    "        grid_match = re.search(r'(\\d+)\\s*x\\s*(\\d+)\\s*x?\\s*(\\d+)?', text_lower)\n",
    "        if grid_match:\n",
    "            nx, ny = int(grid_match.group(1)), int(grid_match.group(2))\n",
    "            nz = int(grid_match.group(3)) if grid_match.group(3) else 1\n",
    "            entities.grid_size = (nx, ny, nz)\n",
    "        \n",
    "        # Porosity\n",
    "        poro_match = re.search(r'porosity[:\\s]+([\\d.]+)', text_lower)\n",
    "        if poro_match:\n",
    "            entities.porosity = float(poro_match.group(1))\n",
    "        \n",
    "        # Permeability\n",
    "        perm_match = re.search(r'permeability[:\\s]+([\\d.]+)', text_lower)\n",
    "        if perm_match:\n",
    "            entities.permeability = float(perm_match.group(1))\n",
    "        \n",
    "        # Depth\n",
    "        depth_match = re.search(r'(\\d+)\\s*(?:ft|feet)', text_lower)\n",
    "        if depth_match:\n",
    "            entities.depths.append(float(depth_match.group(1)))\n",
    "        \n",
    "        # Pressure\n",
    "        pressure_match = re.search(r'(\\d+)\\s*psi', text_lower)\n",
    "        if pressure_match:\n",
    "            entities.pressures.append(float(pressure_match.group(1)))\n",
    "        \n",
    "        return intent, entities\n",
    "\n",
    "print(\"NL Parser ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== From Tutorial 05: Constraint Engine ==========\n",
    "\n",
    "class ConstraintChecker:\n",
    "    \"\"\"Validate physics constraints.\"\"\"\n",
    "    \n",
    "    def check_all(self, params: Dict) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"Check all constraints, return (valid, issues).\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        # Porosity range\n",
    "        if 'porosity' in params:\n",
    "            if not (0 < params['porosity'] < 0.5):\n",
    "                issues.append(f\"Porosity {params['porosity']} out of range (0, 0.5)\")\n",
    "        \n",
    "        # Permeability positive\n",
    "        if 'permeability' in params:\n",
    "            if params['permeability'] <= 0:\n",
    "                issues.append(\"Permeability must be positive\")\n",
    "        \n",
    "        # Pressure gradient\n",
    "        if 'depth' in params and 'pressure' in params:\n",
    "            gradient = params['pressure'] / params['depth']\n",
    "            if not (0.35 <= gradient <= 0.55):\n",
    "                issues.append(f\"Pressure gradient {gradient:.3f} psi/ft unusual\")\n",
    "        \n",
    "        return len(issues) == 0, issues\n",
    "\n",
    "print(\"Constraint Checker ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== From Tutorial 06: Deck Generator ==========\n",
    "\n",
    "class DeckGenerator:\n",
    "    \"\"\"Generate ECLIPSE decks.\"\"\"\n",
    "    \n",
    "    def generate(self, params: Dict) -> str:\n",
    "        \"\"\"Generate complete deck from parameters.\"\"\"\n",
    "        nx = params.get('nx', 10)\n",
    "        ny = params.get('ny', 10)\n",
    "        nz = params.get('nz', 5)\n",
    "        total = nx * ny * nz\n",
    "        top_cells = nx * ny\n",
    "        \n",
    "        poro = params.get('porosity', 0.2)\n",
    "        perm = params.get('permeability', 100)\n",
    "        depth = params.get('depth', 8000)\n",
    "        pressure = params.get('pressure', 3500)\n",
    "        \n",
    "        deck = f'''RUNSPEC\n",
    "\n",
    "TITLE\n",
    "CLARISSA Generated Model\n",
    "\n",
    "OIL\n",
    "WATER\n",
    "\n",
    "FIELD\n",
    "\n",
    "DIMENS\n",
    "  {nx} {ny} {nz} /\n",
    "\n",
    "TABDIMS\n",
    "  1 1 20 20 /\n",
    "\n",
    "WELLDIMS\n",
    "  10 50 5 10 /\n",
    "\n",
    "START\n",
    "  1 JAN 2024 /\n",
    "\n",
    "GRID\n",
    "\n",
    "DX\n",
    "  {total}*100 /\n",
    "DY\n",
    "  {total}*100 /\n",
    "DZ\n",
    "  {total}*20 /\n",
    "\n",
    "TOPS\n",
    "  {top_cells}*{depth} /\n",
    "\n",
    "PORO\n",
    "  {total}*{poro} /\n",
    "\n",
    "PERMX\n",
    "  {total}*{perm} /\n",
    "PERMY\n",
    "  {total}*{perm} /\n",
    "PERMZ\n",
    "  {total}*{perm*0.1:.1f} /\n",
    "\n",
    "PROPS\n",
    "\n",
    "SWOF\n",
    "  0.20 0.0000 1.0000 0.0\n",
    "  0.30 0.0200 0.6000 0.0\n",
    "  0.50 0.1000 0.2000 0.0\n",
    "  0.70 0.3500 0.0200 0.0\n",
    "  0.80 0.5000 0.0000 0.0 /\n",
    "\n",
    "PVTW\n",
    "  {pressure} 1.01 3.0E-6 0.5 0 /\n",
    "\n",
    "PVDO\n",
    "  1000 1.20 1.5\n",
    "  2000 1.15 1.2\n",
    "  3000 1.10 1.0\n",
    "  4000 1.05 0.8\n",
    "  5000 1.02 0.7 /\n",
    "\n",
    "ROCK\n",
    "  {pressure} 3.0E-6 /\n",
    "\n",
    "DENSITY\n",
    "  45.0 64.0 0.06 /\n",
    "\n",
    "SOLUTION\n",
    "\n",
    "EQUIL\n",
    "  {depth} {pressure} {depth + 1000} 0 0 0 1 /\n",
    "\n",
    "SCHEDULE\n",
    "\n",
    "WELSPECS\n",
    "  PROD1 G1 {nx//2} {ny//2} 1* OIL /\n",
    "/\n",
    "\n",
    "COMPDAT\n",
    "  PROD1 {nx//2} {ny//2} 1 {nz} OPEN 1* 0.5 /\n",
    "/\n",
    "\n",
    "WCONPROD\n",
    "  PROD1 OPEN ORAT 500 4* 1000 /\n",
    "/\n",
    "\n",
    "TSTEP\n",
    "  30*30 /\n",
    "\n",
    "END\n",
    "'''\n",
    "        return deck\n",
    "\n",
    "print(\"Deck Generator ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: The CLARISSA Pipeline\n",
    "\n",
    "Orchestrate all components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLARISSAPipeline:\n",
    "    \"\"\"Main CLARISSA processing pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.parser = NLParser()\n",
    "        self.constraints = ConstraintChecker()\n",
    "        self.generator = DeckGenerator()\n",
    "        \n",
    "        self.conversation_history: List[Dict] = []\n",
    "        self.current_params: Dict = {}\n",
    "        self.current_deck: Optional[str] = None\n",
    "        self.assumptions: List[str] = []\n",
    "    \n",
    "    def process_message(self, user_message: str) -> str:\n",
    "        \"\"\"Process a user message and return response.\"\"\"\n",
    "        self.conversation_history.append({'role': 'user', 'content': user_message})\n",
    "        \n",
    "        # 1. Parse intent and entities\n",
    "        intent, entities = self.parser.parse(user_message)\n",
    "        \n",
    "        # 2. Update parameters from entities\n",
    "        self._update_params(entities)\n",
    "        \n",
    "        # 3. Route based on intent\n",
    "        if intent == UserIntent.CREATE_MODEL:\n",
    "            response = self._handle_create_model(entities)\n",
    "        elif intent == UserIntent.ADD_WELL:\n",
    "            response = self._handle_add_well(entities)\n",
    "        elif intent == UserIntent.RUN_SIMULATION:\n",
    "            response = self._handle_run_simulation()\n",
    "        else:\n",
    "            response = self._handle_unknown(user_message)\n",
    "        \n",
    "        self.conversation_history.append({'role': 'assistant', 'content': response})\n",
    "        return response\n",
    "    \n",
    "    def _update_params(self, entities: ExtractedEntities):\n",
    "        \"\"\"Update current parameters from extracted entities.\"\"\"\n",
    "        if entities.grid_size:\n",
    "            self.current_params['nx'] = entities.grid_size[0]\n",
    "            self.current_params['ny'] = entities.grid_size[1]\n",
    "            self.current_params['nz'] = entities.grid_size[2]\n",
    "        if entities.porosity:\n",
    "            self.current_params['porosity'] = entities.porosity\n",
    "        if entities.permeability:\n",
    "            self.current_params['permeability'] = entities.permeability\n",
    "        if entities.depths:\n",
    "            self.current_params['depth'] = entities.depths[0]\n",
    "        if entities.pressures:\n",
    "            self.current_params['pressure'] = entities.pressures[0]\n",
    "    \n",
    "    def _handle_create_model(self, entities: ExtractedEntities) -> str:\n",
    "        \"\"\"Handle model creation request.\"\"\"\n",
    "        self.assumptions = []\n",
    "        \n",
    "        # Apply defaults for missing parameters\n",
    "        defaults = {\n",
    "            'nx': 10, 'ny': 10, 'nz': 5,\n",
    "            'porosity': 0.2, 'permeability': 100,\n",
    "            'depth': 8000, 'pressure': 3500\n",
    "        }\n",
    "        \n",
    "        for key, default in defaults.items():\n",
    "            if key not in self.current_params:\n",
    "                self.current_params[key] = default\n",
    "                self.assumptions.append(f\"Using default {key}={default}\")\n",
    "        \n",
    "        # Validate constraints\n",
    "        valid, issues = self.constraints.check_all(self.current_params)\n",
    "        \n",
    "        if not valid:\n",
    "            return f\"I found some issues: {', '.join(issues)}. Please clarify.\"\n",
    "        \n",
    "        # Generate deck\n",
    "        self.current_deck = self.generator.generate(self.current_params)\n",
    "        \n",
    "        # Build response\n",
    "        nx, ny, nz = self.current_params['nx'], self.current_params['ny'], self.current_params['nz']\n",
    "        response = f\"I've created a {nx}x{ny}x{nz} simulation model.\\n\\n\"\n",
    "        \n",
    "        if self.assumptions:\n",
    "            response += \"Assumptions made:\\n\"\n",
    "            for a in self.assumptions:\n",
    "                response += f\"  - {a}\\n\"\n",
    "        \n",
    "        response += \"\\nThe deck is ready. Would you like to run the simulation?\"\n",
    "        return response\n",
    "    \n",
    "    def _handle_add_well(self, entities: ExtractedEntities) -> str:\n",
    "        \"\"\"Handle add well request.\"\"\"\n",
    "        if not self.current_deck:\n",
    "            return \"Please create a model first before adding wells.\"\n",
    "        return \"Well functionality coming in next version.\"\n",
    "    \n",
    "    def _handle_run_simulation(self) -> str:\n",
    "        \"\"\"Handle simulation run request.\"\"\"\n",
    "        if not self.current_deck:\n",
    "            return \"No deck to simulate. Please create a model first.\"\n",
    "        \n",
    "        # Try to run OPM Flow\n",
    "        result = self._execute_opm_flow()\n",
    "        return result\n",
    "    \n",
    "    def _handle_unknown(self, message: str) -> str:\n",
    "        \"\"\"Handle unknown intent.\"\"\"\n",
    "        return (\"I can help you create reservoir simulation models. Try:\\n\"\n",
    "                \"- 'Create a 20x20x5 model with porosity 0.22'\\n\"\n",
    "                \"- 'Run the simulation'\\n\"\n",
    "                \"- 'Add a producer well at coordinates 10,10'\")\n",
    "    \n",
    "    def _execute_opm_flow(self) -> str:\n",
    "        \"\"\"Execute OPM Flow simulation.\"\"\"\n",
    "        # Check if OPM Flow is available\n",
    "        opm_path = os.environ.get('OPM_FLOW_PATH', '/usr/bin/flow')\n",
    "        \n",
    "        if not os.path.exists(opm_path):\n",
    "            return (\"OPM Flow not found. The deck has been generated and is ready.\\n\"\n",
    "                   f\"You can run it manually with: flow YOUR_DECK.DATA\\n\\n\"\n",
    "                   f\"Deck preview (first 500 chars):\\n{self.current_deck[:500]}...\")\n",
    "        \n",
    "        # Write deck to temp file\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            deck_path = Path(tmpdir) / \"CLARISSA_MODEL.DATA\"\n",
    "            deck_path.write_text(self.current_deck)\n",
    "            \n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    [opm_path, str(deck_path)],\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                    timeout=300,\n",
    "                    cwd=tmpdir\n",
    "                )\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    return \"Simulation completed successfully! Results are available.\"\n",
    "                else:\n",
    "                    return f\"Simulation failed: {result.stderr[:500]}\"\n",
    "                    \n",
    "            except subprocess.TimeoutExpired:\n",
    "                return \"Simulation timed out after 5 minutes.\"\n",
    "            except Exception as e:\n",
    "                return f\"Simulation error: {str(e)}\"\n",
    "\n",
    "print(\"CLARISSA Pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Demo Conversation\n",
    "\n",
    "Walk through a complete interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "clarissa = CLARISSAPipeline()\n",
    "\n",
    "print(\"CLARISSA Conversation Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Conversation turns\n",
    "conversation = [\n",
    "    \"Create a waterflood model with 20x20x5 grid, porosity 0.22, permeability 150 md\",\n",
    "    \"The reservoir is at 8500 ft depth with 3800 psi initial pressure\",\n",
    "    \"Run the simulation\"\n",
    "]\n",
    "\n",
    "for i, user_msg in enumerate(conversation, 1):\n",
    "    print(f\"\\n[Turn {i}]\")\n",
    "    print(f\"User: {user_msg}\")\n",
    "    \n",
    "    response = clarissa.process_message(user_msg)\n",
    "    print(f\"\\nCLARISSA: {response}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show generated deck\n",
    "print(\"Generated ECLIPSE Deck:\")\n",
    "print(\"=\" * 60)\n",
    "if clarissa.current_deck:\n",
    "    print(clarissa.current_deck)\n",
    "else:\n",
    "    print(\"No deck generated yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Conversation State Tracking\n",
    "\n",
    "Examine what the pipeline tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline State\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nCurrent Parameters:\")\n",
    "for key, value in clarissa.current_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nAssumptions Made:\")\n",
    "for assumption in clarissa.assumptions:\n",
    "    print(f\"  - {assumption}\")\n",
    "\n",
    "print(f\"\\nConversation History: {len(clarissa.conversation_history)} messages\")\n",
    "for msg in clarissa.conversation_history:\n",
    "    role = msg['role'].upper()\n",
    "    content = msg['content'][:80] + '...' if len(msg['content']) > 80 else msg['content']\n",
    "    print(f\"  [{role}] {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Saving and Loading Sessions\n",
    "\n",
    "Persist conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_session(pipeline: CLARISSAPipeline, filepath: str):\n",
    "    \"\"\"Save session state to JSON.\"\"\"\n",
    "    session = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'parameters': pipeline.current_params,\n",
    "        'assumptions': pipeline.assumptions,\n",
    "        'conversation': pipeline.conversation_history,\n",
    "        'deck': pipeline.current_deck\n",
    "    }\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(session, f, indent=2)\n",
    "    \n",
    "    print(f\"Session saved to {filepath}\")\n",
    "\n",
    "def load_session(filepath: str) -> CLARISSAPipeline:\n",
    "    \"\"\"Load session state from JSON.\"\"\"\n",
    "    with open(filepath) as f:\n",
    "        session = json.load(f)\n",
    "    \n",
    "    pipeline = CLARISSAPipeline()\n",
    "    pipeline.current_params = session['parameters']\n",
    "    pipeline.assumptions = session['assumptions']\n",
    "    pipeline.conversation_history = session['conversation']\n",
    "    pipeline.current_deck = session['deck']\n",
    "    \n",
    "    print(f\"Session loaded from {filepath}\")\n",
    "    print(f\"  Parameters: {len(pipeline.current_params)}\")\n",
    "    print(f\"  Messages: {len(pipeline.conversation_history)}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Demo save/load\n",
    "save_session(clarissa, '/tmp/clarissa_session.json')\n",
    "loaded = load_session('/tmp/clarissa_session.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we saw:\n",
    "\n",
    "1. **All Components Together**: NL Parser, Constraints, Generator, Execution\n",
    "2. **Conversation Flow**: Multi-turn dialogue with state tracking\n",
    "3. **Deck Generation**: Complete ECLIPSE deck from natural language\n",
    "4. **Assumptions**: Explicit documentation of defaults used\n",
    "5. **Session Management**: Save and load conversation state\n",
    "\n",
    "**Key Insight**: The pipeline orchestrates specialized components, each handling a specific aspect of the task.\n",
    "\n",
    "**Next Tutorial:** [10_API_Reference.ipynb](10_API_Reference.ipynb) - REST API documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}