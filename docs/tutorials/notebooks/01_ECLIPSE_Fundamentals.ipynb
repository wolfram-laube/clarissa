{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - ECLIPSE Fundamentals for CLARISSA\n",
    "\n",
    "**CLARISSA** (Conversational Language Agent for Reservoir Integrated Simulation System Analysis)\n",
    "\n",
    "This notebook provides a comprehensive introduction to ECLIPSE deck syntax and semantics - the foundation that CLARISSA must understand to generate valid simulation models.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand the structure of an ECLIPSE simulation deck\n",
    "2. Learn the eight mandatory sections and their purposes\n",
    "3. Master keyword syntax and data record formats\n",
    "4. Recognize common patterns and pitfalls\n",
    "5. Understand OPM Flow compatibility considerations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLARISSA System Architecture\n",
    "\n",
    "Before diving into ECLIPSE syntax, let's understand where this fits in the bigger picture. CLARISSA is a 6-layer system that translates natural language into executable simulation decks:\n",
    "\n",
    "```mermaid\n",
    "flowchart TB\n",
    "    subgraph UI[\"User Interface Layer\"]\n",
    "        Voice[\"ðŸŽ¤ Voice Input<br/>Field Operations\"]\n",
    "        Text[\"ðŸ’¬ Text Chat<br/>Technical
    "\n",
    "A **deck** (historically called a \"card deck\" from punch card days) is a structured text file that defines:\n",
    "\n",
    "- **What** to simulate (fluid system, rock properties)\n",
    "- **Where** the reservoir is (grid geometry, depth)\n",
    "- **How** it's operated (wells, constraints, schedule)\n",
    "- **What** to output (summary vectors, restart files)\n",
    "\n",
    "Think of it as **Infrastructure-as-Code for subsurface physics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A minimal ECLIPSE deck structure\n",
    "MINIMAL_DECK = \"\"\"\n",
    "-- ============================================================\n",
    "-- MINIMAL ECLIPSE DECK STRUCTURE\n",
    "-- ============================================================\n",
    "-- Comments start with two dashes\n",
    "\n",
    "RUNSPEC    -- Section 1: Run Specification\n",
    "           -- What kind of simulation is this?\n",
    "\n",
    "GRID       -- Section 2: Grid Definition  \n",
    "           -- Where is the reservoir?\n",
    "\n",
    "PROPS      -- Section 3: Properties\n",
    "           -- Rock and fluid properties\n",
    "\n",
    "SOLUTION   -- Section 4: Solution (Initial Conditions)\n",
    "           -- Starting state of the reservoir\n",
    "\n",
    "SUMMARY    -- Section 5: Summary Output\n",
    "           -- What to log during simulation\n",
    "\n",
    "SCHEDULE   -- Section 6: Schedule\n",
    "           -- Wells and time-stepping\n",
    "\n",
    "END        -- Terminates the deck\n",
    "\"\"\"\n",
    "\n",
    "print(MINIMAL_DECK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Section Order is Mandatory\n",
    "\n",
    "ECLIPSE enforces strict section ordering. The sections must appear in this sequence:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  RUNSPEC   â”‚  \"Metadata\" - dimensions, phases, features     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  GRID      â”‚  \"Infrastructure\" - 3D geometry                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  EDIT      â”‚  \"Patches\" - grid corrections (OPTIONAL)       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  PROPS     â”‚  \"Config\" - rock/fluid properties              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  REGIONS   â”‚  \"Zones\" - property regions (OPTIONAL)         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  SOLUTION  â”‚  \"Init\" - initial conditions                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  SUMMARY   â”‚  \"Logging\" - output specification              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  SCHEDULE  â”‚  \"Workflow\" - wells and timesteps              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**CLARISSA Validation Rule #1**: Always check section ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum, auto\n",
    "\n",
    "class EclipseSection(Enum):\n",
    "    \"\"\"ECLIPSE sections in required order\"\"\"\n",
    "    RUNSPEC = auto()\n",
    "    GRID = auto()\n",
    "    EDIT = auto()      # Optional\n",
    "    PROPS = auto()\n",
    "    REGIONS = auto()   # Optional\n",
    "    SOLUTION = auto()\n",
    "    SUMMARY = auto()\n",
    "    SCHEDULE = auto()\n",
    "\n",
    "REQUIRED_SECTIONS = [\n",
    "    EclipseSection.RUNSPEC,\n",
    "    EclipseSection.GRID,\n",
    "    EclipseSection.PROPS,\n",
    "    EclipseSection.SOLUTION,\n",
    "    EclipseSection.SUMMARY,\n",
    "    EclipseSection.SCHEDULE\n",
    "]\n",
    "\n",
    "OPTIONAL_SECTIONS = [\n",
    "    EclipseSection.EDIT,\n",
    "    EclipseSection.REGIONS\n",
    "]\n",
    "\n",
    "@dataclass\n",
    "class SectionValidationResult:\n",
    "    valid: bool\n",
    "    sections_found: List[str]\n",
    "    missing_sections: List[str]\n",
    "    order_errors: List[str]\n",
    "\n",
    "def validate_section_order(deck_content: str) -> SectionValidationResult:\n",
    "    \"\"\"\n",
    "    Validate that ECLIPSE sections appear in correct order.\n",
    "    \n",
    "    This is the first validation CLARISSA performs on any deck.\n",
    "    \"\"\"\n",
    "    # Find all section keywords\n",
    "    section_pattern = r'^(RUNSPEC|GRID|EDIT|PROPS|REGIONS|SOLUTION|SUMMARY|SCHEDULE)\\s*$'\n",
    "    \n",
    "    sections_found = []\n",
    "    for line in deck_content.split('\\n'):\n",
    "        line = line.split('--')[0].strip()  # Remove comments\n",
    "        match = re.match(section_pattern, line)\n",
    "        if match:\n",
    "            sections_found.append(match.group(1))\n",
    "    \n",
    "    # Check for missing required sections\n",
    "    missing = [s.name for s in REQUIRED_SECTIONS if s.name not in sections_found]\n",
    "    \n",
    "    # Check order\n",
    "    order_errors = []\n",
    "    section_order = [s.name for s in EclipseSection]\n",
    "    \n",
    "    last_index = -1\n",
    "    for section in sections_found:\n",
    "        current_index = section_order.index(section)\n",
    "        if current_index < last_index:\n",
    "            order_errors.append(\n",
    "                f\"Section {section} appears after {section_order[last_index]} \"\n",
    "                f\"but should come before it\"\n",
    "            )\n",
    "        last_index = current_index\n",
    "    \n",
    "    return SectionValidationResult(\n",
    "        valid=len(missing) == 0 and len(order_errors) == 0,\n",
    "        sections_found=sections_found,\n",
    "        missing_sections=missing,\n",
    "        order_errors=order_errors\n",
    "    )\n",
    "\n",
    "# Test with a valid deck\n",
    "valid_deck = \"\"\"\n",
    "RUNSPEC\n",
    "GRID\n",
    "PROPS\n",
    "SOLUTION\n",
    "SUMMARY\n",
    "SCHEDULE\n",
    "END\n",
    "\"\"\"\n",
    "\n",
    "result = validate_section_order(valid_deck)\n",
    "print(f\"Valid: {result.valid}\")\n",
    "print(f\"Sections found: {result.sections_found}\")\n",
    "print(f\"Missing: {result.missing_sections}\")\n",
    "print(f\"Order errors: {result.order_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with an invalid deck (wrong order)\n",
    "invalid_deck = \"\"\"\n",
    "RUNSPEC\n",
    "PROPS      -- WRONG: PROPS before GRID!\n",
    "GRID\n",
    "SOLUTION\n",
    "SCHEDULE   -- Missing SUMMARY\n",
    "END\n",
    "\"\"\"\n",
    "\n",
    "result = validate_section_order(invalid_deck)\n",
    "print(f\"Valid: {result.valid}\")\n",
    "print(f\"Sections found: {result.sections_found}\")\n",
    "print(f\"Missing: {result.missing_sections}\")\n",
    "print(f\"Order errors: {result.order_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keyword Syntax\n",
    "\n",
    "ECLIPSE keywords follow a consistent pattern:\n",
    "\n",
    "```eclipse\n",
    "KEYWORD\n",
    "  data data data /    -- Slash terminates a record\n",
    "  data data data /    -- Multiple records allowed\n",
    "/                     -- Empty slash terminates keyword (for some keywords)\n",
    "```\n",
    "\n",
    "### Key Syntax Rules\n",
    "\n",
    "1. **Keywords** are ALL CAPS, typically 4-8 characters\n",
    "2. **Records** are terminated by `/` (forward slash)\n",
    "3. **Comments** start with `--` (two dashes)\n",
    "4. **Whitespace** is flexible (spaces, tabs, newlines)\n",
    "5. **Repetition** uses `N*value` syntax (e.g., `100*0.2` means \"100 values of 0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Union\n",
    "import re\n",
    "\n",
    "@dataclass\n",
    "class KeywordData:\n",
    "    \"\"\"Parsed ECLIPSE keyword with its data records\"\"\"\n",
    "    name: str\n",
    "    records: List[List[Any]]\n",
    "    raw_text: str\n",
    "\n",
    "def expand_repetition(value: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Expand ECLIPSE repetition syntax.\n",
    "    \n",
    "    Examples:\n",
    "        '3*100' -> ['100', '100', '100']\n",
    "        '100'   -> ['100']\n",
    "        '2*'    -> ['1*', '1*']  (default value marker)\n",
    "    \"\"\"\n",
    "    if '*' in value:\n",
    "        parts = value.split('*')\n",
    "        count = int(parts[0])\n",
    "        val = parts[1] if len(parts) > 1 and parts[1] else '1*'\n",
    "        return [val] * count\n",
    "    return [value]\n",
    "\n",
    "def parse_record(record_text: str) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Parse a single ECLIPSE data record.\n",
    "    \n",
    "    Handles:\n",
    "    - Numeric values (int, float)\n",
    "    - Strings (quoted or unquoted)\n",
    "    - Repetition syntax (N*value)\n",
    "    - Default markers (1*)\n",
    "    \"\"\"\n",
    "    # Remove comments\n",
    "    record_text = re.sub(r'--.*', '', record_text)\n",
    "    \n",
    "    # Split on whitespace\n",
    "    tokens = record_text.split()\n",
    "    \n",
    "    values = []\n",
    "    for token in tokens:\n",
    "        # Handle quoted strings\n",
    "        if token.startswith(\"'\") and token.endswith(\"'\"):\n",
    "            values.append(token.strip(\"'\"))\n",
    "        # Handle repetition\n",
    "        elif '*' in token and not token.startswith('1*'):\n",
    "            values.extend(expand_repetition(token))\n",
    "        # Handle default marker\n",
    "        elif token == '1*':\n",
    "            values.append(None)  # None represents default\n",
    "        # Handle numbers\n",
    "        else:\n",
    "            try:\n",
    "                if '.' in token or 'e' in token.lower():\n",
    "                    values.append(float(token))\n",
    "                else:\n",
    "                    values.append(int(token))\n",
    "            except ValueError:\n",
    "                values.append(token)  # Keep as string\n",
    "    \n",
    "    return values\n",
    "\n",
    "def parse_keyword(keyword_text: str) -> KeywordData:\n",
    "    \"\"\"\n",
    "    Parse an ECLIPSE keyword block.\n",
    "    \n",
    "    Example input:\n",
    "        DIMENS\n",
    "          10 10 3 /\n",
    "    \n",
    "    Returns KeywordData with name='DIMENS' and records=[[10, 10, 3]]\n",
    "    \"\"\"\n",
    "    lines = keyword_text.strip().split('\\n')\n",
    "    \n",
    "    # First non-empty, non-comment line is the keyword name\n",
    "    keyword_name = None\n",
    "    for line in lines:\n",
    "        stripped = line.split('--')[0].strip()\n",
    "        if stripped:\n",
    "            keyword_name = stripped\n",
    "            break\n",
    "    \n",
    "    if not keyword_name:\n",
    "        raise ValueError(\"No keyword found\")\n",
    "    \n",
    "    # Find all records (terminated by /)\n",
    "    # Join remaining lines and split by /\n",
    "    data_text = '\\n'.join(lines[1:])  # Everything after keyword name\n",
    "    \n",
    "    # Split by / but handle quoted strings\n",
    "    records = []\n",
    "    current_record = []\n",
    "    \n",
    "    for part in re.split(r'/', data_text):\n",
    "        part = part.strip()\n",
    "        if part:\n",
    "            record_values = parse_record(part)\n",
    "            if record_values:\n",
    "                records.append(record_values)\n",
    "    \n",
    "    return KeywordData(\n",
    "        name=keyword_name,\n",
    "        records=records,\n",
    "        raw_text=keyword_text\n",
    "    )\n",
    "\n",
    "# Test parsing\n",
    "dimens_text = \"\"\"\n",
    "DIMENS\n",
    "  10 10 3 /\n",
    "\"\"\"\n",
    "\n",
    "result = parse_keyword(dimens_text)\n",
    "print(f\"Keyword: {result.name}\")\n",
    "print(f\"Records: {result.records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex example: WELSPECS with multiple wells\n",
    "welspecs_text = \"\"\"\n",
    "WELSPECS\n",
    "-- Name  Group  I   J   Depth  Phase\n",
    "  'INJ1' 'G1'   1   1   8335   'WATER' /\n",
    "  'PROD1' 'G1'  10  10  8335   'OIL'   /\n",
    "  'PROD2' 'G1'  10  1   8335   'OIL'   /\n",
    "/\n",
    "\"\"\"\n",
    "\n",
    "result = parse_keyword(welspecs_text)\n",
    "print(f\"Keyword: {result.name}\")\n",
    "print(f\"Number of wells: {len(result.records)}\")\n",
    "for i, well in enumerate(result.records):\n",
    "    print(f\"  Well {i+1}: {well}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test repetition syntax\n",
    "poro_text = \"\"\"\n",
    "PORO\n",
    "  300*0.2 /   -- 300 cells with 20% porosity\n",
    "\"\"\"\n",
    "\n",
    "result = parse_keyword(poro_text)\n",
    "print(f\"Keyword: {result.name}\")\n",
    "print(f\"Number of values: {len(result.records[0])}\")\n",
    "print(f\"First 5 values: {result.records[0][:5]}\")\n",
    "print(f\"All values same: {len(set(result.records[0])) == 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RUNSPEC Section Deep Dive\n",
    "\n",
    "RUNSPEC defines the \"metadata\" of your simulation:\n",
    "\n",
    "- **TITLE**: Model name\n",
    "- **DIMENS**: Grid dimensions (NX, NY, NZ)\n",
    "- **Phase keywords**: OIL, WATER, GAS, DISGAS, VAPOIL\n",
    "- **Unit system**: METRIC, FIELD, LAB\n",
    "- **START**: Simulation start date\n",
    "- **Dimension keywords**: TABDIMS, WELLDIMS, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RunspecData:\n",
    "    \"\"\"Parsed RUNSPEC section data\"\"\"\n",
    "    title: Optional[str] = None\n",
    "    nx: Optional[int] = None\n",
    "    ny: Optional[int] = None\n",
    "    nz: Optional[int] = None\n",
    "    phases: List[str] = None\n",
    "    unit_system: str = 'METRIC'  # Default\n",
    "    start_date: Optional[str] = None\n",
    "    disgas: bool = False\n",
    "    vapoil: bool = False\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.phases is None:\n",
    "            self.phases = []\n",
    "    \n",
    "    @property\n",
    "    def total_cells(self) -> Optional[int]:\n",
    "        if all([self.nx, self.ny, self.nz]):\n",
    "            return self.nx * self.ny * self.nz\n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def is_three_phase(self) -> bool:\n",
    "        return all(p in self.phases for p in ['OIL', 'WATER', 'GAS'])\n",
    "\n",
    "def parse_runspec(deck_content: str) -> RunspecData:\n",
    "    \"\"\"\n",
    "    Parse RUNSPEC section and extract key parameters.\n",
    "    \"\"\"\n",
    "    data = RunspecData()\n",
    "    \n",
    "    # Extract RUNSPEC section\n",
    "    runspec_match = re.search(\n",
    "        r'RUNSPEC(.*?)(?=GRID|$)', \n",
    "        deck_content, \n",
    "        re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    if not runspec_match:\n",
    "        return data\n",
    "    \n",
    "    runspec_text = runspec_match.group(1)\n",
    "    \n",
    "    # Parse TITLE\n",
    "    title_match = re.search(r'TITLE\\s*\\n([^\\n]+)', runspec_text)\n",
    "    if title_match:\n",
    "        data.title = title_match.group(1).strip()\n",
    "    \n",
    "    # Parse DIMENS\n",
    "    dimens_match = re.search(r'DIMENS\\s*\\n\\s*(\\d+)\\s+(\\d+)\\s+(\\d+)', runspec_text)\n",
    "    if dimens_match:\n",
    "        data.nx = int(dimens_match.group(1))\n",
    "        data.ny = int(dimens_match.group(2))\n",
    "        data.nz = int(dimens_match.group(3))\n",
    "    \n",
    "    # Parse phases (standalone keywords)\n",
    "    if re.search(r'^OIL\\s*$', runspec_text, re.MULTILINE):\n",
    "        data.phases.append('OIL')\n",
    "    if re.search(r'^WATER\\s*$', runspec_text, re.MULTILINE):\n",
    "        data.phases.append('WATER')\n",
    "    if re.search(r'^GAS\\s*$', runspec_text, re.MULTILINE):\n",
    "        data.phases.append('GAS')\n",
    "    if re.search(r'^DISGAS\\s*$', runspec_text, re.MULTILINE):\n",
    "        data.disgas = True\n",
    "    if re.search(r'^VAPOIL\\s*$', runspec_text, re.MULTILINE):\n",
    "        data.vapoil = True\n",
    "    \n",
    "    # Parse unit system\n",
    "    if re.search(r'^FIELD\\s*$', runspec_text, re.MULTILINE):\n",
    "        data.unit_system = 'FIELD'\n",
    "    elif re.search(r'^LAB\\s*$', runspec_text, re.MULTILINE):\n",
    "        data.unit_system = 'LAB'\n",
    "    else:\n",
    "        data.unit_system = 'METRIC'  # Default\n",
    "    \n",
    "    # Parse START date\n",
    "    start_match = re.search(r\"START\\s*\\n\\s*(\\d+)\\s+'?(\\w+)'?\\s+(\\d+)\", runspec_text)\n",
    "    if start_match:\n",
    "        day, month, year = start_match.groups()\n",
    "        data.start_date = f\"{day} {month} {year}\"\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Test with SPE1 example\n",
    "spe1_runspec = \"\"\"\n",
    "RUNSPEC\n",
    "\n",
    "TITLE\n",
    "SPE1 - First SPE Comparative Solution Project\n",
    "\n",
    "DIMENS\n",
    "  10 10 3 /\n",
    "\n",
    "OIL\n",
    "WATER\n",
    "GAS\n",
    "DISGAS\n",
    "\n",
    "FIELD\n",
    "\n",
    "START\n",
    "  1 'JAN' 2025 /\n",
    "\n",
    "GRID\n",
    "\"\"\"\n",
    "\n",
    "runspec = parse_runspec(spe1_runspec)\n",
    "print(f\"Title: {runspec.title}\")\n",
    "print(f\"Dimensions: {runspec.nx} x {runspec.ny} x {runspec.nz}\")\n",
    "print(f\"Total cells: {runspec.total_cells}\")\n",
    "print(f\"Phases: {runspec.phases}\")\n",
    "print(f\"Three-phase: {runspec.is_three_phase}\")\n",
    "print(f\"Dissolved gas: {runspec.disgas}\")\n",
    "print(f\"Unit system: {runspec.unit_system}\")\n",
    "print(f\"Start date: {runspec.start_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GRID Section: Defining Reservoir Geometry\n",
    "\n",
    "The GRID section defines the 3D structure of the reservoir. Key keywords:\n",
    "\n",
    "| Keyword | Description | Data Count |\n",
    "|---------|-------------|------------|\n",
    "| DX | Cell size in X direction | NXÃ—NYÃ—NZ or NX |\n",
    "| DY | Cell size in Y direction | NXÃ—NYÃ—NZ or NY |\n",
    "| DZ | Cell size in Z direction | NXÃ—NYÃ—NZ or NZ |\n",
    "| TOPS | Depth of cell tops | NXÃ—NY (top layer) |\n",
    "| PERMX | Permeability in X | NXÃ—NYÃ—NZ |\n",
    "| PERMY | Permeability in Y | NXÃ—NYÃ—NZ |\n",
    "| PERMZ | Permeability in Z | NXÃ—NYÃ—NZ |\n",
    "| PORO | Porosity | NXÃ—NYÃ—NZ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GridData:\n",
    "    \"\"\"Parsed GRID section data\"\"\"\n",
    "    dx: List[float] = None\n",
    "    dy: List[float] = None\n",
    "    dz: List[float] = None\n",
    "    tops: List[float] = None\n",
    "    permx: List[float] = None\n",
    "    permy: List[float] = None\n",
    "    permz: List[float] = None\n",
    "    poro: List[float] = None\n",
    "    \n",
    "    def validate(self, nx: int, ny: int, nz: int) -> List[str]:\n",
    "        \"\"\"\n",
    "        Validate grid data against expected dimensions.\n",
    "        Returns list of validation errors.\n",
    "        \"\"\"\n",
    "        errors = []\n",
    "        total_cells = nx * ny * nz\n",
    "        top_cells = nx * ny\n",
    "        \n",
    "        # Check array sizes\n",
    "        if self.poro and len(self.poro) != total_cells:\n",
    "            errors.append(\n",
    "                f\"PORO has {len(self.poro)} values, expected {total_cells}\"\n",
    "            )\n",
    "        \n",
    "        if self.permx and len(self.permx) != total_cells:\n",
    "            errors.append(\n",
    "                f\"PERMX has {len(self.permx)} values, expected {total_cells}\"\n",
    "            )\n",
    "        \n",
    "        if self.tops and len(self.tops) != top_cells:\n",
    "            errors.append(\n",
    "                f\"TOPS has {len(self.tops)} values, expected {top_cells}\"\n",
    "            )\n",
    "        \n",
    "        # Check physical validity\n",
    "        if self.poro:\n",
    "            invalid_poro = [p for p in self.poro if p < 0 or p > 1]\n",
    "            if invalid_poro:\n",
    "                errors.append(\n",
    "                    f\"PORO has {len(invalid_poro)} values outside [0,1] range\"\n",
    "                )\n",
    "        \n",
    "        if self.permx:\n",
    "            negative_perm = [p for p in self.permx if p < 0]\n",
    "            if negative_perm:\n",
    "                errors.append(\n",
    "                    f\"PERMX has {len(negative_perm)} negative values\"\n",
    "                )\n",
    "        \n",
    "        return errors\n",
    "\n",
    "def generate_grid_section(\n",
    "    nx: int, ny: int, nz: int,\n",
    "    dx: float, dy: float, dz: List[float],\n",
    "    top_depth: float,\n",
    "    permx: float, poro: float,\n",
    "    kv_kh_ratio: float = 0.1\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate GRID section for a simple box model.\n",
    "    \n",
    "    This is a key function for CLARISSA's deck generation.\n",
    "    \n",
    "    Args:\n",
    "        nx, ny, nz: Grid dimensions\n",
    "        dx, dy: Horizontal cell sizes (ft or m)\n",
    "        dz: Layer thicknesses (list of length nz)\n",
    "        top_depth: Depth to top of reservoir\n",
    "        permx: Horizontal permeability (mD)\n",
    "        poro: Porosity (fraction)\n",
    "        kv_kh_ratio: Vertical/horizontal perm ratio\n",
    "    \"\"\"\n",
    "    total_cells = nx * ny * nz\n",
    "    top_cells = nx * ny\n",
    "    \n",
    "    lines = [\n",
    "        \"GRID\",\n",
    "        \"\",\n",
    "        \"-- Grid geometry\",\n",
    "        \"-- Generated by CLARISSA\",\n",
    "        \"\",\n",
    "    ]\n",
    "    \n",
    "    # DX - all cells same size\n",
    "    lines.append(\"DX\")\n",
    "    lines.append(f\"  {total_cells}*{dx} /\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # DY - all cells same size\n",
    "    lines.append(\"DY\")\n",
    "    lines.append(f\"  {total_cells}*{dy} /\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # DZ - varies by layer\n",
    "    lines.append(\"DZ\")\n",
    "    dz_values = []\n",
    "    for layer_dz in dz:\n",
    "        dz_values.append(f\"{top_cells}*{layer_dz}\")\n",
    "    lines.append(f\"  {' '.join(dz_values)} /\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # TOPS - depth to top of each column\n",
    "    lines.append(\"TOPS\")\n",
    "    lines.append(f\"  {top_cells}*{top_depth} /\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # Permeability\n",
    "    lines.append(\"-- Permeability (mD)\")\n",
    "    lines.append(\"PERMX\")\n",
    "    lines.append(f\"  {total_cells}*{permx} /\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    lines.append(\"PERMY\")\n",
    "    lines.append(f\"  {total_cells}*{permx} /  -- Same as PERMX (isotropic)\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    permz = permx * kv_kh_ratio\n",
    "    lines.append(\"PERMZ\")\n",
    "    lines.append(f\"  {total_cells}*{permz} /  -- Kv/Kh = {kv_kh_ratio}\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # Porosity\n",
    "    lines.append(\"-- Porosity (fraction)\")\n",
    "    lines.append(\"PORO\")\n",
    "    lines.append(f\"  {total_cells}*{poro} /\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Generate example grid\n",
    "grid_section = generate_grid_section(\n",
    "    nx=10, ny=10, nz=3,\n",
    "    dx=300, dy=300, dz=[20, 30, 50],\n",
    "    top_depth=8325,\n",
    "    permx=500, poro=0.2\n",
    ")\n",
    "\n",
    "print(grid_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PROPS Section: Rock and Fluid Properties\n",
    "\n",
    "PROPS contains the physics - how fluids behave under pressure and temperature.\n",
    "\n",
    "### Key Property Keywords\n",
    "\n",
    "| Keyword | Description | Required When |\n",
    "|---------|-------------|---------------|\n",
    "| PVTO | Oil PVT with dissolved gas | OIL + DISGAS |\n",
    "| PVDO | Dead oil PVT | OIL (no gas) |\n",
    "| PVTW | Water PVT | WATER |\n",
    "| PVDG | Dry gas PVT | GAS |\n",
    "| SWOF | Water-Oil relative perm | OIL + WATER |\n",
    "| SGOF | Gas-Oil relative perm | OIL + GAS |\n",
    "| ROCK | Rock compressibility | Always |\n",
    "| DENSITY | Fluid densities | Always |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FluidDensities:\n",
    "    \"\"\"Surface densities of fluids\"\"\"\n",
    "    oil: float      # lb/ftÂ³ or kg/mÂ³\n",
    "    water: float    # lb/ftÂ³ or kg/mÂ³\n",
    "    gas: float      # lb/ftÂ³ or kg/mÂ³\n",
    "\n",
    "@dataclass  \n",
    "class RelPermPoint:\n",
    "    \"\"\"Single point on relative permeability curve\"\"\"\n",
    "    saturation: float   # Sw or Sg\n",
    "    kr_water_or_gas: float  # Krw or Krg\n",
    "    kr_oil: float       # Krow or Krog\n",
    "    capillary: float    # Pcow or Pcog\n",
    "\n",
    "def generate_swof_table(\n",
    "    swirr: float = 0.2,    # Irreducible water saturation\n",
    "    sorw: float = 0.2,     # Residual oil to water\n",
    "    krw_max: float = 0.3,  # Max water rel perm\n",
    "    kro_max: float = 1.0,  # Max oil rel perm (at Swirr)\n",
    "    nw: float = 2.0,       # Corey exponent for water\n",
    "    no: float = 2.0        # Corey exponent for oil\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate SWOF table using Corey correlations.\n",
    "    \n",
    "    This is a common task for CLARISSA when user doesn't provide\n",
    "    explicit rel perm data.\n",
    "    \"\"\"\n",
    "    lines = [\n",
    "        \"SWOF\",\n",
    "        \"-- Sw      Krw      Kro      Pcow\",\n",
    "        \"-- Water-Oil Relative Permeability (Corey model)\",\n",
    "        f\"-- Swirr={swirr}, Sorw={sorw}, nw={nw}, no={no}\",\n",
    "    ]\n",
    "    \n",
    "    # Calculate normalized saturation range\n",
    "    sw_max = 1 - sorw\n",
    "    \n",
    "    # Generate 11 points\n",
    "    for i in range(11):\n",
    "        sw = swirr + (sw_max - swirr) * i / 10\n",
    "        \n",
    "        # Normalized saturation\n",
    "        sw_norm = (sw - swirr) / (sw_max - swirr)\n",
    "        so_norm = 1 - sw_norm\n",
    "        \n",
    "        # Corey model\n",
    "        krw = krw_max * (sw_norm ** nw)\n",
    "        kro = kro_max * (so_norm ** no)\n",
    "        \n",
    "        # No capillary pressure for simplicity\n",
    "        pcow = 0.0\n",
    "        \n",
    "        lines.append(f\"  {sw:.4f}  {krw:.6f}  {kro:.6f}  {pcow:.1f}\")\n",
    "    \n",
    "    lines.append(\"/\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Generate example SWOF\n",
    "swof_table = generate_swof_table()\n",
    "print(swof_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pvt_section(\n",
    "    phases: List[str],\n",
    "    unit_system: str = 'FIELD',\n",
    "    api_gravity: float = 35,\n",
    "    gas_gravity: float = 0.7,\n",
    "    water_salinity_ppm: float = 10000\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate basic PVT properties.\n",
    "    \n",
    "    For production use, these would come from:\n",
    "    - Lab PVT analysis\n",
    "    - Analog database\n",
    "    - Correlations (Standing, Vazquez-Beggs, etc.)\n",
    "    \"\"\"\n",
    "    lines = [\n",
    "        \"-- PVT Properties\",\n",
    "        \"-- Generated by CLARISSA using correlations\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    # DENSITY keyword\n",
    "    if unit_system == 'FIELD':\n",
    "        # Calculate oil density from API gravity\n",
    "        oil_sg = 141.5 / (api_gravity + 131.5)\n",
    "        oil_density = oil_sg * 62.4  # lb/ftÂ³\n",
    "        water_density = 62.4 * (1 + water_salinity_ppm / 1e6)  # Approximate\n",
    "        gas_density = gas_gravity * 0.0764  # lb/ftÂ³ at standard conditions\n",
    "        \n",
    "        lines.append(\"DENSITY\")\n",
    "        lines.append(f\"-- Oil   Water   Gas  (lb/ftÂ³)\")\n",
    "        lines.append(f\"  {oil_density:.2f}  {water_density:.2f}  {gas_density:.4f} /\")\n",
    "        lines.append(\"\")\n",
    "    \n",
    "    # PVTW - Water PVT (relatively simple)\n",
    "    if 'WATER' in phases:\n",
    "        lines.append(\"PVTW\")\n",
    "        lines.append(\"-- Pref    Bw      Cw        Viscw   Viscosibility\")\n",
    "        lines.append(\"-- (psi)   (rb/stb) (1/psi)  (cp)    (1/psi)\")\n",
    "        lines.append(\"   4000    1.029   3.0E-6    0.31    0.0 /\")\n",
    "        lines.append(\"\")\n",
    "    \n",
    "    # PVDO - Dead oil (simplified)\n",
    "    if 'OIL' in phases and 'GAS' not in phases:\n",
    "        lines.append(\"PVDO\")\n",
    "        lines.append(\"-- P(psi)   Bo      Visc(cp)\")\n",
    "        lines.append(\"   14.7    1.05    2.5\")\n",
    "        lines.append(\"   1000    1.04    2.3\")\n",
    "        lines.append(\"   2000    1.03    2.1\")\n",
    "        lines.append(\"   3000    1.02    1.9\")\n",
    "        lines.append(\"   4000    1.01    1.8\")\n",
    "        lines.append(\"   5000    1.00    1.7 /\")\n",
    "        lines.append(\"/\")\n",
    "        lines.append(\"\")\n",
    "    \n",
    "    # PVDG - Dry gas (if gas present)\n",
    "    if 'GAS' in phases:\n",
    "        lines.append(\"PVDG\")\n",
    "        lines.append(\"-- P(psi)   Bg       Visc(cp)\")\n",
    "        lines.append(\"   14.7    166.67   0.0080\")\n",
    "        lines.append(\"   500     4.893    0.0096\")\n",
    "        lines.append(\"   1000    2.501    0.0112\")\n",
    "        lines.append(\"   2000    1.289    0.0140\")\n",
    "        lines.append(\"   3000    0.884    0.0164\")\n",
    "        lines.append(\"   4000    0.683    0.0186\")\n",
    "        lines.append(\"   5000    0.563    0.0208 /\")\n",
    "        lines.append(\"/\")\n",
    "        lines.append(\"\")\n",
    "    \n",
    "    # ROCK compressibility\n",
    "    lines.append(\"ROCK\")\n",
    "    lines.append(\"-- Pref     Compressibility\")\n",
    "    lines.append(\"   4000     4.0E-6 /\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Generate PVT for oil-water system\n",
    "pvt_section = generate_pvt_section(\n",
    "    phases=['OIL', 'WATER'],\n",
    "    api_gravity=32\n",
    ")\n",
    "print(pvt_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SOLUTION Section: Initial Conditions\n",
    "\n",
    "SOLUTION defines the starting state of the reservoir. The most common approach is **equilibrium initialization** using EQUIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EquilData:\n",
    "    \"\"\"\n",
    "    Equilibration data for initialization.\n",
    "    \n",
    "    EQUIL defines how the simulator calculates initial\n",
    "    pressures and saturations based on gravity equilibrium.\n",
    "    \"\"\"\n",
    "    datum_depth: float      # Reference depth (ft or m)\n",
    "    datum_pressure: float   # Pressure at datum (psi or bar)\n",
    "    woc_depth: float        # Water-Oil Contact depth\n",
    "    woc_pcow: float = 0     # Capillary pressure at WOC\n",
    "    goc_depth: float = 0    # Gas-Oil Contact depth (0 = no gas cap)\n",
    "    goc_pcog: float = 0     # Capillary pressure at GOC\n",
    "    \n",
    "    def validate(self) -> List[str]:\n",
    "        \"\"\"Validate physical plausibility\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # GOC must be above WOC (shallower = smaller depth value)\n",
    "        if self.goc_depth > 0 and self.goc_depth > self.woc_depth:\n",
    "            errors.append(\n",
    "                f\"GOC ({self.goc_depth}) must be shallower than WOC ({self.woc_depth})\"\n",
    "            )\n",
    "        \n",
    "        # Pressure must be positive\n",
    "        if self.datum_pressure <= 0:\n",
    "            errors.append(f\"Datum pressure must be positive\")\n",
    "        \n",
    "        # Check pressure gradient (normal: 0.43-0.52 psi/ft)\n",
    "        gradient = self.datum_pressure / self.datum_depth\n",
    "        if gradient < 0.3 or gradient > 0.7:\n",
    "            errors.append(\n",
    "                f\"Pressure gradient {gradient:.3f} psi/ft is unusual \"\n",
    "                f\"(normal: 0.43-0.52 psi/ft)\"\n",
    "            )\n",
    "        \n",
    "        return errors\n",
    "\n",
    "def generate_solution_section(\n",
    "    equil: EquilData,\n",
    "    include_rptrst: bool = True\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate SOLUTION section with equilibration.\n",
    "    \"\"\"\n",
    "    # Validate first\n",
    "    errors = equil.validate()\n",
    "    if errors:\n",
    "        print(f\"WARNING: {errors}\")\n",
    "    \n",
    "    lines = [\n",
    "        \"SOLUTION\",\n",
    "        \"\",\n",
    "        \"-- Equilibration data\",\n",
    "        \"EQUIL\",\n",
    "        \"-- Datum  Pdat    WOC    Pcow   GOC    Pcog  Rsvd  Rvvd  Acc\",\n",
    "        f\"   {equil.datum_depth}  {equil.datum_pressure}  {equil.woc_depth}  \"\n",
    "        f\"{equil.woc_pcow}  {equil.goc_depth}  {equil.goc_pcog}  1*  1*  0 /\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    if include_rptrst:\n",
    "        lines.extend([\n",
    "            \"-- Restart file output\",\n",
    "            \"RPTRST\",\n",
    "            \"  'BASIC=2' /\",\n",
    "            \"\"\n",
    "        ])\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Generate example\n",
    "equil = EquilData(\n",
    "    datum_depth=8400,\n",
    "    datum_pressure=4000,\n",
    "    woc_depth=8500,\n",
    "    goc_depth=8200  # Gas cap present\n",
    ")\n",
    "\n",
    "solution = generate_solution_section(equil)\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SCHEDULE Section: Wells and Time-Stepping\n",
    "\n",
    "SCHEDULE is where the action happens - wells are defined, controls are set, and time advances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Optional\n",
    "\n",
    "class WellType(Enum):\n",
    "    PRODUCER = 'producer'\n",
    "    INJECTOR = 'injector'\n",
    "\n",
    "class ControlMode(Enum):\n",
    "    ORAT = 'ORAT'   # Oil rate\n",
    "    WRAT = 'WRAT'   # Water rate  \n",
    "    GRAT = 'GRAT'   # Gas rate\n",
    "    LRAT = 'LRAT'   # Liquid rate\n",
    "    BHP = 'BHP'     # Bottom hole pressure\n",
    "    RATE = 'RATE'   # For injectors\n",
    "\n",
    "@dataclass\n",
    "class Well:\n",
    "    \"\"\"Well definition for CLARISSA\"\"\"\n",
    "    name: str\n",
    "    well_type: WellType\n",
    "    i: int              # I-index (1-based)\n",
    "    j: int              # J-index (1-based)\n",
    "    k_top: int          # Top perforation layer\n",
    "    k_bottom: int       # Bottom perforation layer\n",
    "    datum_depth: float  # Reference depth for BHP\n",
    "    \n",
    "    # Control\n",
    "    control_mode: ControlMode = ControlMode.ORAT\n",
    "    control_value: float = 1000  # Rate (STB/d) or pressure (psi)\n",
    "    bhp_limit: float = 1000      # Min BHP for producers\n",
    "    \n",
    "    # For injectors\n",
    "    injection_fluid: str = 'WATER'  # WATER or GAS\n",
    "    \n",
    "    def validate(self, nx: int, ny: int, nz: int) -> List[str]:\n",
    "        \"\"\"Validate well against grid dimensions\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        if not (1 <= self.i <= nx):\n",
    "            errors.append(f\"Well {self.name}: I={self.i} outside grid (1-{nx})\")\n",
    "        if not (1 <= self.j <= ny):\n",
    "            errors.append(f\"Well {self.name}: J={self.j} outside grid (1-{ny})\")\n",
    "        if not (1 <= self.k_top <= nz):\n",
    "            errors.append(f\"Well {self.name}: K_top={self.k_top} outside grid (1-{nz})\")\n",
    "        if not (1 <= self.k_bottom <= nz):\n",
    "            errors.append(f\"Well {self.name}: K_bottom={self.k_bottom} outside grid (1-{nz})\")\n",
    "        if self.k_top > self.k_bottom:\n",
    "            errors.append(f\"Well {self.name}: K_top > K_bottom\")\n",
    "        if len(self.name) > 8:\n",
    "            errors.append(f\"Well {self.name}: name exceeds 8 characters\")\n",
    "        \n",
    "        return errors\n",
    "\n",
    "def generate_schedule_section(\n",
    "    wells: List[Well],\n",
    "    total_days: int = 365,\n",
    "    timestep_days: int = 30,\n",
    "    group_name: str = 'FIELD'\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate complete SCHEDULE section.\n",
    "    \n",
    "    This is one of CLARISSA's core generation functions.\n",
    "    \"\"\"\n",
    "    lines = [\n",
    "        \"SCHEDULE\",\n",
    "        \"\",\n",
    "        \"-- Well specifications\",\n",
    "        \"WELSPECS\",\n",
    "        \"-- Name    Group   I    J    Depth   Phase\"\n",
    "    ]\n",
    "    \n",
    "    for well in wells:\n",
    "        phase = well.injection_fluid if well.well_type == WellType.INJECTOR else 'OIL'\n",
    "        lines.append(\n",
    "            f\"  '{well.name}'  '{group_name}'  {well.i}  {well.j}  \"\n",
    "            f\"{well.datum_depth}  '{phase}' /\"\n",
    "        )\n",
    "    lines.append(\"/\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # COMPDAT - perforations\n",
    "    lines.append(\"-- Completions\")\n",
    "    lines.append(\"COMPDAT\")\n",
    "    lines.append(\"-- Name    I    J   K1   K2   Status  SAT  ...\")\n",
    "    \n",
    "    for well in wells:\n",
    "        lines.append(\n",
    "            f\"  '{well.name}'  {well.i}  {well.j}  {well.k_top}  {well.k_bottom}  \"\n",
    "            f\"'OPEN'  2*  0.5 /\"  # Default wellbore radius 0.5 ft\n",
    "        )\n",
    "    lines.append(\"/\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # Separate producers and injectors\n",
    "    producers = [w for w in wells if w.well_type == WellType.PRODUCER]\n",
    "    injectors = [w for w in wells if w.well_type == WellType.INJECTOR]\n",
    "    \n",
    "    # WCONPROD - producer controls\n",
    "    if producers:\n",
    "        lines.append(\"-- Producer controls\")\n",
    "        lines.append(\"WCONPROD\")\n",
    "        lines.append(\"-- Name   Status  Mode   Orat   Wrat   Grat   Lrat   BHP\")\n",
    "        \n",
    "        for well in producers:\n",
    "            orat = well.control_value if well.control_mode == ControlMode.ORAT else '1*'\n",
    "            bhp = well.bhp_limit\n",
    "            lines.append(\n",
    "                f\"  '{well.name}'  'OPEN'  '{well.control_mode.value}'  \"\n",
    "                f\"{orat}  1*  1*  1*  {bhp} /\"\n",
    "            )\n",
    "        lines.append(\"/\")\n",
    "        lines.append(\"\")\n",
    "    \n",
    "    # WCONINJE - injector controls\n",
    "    if injectors:\n",
    "        lines.append(\"-- Injector controls\")\n",
    "        lines.append(\"WCONINJE\")\n",
    "        lines.append(\"-- Name   Fluid   Status  Mode   Rate   BHP\")\n",
    "        \n",
    "        for well in injectors:\n",
    "            lines.append(\n",
    "                f\"  '{well.name}'  '{well.injection_fluid}'  'OPEN'  'RATE'  \"\n",
    "                f\"{well.control_value}  1* /\"\n",
    "            )\n",
    "        lines.append(\"/\")\n",
    "        lines.append(\"\")\n",
    "    \n",
    "    # Time stepping\n",
    "    num_steps = total_days // timestep_days\n",
    "    lines.append(\"-- Time stepping\")\n",
    "    lines.append(\"TSTEP\")\n",
    "    lines.append(f\"  {num_steps}*{timestep_days} /\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"END\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Create example 5-spot pattern\n",
    "wells = [\n",
    "    Well(\n",
    "        name='INJ1',\n",
    "        well_type=WellType.INJECTOR,\n",
    "        i=5, j=5,  # Center\n",
    "        k_top=1, k_bottom=3,\n",
    "        datum_depth=8400,\n",
    "        control_value=5000,  # 5000 bbl/d injection\n",
    "        injection_fluid='WATER'\n",
    "    ),\n",
    "    Well(\n",
    "        name='PROD1',\n",
    "        well_type=WellType.PRODUCER,\n",
    "        i=1, j=1,  # Corner 1\n",
    "        k_top=1, k_bottom=3,\n",
    "        datum_depth=8400,\n",
    "        control_mode=ControlMode.ORAT,\n",
    "        control_value=1500,\n",
    "        bhp_limit=1000\n",
    "    ),\n",
    "    Well(\n",
    "        name='PROD2',\n",
    "        well_type=WellType.PRODUCER,\n",
    "        i=10, j=1,  # Corner 2\n",
    "        k_top=1, k_bottom=3,\n",
    "        datum_depth=8400,\n",
    "        control_mode=ControlMode.ORAT,\n",
    "        control_value=1500,\n",
    "        bhp_limit=1000\n",
    "    ),\n",
    "    Well(\n",
    "        name='PROD3',\n",
    "        well_type=WellType.PRODUCER,\n",
    "        i=1, j=10,  # Corner 3\n",
    "        k_top=1, k_bottom=3,\n",
    "        datum_depth=8400,\n",
    "        control_mode=ControlMode.ORAT,\n",
    "        control_value=1500,\n",
    "        bhp_limit=1000\n",
    "    ),\n",
    "    Well(\n",
    "        name='PROD4',\n",
    "        well_type=WellType.PRODUCER,\n",
    "        i=10, j=10,  # Corner 4\n",
    "        k_top=1, k_bottom=3,\n",
    "        datum_depth=8400,\n",
    "        control_mode=ControlMode.ORAT,\n",
    "        control_value=1500,\n",
    "        bhp_limit=1000\n",
    "    ),\n",
    "]\n",
    "\n",
    "schedule = generate_schedule_section(wells, total_days=1825, timestep_days=30)\n",
    "print(schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Complete Deck Assembly\n",
    "\n",
    "Now let's put it all together into a complete, runnable deck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_complete_deck(\n",
    "    title: str,\n",
    "    nx: int, ny: int, nz: int,\n",
    "    dx: float, dy: float, dz: List[float],\n",
    "    top_depth: float,\n",
    "    datum_pressure: float,\n",
    "    woc_depth: float,\n",
    "    permx: float, poro: float,\n",
    "    wells: List[Well],\n",
    "    total_days: int,\n",
    "    unit_system: str = 'FIELD',\n",
    "    phases: List[str] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a complete ECLIPSE simulation deck.\n",
    "    \n",
    "    This is CLARISSA's main deck generation entry point.\n",
    "    \"\"\"\n",
    "    if phases is None:\n",
    "        phases = ['OIL', 'WATER']\n",
    "    \n",
    "    lines = [\n",
    "        \"-- \" + \"=\"*60,\n",
    "        f\"-- {title}\",\n",
    "        \"-- Generated by CLARISSA\",\n",
    "        f\"-- Date: 2025-01-18\",\n",
    "        \"-- \" + \"=\"*60,\n",
    "        \"\",\n",
    "        \"-- \" + \"-\"*60,\n",
    "        \"-- RUNSPEC SECTION\",\n",
    "        \"-- \" + \"-\"*60,\n",
    "        \"RUNSPEC\",\n",
    "        \"\",\n",
    "        \"TITLE\",\n",
    "        title,\n",
    "        \"\",\n",
    "        \"DIMENS\",\n",
    "        f\"  {nx}  {ny}  {nz} /\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    # Phases\n",
    "    for phase in phases:\n",
    "        lines.append(phase)\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # Units\n",
    "    lines.append(unit_system)\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    lines.extend([\n",
    "        \"START\",\n",
    "        \"  1 'JAN' 2025 /\",\n",
    "        \"\",\n",
    "        \"-- \" + \"-\"*60,\n",
    "        \"-- GRID SECTION\", \n",
    "        \"-- \" + \"-\"*60,\n",
    "    ])\n",
    "    \n",
    "    # Add GRID section\n",
    "    lines.append(generate_grid_section(\n",
    "        nx, ny, nz, dx, dy, dz, top_depth, permx, poro\n",
    "    ))\n",
    "    \n",
    "    # PROPS section\n",
    "    lines.extend([\n",
    "        \"-- \" + \"-\"*60,\n",
    "        \"-- PROPS SECTION\",\n",
    "        \"-- \" + \"-\"*60,\n",
    "        \"PROPS\",\n",
    "        \"\"\n",
    "    ])\n",
    "    \n",
    "    lines.append(generate_pvt_section(phases, unit_system))\n",
    "    lines.append(generate_swof_table())\n",
    "    \n",
    "    # SOLUTION section\n",
    "    lines.extend([\n",
    "        \"-- \" + \"-\"*60,\n",
    "        \"-- SOLUTION SECTION\",\n",
    "        \"-- \" + \"-\"*60,\n",
    "    ])\n",
    "    \n",
    "    equil = EquilData(\n",
    "        datum_depth=top_depth + sum(dz)/2,  # Mid-reservoir\n",
    "        datum_pressure=datum_pressure,\n",
    "        woc_depth=woc_depth\n",
    "    )\n",
    "    lines.append(generate_solution_section(equil))\n",
    "    \n",
    "    # SUMMARY section\n",
    "    lines.extend([\n",
    "        \"-- \" + \"-\"*60,\n",
    "        \"-- SUMMARY SECTION\",\n",
    "        \"-- \" + \"-\"*60,\n",
    "        \"SUMMARY\",\n",
    "        \"\",\n",
    "        \"-- Field totals\",\n",
    "        \"FOPR\",  # Field oil production rate\n",
    "        \"FWPR\",  # Field water production rate\n",
    "        \"FOPT\",  # Field oil production total\n",
    "        \"FWPT\",  # Field water production total\n",
    "        \"FWIR\",  # Field water injection rate\n",
    "        \"FWIT\",  # Field water injection total\n",
    "        \"FPR\",   # Field pressure\n",
    "        \"\",\n",
    "        \"-- Well data\",\n",
    "        \"WOPR\",  # Well oil production rate\n",
    "        \"/\",\n",
    "        \"WWPR\",  # Well water production rate\n",
    "        \"/\",\n",
    "        \"WBHP\",  # Well bottom hole pressure\n",
    "        \"/\",\n",
    "        \"\",\n",
    "    ])\n",
    "    \n",
    "    # SCHEDULE section\n",
    "    lines.extend([\n",
    "        \"-- \" + \"-\"*60,\n",
    "        \"-- SCHEDULE SECTION\",\n",
    "        \"-- \" + \"-\"*60,\n",
    "    ])\n",
    "    \n",
    "    lines.append(generate_schedule_section(wells, total_days))\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Generate complete deck\n",
    "complete_deck = generate_complete_deck(\n",
    "    title=\"5-Spot Waterflood - CLARISSA Demo\",\n",
    "    nx=10, ny=10, nz=3,\n",
    "    dx=300, dy=300, dz=[20, 30, 50],\n",
    "    top_depth=8325,\n",
    "    datum_pressure=4000,\n",
    "    woc_depth=8500,\n",
    "    permx=500, poro=0.2,\n",
    "    wells=wells,\n",
    "    total_days=1825\n",
    ")\n",
    "\n",
    "print(complete_deck[:3000])  # First 3000 chars\n",
    "print(\"\\n... [truncated] ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the deck to a file\n",
    "deck_path = \"../data/sample_decks/CLARISSA_DEMO.DATA\"\n",
    "\n",
    "import os\n",
    "os.makedirs(os.path.dirname(deck_path), exist_ok=True)\n",
    "\n",
    "with open(deck_path, 'w') as f:\n",
    "    f.write(complete_deck)\n",
    "\n",
    "print(f\"Deck saved to {deck_path}\")\n",
    "print(f\"Total lines: {len(complete_deck.splitlines())}\")\n",
    "print(f\"Total size: {len(complete_deck)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. OPM Flow Compatibility\n",
    "\n",
    "Not all ECLIPSE keywords are supported by OPM Flow. CLARISSA must track compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPM Flow keyword compatibility database\n",
    "OPM_KEYWORD_SUPPORT = {\n",
    "    # RUNSPEC\n",
    "    'DIMENS': {'supported': True, 'notes': ''},\n",
    "    'OIL': {'supported': True, 'notes': ''},\n",
    "    'WATER': {'supported': True, 'notes': ''},\n",
    "    'GAS': {'supported': True, 'notes': ''},\n",
    "    'DISGAS': {'supported': True, 'notes': ''},\n",
    "    'VAPOIL': {'supported': True, 'notes': ''},\n",
    "    'METRIC': {'supported': True, 'notes': ''},\n",
    "    'FIELD': {'supported': True, 'notes': ''},\n",
    "    \n",
    "    # GRID\n",
    "    'DX': {'supported': True, 'notes': ''},\n",
    "    'DY': {'supported': True, 'notes': ''},\n",
    "    'DZ': {'supported': True, 'notes': ''},\n",
    "    'TOPS': {'supported': True, 'notes': ''},\n",
    "    'PERMX': {'supported': True, 'notes': ''},\n",
    "    'PERMY': {'supported': True, 'notes': ''},\n",
    "    'PERMZ': {'supported': True, 'notes': ''},\n",
    "    'PORO': {'supported': True, 'notes': ''},\n",
    "    'NTG': {'supported': True, 'notes': ''},\n",
    "    'COORD': {'supported': True, 'notes': 'Corner-point grids'},\n",
    "    'ZCORN': {'supported': True, 'notes': 'Corner-point grids'},\n",
    "    \n",
    "    # PROPS\n",
    "    'PVTO': {'supported': True, 'notes': ''},\n",
    "    'PVDO': {'supported': True, 'notes': ''},\n",
    "    'PVTW': {'supported': True, 'notes': ''},\n",
    "    'PVDG': {'supported': True, 'notes': ''},\n",
    "    'SWOF': {'supported': True, 'notes': ''},\n",
    "    'SGOF': {'supported': True, 'notes': ''},\n",
    "    'ROCK': {'supported': True, 'notes': ''},\n",
    "    'DENSITY': {'supported': True, 'notes': ''},\n",
    "    \n",
    "    # SOLUTION\n",
    "    'EQUIL': {'supported': True, 'notes': ''},\n",
    "    'RPTRST': {'supported': True, 'notes': ''},\n",
    "    \n",
    "    # SCHEDULE\n",
    "    'WELSPECS': {'supported': True, 'notes': ''},\n",
    "    'COMPDAT': {'supported': True, 'notes': ''},\n",
    "    'WCONPROD': {'supported': True, 'notes': ''},\n",
    "    'WCONINJE': {'supported': True, 'notes': ''},\n",
    "    'TSTEP': {'supported': True, 'notes': ''},\n",
    "    'DATES': {'supported': True, 'notes': ''},\n",
    "    \n",
    "    # Partially supported or unsupported\n",
    "    'COMPS': {'supported': False, 'notes': 'Compositional not fully supported'},\n",
    "    'EOS': {'supported': False, 'notes': 'Compositional not fully supported'},\n",
    "    'THERMAL': {'supported': False, 'notes': 'Thermal simulation not supported'},\n",
    "    'POLYMER': {'supported': True, 'notes': 'Basic polymer flooding supported'},\n",
    "    'AQUIFER': {'supported': True, 'notes': 'Analytical aquifers supported'},\n",
    "}\n",
    "\n",
    "def check_opm_compatibility(deck_content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Check deck for OPM Flow compatibility.\n",
    "    \n",
    "    Returns dict with supported, unsupported, and unknown keywords.\n",
    "    \"\"\"\n",
    "    # Extract all keywords from deck\n",
    "    keyword_pattern = r'^([A-Z]{2,10})\\s*$'\n",
    "    \n",
    "    keywords_found = set()\n",
    "    for line in deck_content.split('\\n'):\n",
    "        line = line.split('--')[0].strip()\n",
    "        match = re.match(keyword_pattern, line)\n",
    "        if match:\n",
    "            keywords_found.add(match.group(1))\n",
    "    \n",
    "    supported = []\n",
    "    unsupported = []\n",
    "    unknown = []\n",
    "    \n",
    "    for kw in keywords_found:\n",
    "        if kw in OPM_KEYWORD_SUPPORT:\n",
    "            if OPM_KEYWORD_SUPPORT[kw]['supported']:\n",
    "                supported.append(kw)\n",
    "            else:\n",
    "                unsupported.append((kw, OPM_KEYWORD_SUPPORT[kw]['notes']))\n",
    "        else:\n",
    "            unknown.append(kw)\n",
    "    \n",
    "    return {\n",
    "        'supported': sorted(supported),\n",
    "        'unsupported': unsupported,\n",
    "        'unknown': sorted(unknown),\n",
    "        'compatible': len(unsupported) == 0\n",
    "    }\n",
    "\n",
    "# Check our generated deck\n",
    "compatibility = check_opm_compatibility(complete_deck)\n",
    "print(f\"OPM Flow Compatible: {compatibility['compatible']}\")\n",
    "print(f\"Supported keywords: {compatibility['supported']}\")\n",
    "print(f\"Unsupported: {compatibility['unsupported']}\")\n",
    "print(f\"Unknown: {compatibility['unknown']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Key Points for CLARISSA\n",
    "\n",
    "### What CLARISSA Must Know\n",
    "\n",
    "1. **Section ordering is mandatory** - RUNSPEC â†’ GRID â†’ PROPS â†’ SOLUTION â†’ SUMMARY â†’ SCHEDULE\n",
    "\n",
    "2. **Keyword syntax** - Records terminated by `/`, keywords in ALL CAPS\n",
    "\n",
    "3. **Data validation** - Array sizes must match grid dimensions\n",
    "\n",
    "4. **Physical plausibility** - Pressures, saturations, contacts must be sensible\n",
    "\n",
    "5. **OPM compatibility** - Track which keywords are supported\n",
    "\n",
    "### Next Notebook\n",
    "\n",
    "In **02_OPM_Flow_Integration.ipynb**, we'll cover:\n",
    "- Running OPM Flow in Docker\n",
    "- Parsing simulation results\n",
    "- Error handling and recovery\n",
    "- Integration with CLARISSA's simulation layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
