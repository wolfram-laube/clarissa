{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLARISSA Tutorial 01: ECLIPSE Deck Fundamentals\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand ECLIPSE deck structure and section ordering\n",
    "- Parse and validate keyword syntax\n",
    "- Generate syntactically correct deck sections\n",
    "- Check OPM Flow compatibility\n",
    "\n",
    "**Prerequisites:** Basic Python knowledge, familiarity with reservoir simulation concepts\n",
    "\n",
    "**Estimated Time:** 45 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLARISSA System Architecture\n",
    "\n",
    "CLARISSA is a 6-layer system that translates natural language into executable simulation decks:\n",
    "\n",
    "| Layer | Function |\n",
    "|-------|----------|\n",
    "| User Interface | Voice, Text, Web, API inputs |\n",
    "| Translation | NL Parser, Confidence Scoring, Rollback |\n",
    "| Knowledge | Vector Store, Corrections DB, Analog Database |\n",
    "| Core | LLM (Planning), RL Agent, Neuro-Symbolic Constraints |\n",
    "| Validation | Syntax, Semantic, Physics checks |\n",
    "| Simulation | OPM Flow, Eclipse Export, Result Parser |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Deck?\n",
    "\n",
    "A **deck** (historically called a \"card deck\" from punch card days) is a structured text file that defines:\n",
    "\n",
    "- **What** to simulate (fluid system, rock properties)\n",
    "- **Where** (grid geometry, regions)\n",
    "- **When** (schedule of operations)\n",
    "- **How** (numerical controls, output requests)\n",
    "\n",
    "ECLIPSE decks follow a strict section ordering that we must understand to generate valid input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Deck Structure and Section Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import re\n",
    "\n",
    "class DeckSection(Enum):\n",
    "    \"\"\"ECLIPSE deck sections in required order.\"\"\"\n",
    "    RUNSPEC = auto()    # Run specification - dimensions, phases, features\n",
    "    GRID = auto()       # Grid geometry and properties\n",
    "    EDIT = auto()       # Grid property modifications (optional)\n",
    "    PROPS = auto()      # Rock and fluid properties\n",
    "    REGIONS = auto()    # Region definitions (optional)\n",
    "    SOLUTION = auto()   # Initial conditions\n",
    "    SUMMARY = auto()    # Output requests (optional)\n",
    "    SCHEDULE = auto()   # Well operations and time stepping\n",
    "\n",
    "# Valid section transitions\n",
    "SECTION_ORDER = list(DeckSection)\n",
    "print(f\"Valid section order: {' -> '.join(s.name for s in SECTION_ORDER)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_section_order(sections: List[DeckSection]) -> Tuple[bool, Optional[str]]:\n",
    "    \"\"\"Validate that sections appear in correct order.\n",
    "    \n",
    "    Args:\n",
    "        sections: List of sections in order they appear\n",
    "        \n",
    "    Returns:\n",
    "        (is_valid, error_message)\n",
    "    \"\"\"\n",
    "    if not sections:\n",
    "        return False, \"No sections found\"\n",
    "    \n",
    "    # Check required sections\n",
    "    required = {DeckSection.RUNSPEC, DeckSection.GRID, DeckSection.PROPS, \n",
    "                DeckSection.SOLUTION, DeckSection.SCHEDULE}\n",
    "    missing = required - set(sections)\n",
    "    if missing:\n",
    "        return False, f\"Missing required sections: {[s.name for s in missing]}\"\n",
    "    \n",
    "    # Check order\n",
    "    section_indices = {s: i for i, s in enumerate(SECTION_ORDER)}\n",
    "    prev_idx = -1\n",
    "    for section in sections:\n",
    "        curr_idx = section_indices[section]\n",
    "        if curr_idx < prev_idx:\n",
    "            return False, f\"{section.name} appears after a later section\"\n",
    "        prev_idx = curr_idx\n",
    "    \n",
    "    return True, None\n",
    "\n",
    "# Test with valid order\n",
    "valid_sections = [DeckSection.RUNSPEC, DeckSection.GRID, DeckSection.PROPS, \n",
    "                  DeckSection.SOLUTION, DeckSection.SCHEDULE]\n",
    "is_valid, error = validate_section_order(valid_sections)\n",
    "print(f\"Valid deck: {is_valid}\")\n",
    "\n",
    "# Test with invalid order\n",
    "invalid_sections = [DeckSection.GRID, DeckSection.RUNSPEC, DeckSection.PROPS, \n",
    "                    DeckSection.SOLUTION, DeckSection.SCHEDULE]\n",
    "is_valid, error = validate_section_order(invalid_sections)\n",
    "print(f\"Invalid deck: {is_valid}, Error: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Keyword Syntax Parsing\n",
    "\n",
    "ECLIPSE keywords follow specific syntax rules:\n",
    "\n",
    "- Keywords are uppercase, max 8 characters\n",
    "- Data records follow the keyword\n",
    "- Records end with `/`\n",
    "- `*` means repeat, `1*` means use default\n",
    "- `--` indicates comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class KeywordRecord:\n",
    "    \"\"\"A single record within an ECLIPSE keyword.\"\"\"\n",
    "    values: List[str]\n",
    "    \n",
    "    def expand_repeats(self) -> List[str]:\n",
    "        \"\"\"Expand repeat notation (e.g., '3*0.25' -> ['0.25', '0.25', '0.25']).\"\"\"\n",
    "        expanded = []\n",
    "        for val in self.values:\n",
    "            if '*' in val and not val.startswith('1*'):\n",
    "                parts = val.split('*')\n",
    "                if len(parts) == 2 and parts[0].isdigit():\n",
    "                    count = int(parts[0])\n",
    "                    expanded.extend([parts[1]] * count)\n",
    "                else:\n",
    "                    expanded.append(val)\n",
    "            else:\n",
    "                expanded.append(val)\n",
    "        return expanded\n",
    "\n",
    "@dataclass\n",
    "class Keyword:\n",
    "    \"\"\"An ECLIPSE keyword with its data records.\"\"\"\n",
    "    name: str\n",
    "    records: List[KeywordRecord] = field(default_factory=list)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        lines = [self.name]\n",
    "        for record in self.records:\n",
    "            lines.append('  ' + ' '.join(record.values) + ' /')\n",
    "        lines.append('/')\n",
    "        return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_keyword_block(text: str) -> List[Keyword]:\n",
    "    \"\"\"Parse ECLIPSE keyword blocks from text.\"\"\"\n",
    "    keywords = []\n",
    "    lines = text.strip().split('\\n')\n",
    "    \n",
    "    current_keyword = None\n",
    "    current_records = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Remove comments\n",
    "        if '--' in line:\n",
    "            line = line[:line.index('--')]\n",
    "        line = line.strip()\n",
    "        \n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # Check for keyword (uppercase, starts at beginning)\n",
    "        if line.isupper() and not any(c.isdigit() for c in line.split()[0]):\n",
    "            if current_keyword:\n",
    "                keywords.append(Keyword(current_keyword, current_records))\n",
    "            current_keyword = line.split()[0]\n",
    "            current_records = []\n",
    "            # Check for inline data\n",
    "            if len(line.split()) > 1:\n",
    "                data = line.split()[1:]\n",
    "                if data[-1] == '/':\n",
    "                    current_records.append(KeywordRecord(data[:-1]))\n",
    "        elif line == '/':\n",
    "            if current_keyword:\n",
    "                keywords.append(Keyword(current_keyword, current_records))\n",
    "                current_keyword = None\n",
    "                current_records = []\n",
    "        elif line.endswith('/'):\n",
    "            values = line[:-1].strip().split()\n",
    "            if values:\n",
    "                current_records.append(KeywordRecord(values))\n",
    "    \n",
    "    if current_keyword:\n",
    "        keywords.append(Keyword(current_keyword, current_records))\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "# Test parsing\n",
    "test_block = '''\n",
    "WELSPECS\n",
    "  PROD1 G1 10 10 8335 OIL /\n",
    "  INJ1  G1 1  1  8335 WATER /\n",
    "/\n",
    "\n",
    "COMPDAT\n",
    "  PROD1 10 10 1 5 OPEN 1* 0.5 /\n",
    "/\n",
    "'''\n",
    "\n",
    "keywords = parse_keyword_block(test_block)\n",
    "for kw in keywords:\n",
    "    print(f\"Keyword: {kw.name}\")\n",
    "    for rec in kw.records:\n",
    "        print(f\"  Record: {rec.values}\")\n",
    "        print(f\"  Expanded: {rec.expand_repeats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Deck Generation\n",
    "\n",
    "Now let's build functions to generate valid deck sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RunspecData:\n",
    "    \"\"\"Data for RUNSPEC section.\"\"\"\n",
    "    title: str = \"CLARISSA Generated Model\"\n",
    "    nx: int = 10\n",
    "    ny: int = 10\n",
    "    nz: int = 5\n",
    "    phases: List[str] = field(default_factory=lambda: ['OIL', 'WATER', 'GAS'])\n",
    "    metric: bool = False\n",
    "\n",
    "def generate_runspec(data: RunspecData) -> str:\n",
    "    \"\"\"Generate RUNSPEC section.\"\"\"\n",
    "    lines = [\n",
    "        \"RUNSPEC\",\n",
    "        \"\",\n",
    "        f\"TITLE\",\n",
    "        f\"{data.title}\",\n",
    "        \"\",\n",
    "        \"-- Phases\",\n",
    "    ]\n",
    "    \n",
    "    for phase in data.phases:\n",
    "        lines.append(phase)\n",
    "    \n",
    "    lines.extend([\n",
    "        \"\",\n",
    "        \"-- Units\",\n",
    "        \"METRIC\" if data.metric else \"FIELD\",\n",
    "        \"\",\n",
    "        \"-- Grid dimensions\",\n",
    "        \"DIMENS\",\n",
    "        f\"  {data.nx} {data.ny} {data.nz} /\",\n",
    "        \"\"\n",
    "    ])\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Test RUNSPEC generation\n",
    "runspec_data = RunspecData(title=\"5-Spot Waterflood\", nx=20, ny=20, nz=5)\n",
    "print(generate_runspec(runspec_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GridData:\n",
    "    \"\"\"Data for GRID section.\"\"\"\n",
    "    dx: float = 100.0  # ft or m\n",
    "    dy: float = 100.0\n",
    "    dz: float = 20.0\n",
    "    tops: float = 8000.0  # Top depth\n",
    "    poro: float = 0.2\n",
    "    permx: float = 100.0  # mD\n",
    "    permy: float = 100.0\n",
    "    permz: float = 10.0\n",
    "    nx: int = 10\n",
    "    ny: int = 10\n",
    "    nz: int = 5\n",
    "\n",
    "def generate_grid(data: GridData) -> str:\n",
    "    \"\"\"Generate GRID section with Cartesian grid.\"\"\"\n",
    "    total_cells = data.nx * data.ny * data.nz\n",
    "    top_cells = data.nx * data.ny\n",
    "    \n",
    "    lines = [\n",
    "        \"GRID\",\n",
    "        \"\",\n",
    "        \"-- Cell dimensions\",\n",
    "        \"DX\",\n",
    "        f\"  {total_cells}*{data.dx} /\",\n",
    "        \"DY\",\n",
    "        f\"  {total_cells}*{data.dy} /\",\n",
    "        \"DZ\",\n",
    "        f\"  {total_cells}*{data.dz} /\",\n",
    "        \"\",\n",
    "        \"-- Top depth (first layer only)\",\n",
    "        \"TOPS\",\n",
    "        f\"  {top_cells}*{data.tops} /\",\n",
    "        \"\",\n",
    "        \"-- Porosity\",\n",
    "        \"PORO\",\n",
    "        f\"  {total_cells}*{data.poro} /\",\n",
    "        \"\",\n",
    "        \"-- Permeability\",\n",
    "        \"PERMX\",\n",
    "        f\"  {total_cells}*{data.permx} /\",\n",
    "        \"PERMY\",\n",
    "        f\"  {total_cells}*{data.permy} /\",\n",
    "        \"PERMZ\",\n",
    "        f\"  {total_cells}*{data.permz} /\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Test GRID generation\n",
    "grid_data = GridData(nx=20, ny=20, nz=5, permx=150.0)\n",
    "print(generate_grid(grid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_props() -> str:\n",
    "    \"\"\"Generate PROPS section with standard black oil properties.\"\"\"\n",
    "    return '''PROPS\n",
    "\n",
    "-- Water-Oil relative permeability\n",
    "SWOF\n",
    "-- Sw    Krw      Krow     Pcow\n",
    "   0.20  0.0000   1.0000   0.0\n",
    "   0.30  0.0200   0.6000   0.0\n",
    "   0.40  0.0500   0.3500   0.0\n",
    "   0.50  0.1000   0.2000   0.0\n",
    "   0.60  0.2000   0.0900   0.0\n",
    "   0.70  0.3500   0.0200   0.0\n",
    "   0.80  0.5000   0.0000   0.0\n",
    "/\n",
    "\n",
    "-- PVT data\n",
    "PVTW\n",
    "-- Pref   Bw       Cw         Vw       Cv\n",
    "   4000   1.012    3.0E-6     0.5      0.0 /\n",
    "\n",
    "PVDO\n",
    "-- P       Bo        Vo\n",
    "   1000    1.200     2.5\n",
    "   2000    1.150     2.0\n",
    "   3000    1.100     1.5\n",
    "   4000    1.050     1.2\n",
    "   5000    1.020     1.0\n",
    "/\n",
    "\n",
    "ROCK\n",
    "-- Pref  Cr\n",
    "   4000  3.0E-6 /\n",
    "\n",
    "DENSITY\n",
    "-- Oil    Water   Gas\n",
    "   45.0   64.0    0.06 /\n",
    "'''\n",
    "\n",
    "print(generate_props())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EquilData:\n",
    "    \"\"\"Data for equilibration.\"\"\"\n",
    "    datum_depth: float = 8000.0\n",
    "    datum_pressure: float = 4000.0\n",
    "    woc_depth: float = 9000.0  # Water-oil contact\n",
    "    goc_depth: float = 7000.0  # Gas-oil contact (above reservoir)\n",
    "\n",
    "def generate_solution(data: EquilData) -> str:\n",
    "    \"\"\"Generate SOLUTION section.\"\"\"\n",
    "    return f'''SOLUTION\n",
    "\n",
    "EQUIL\n",
    "-- Datum   Pres    WOC     Pcow  GOC     Pcog  Init\n",
    "   {data.datum_depth}  {data.datum_pressure}  {data.woc_depth}  0  {data.goc_depth}  0  1 /\n",
    "'''\n",
    "\n",
    "equil_data = EquilData(datum_depth=8500, datum_pressure=3800)\n",
    "print(generate_solution(equil_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Well:\n",
    "    \"\"\"Well specification.\"\"\"\n",
    "    name: str\n",
    "    i: int  # I-location\n",
    "    j: int  # J-location\n",
    "    k1: int = 1  # Top completion\n",
    "    k2: int = 5  # Bottom completion\n",
    "    well_type: str = \"PROD\"  # PROD or INJ\n",
    "    phase: str = \"OIL\"  # OIL, WATER, GAS\n",
    "    rate: float = 1000.0  # STB/D or MSCF/D\n",
    "    bhp_limit: float = 1000.0  # psi\n",
    "\n",
    "def generate_schedule(wells: List[Well], end_time: int = 365) -> str:\n",
    "    \"\"\"Generate SCHEDULE section.\"\"\"\n",
    "    lines = [\"SCHEDULE\", \"\"]\n",
    "    \n",
    "    # Well specifications\n",
    "    lines.append(\"WELSPECS\")\n",
    "    for w in wells:\n",
    "        group = \"G1\"\n",
    "        lines.append(f\"  {w.name:8} {group} {w.i:3} {w.j:3} 1* {w.phase} /\")\n",
    "    lines.extend([\"/\", \"\"])\n",
    "    \n",
    "    # Completions\n",
    "    lines.append(\"COMPDAT\")\n",
    "    for w in wells:\n",
    "        lines.append(f\"  {w.name:8} {w.i:3} {w.j:3} {w.k1:3} {w.k2:3} OPEN 1* 0.5 /\")\n",
    "    lines.extend([\"/\", \"\"])\n",
    "    \n",
    "    # Production controls\n",
    "    producers = [w for w in wells if w.well_type == \"PROD\"]\n",
    "    if producers:\n",
    "        lines.append(\"WCONPROD\")\n",
    "        for w in producers:\n",
    "            lines.append(f\"  {w.name:8} OPEN ORAT {w.rate:.0f} 4* {w.bhp_limit:.0f} /\")\n",
    "        lines.extend([\"/\", \"\"])\n",
    "    \n",
    "    # Injection controls\n",
    "    injectors = [w for w in wells if w.well_type == \"INJ\"]\n",
    "    if injectors:\n",
    "        lines.append(\"WCONINJE\")\n",
    "        for w in injectors:\n",
    "            lines.append(f\"  {w.name:8} {w.phase} OPEN RATE {w.rate:.0f} 1* 5000 /\")\n",
    "        lines.extend([\"/\", \"\"])\n",
    "    \n",
    "    # Time steps\n",
    "    lines.append(\"TSTEP\")\n",
    "    lines.append(f\"  {end_time}*1 /\")\n",
    "    lines.extend([\"\", \"END\"])\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Create 5-spot pattern\n",
    "wells = [\n",
    "    Well(\"PROD1\", 10, 10, well_type=\"PROD\", rate=500),\n",
    "    Well(\"INJ1\", 1, 1, well_type=\"INJ\", phase=\"WATER\", rate=600),\n",
    "    Well(\"INJ2\", 1, 20, well_type=\"INJ\", phase=\"WATER\", rate=600),\n",
    "    Well(\"INJ3\", 20, 1, well_type=\"INJ\", phase=\"WATER\", rate=600),\n",
    "    Well(\"INJ4\", 20, 20, well_type=\"INJ\", phase=\"WATER\", rate=600),\n",
    "]\n",
    "print(generate_schedule(wells, end_time=730))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Complete Deck Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_complete_deck(\n",
    "    runspec: RunspecData,\n",
    "    grid: GridData,\n",
    "    equil: EquilData,\n",
    "    wells: List[Well],\n",
    "    simulation_days: int = 365\n",
    ") -> str:\n",
    "    \"\"\"Generate a complete ECLIPSE deck.\"\"\"\n",
    "    sections = [\n",
    "        generate_runspec(runspec),\n",
    "        generate_grid(grid),\n",
    "        generate_props(),\n",
    "        generate_solution(equil),\n",
    "        generate_schedule(wells, simulation_days)\n",
    "    ]\n",
    "    return \"\\n\".join(sections)\n",
    "\n",
    "# Generate complete deck\n",
    "runspec = RunspecData(title=\"5-Spot Waterflood Tutorial\", nx=20, ny=20, nz=5)\n",
    "grid = GridData(nx=20, ny=20, nz=5, permx=150, tops=8500)\n",
    "equil = EquilData(datum_depth=8500, datum_pressure=3800)\n",
    "\n",
    "complete_deck = generate_complete_deck(runspec, grid, equil, wells, 730)\n",
    "print(f\"Generated deck: {len(complete_deck)} characters\")\n",
    "print(\"\\n--- First 2000 characters ---\")\n",
    "print(complete_deck[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: OPM Flow Compatibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords supported by OPM Flow (subset)\n",
    "OPM_SUPPORTED_KEYWORDS = {\n",
    "    'RUNSPEC': {'TITLE', 'DIMENS', 'OIL', 'WATER', 'GAS', 'FIELD', 'METRIC', 'START'},\n",
    "    'GRID': {'DX', 'DY', 'DZ', 'TOPS', 'PORO', 'PERMX', 'PERMY', 'PERMZ', 'NTG', 'ACTNUM'},\n",
    "    'PROPS': {'SWOF', 'SGOF', 'PVTW', 'PVDO', 'PVDG', 'ROCK', 'DENSITY'},\n",
    "    'SOLUTION': {'EQUIL', 'PRESSURE', 'SWAT'},\n",
    "    'SCHEDULE': {'WELSPECS', 'COMPDAT', 'WCONPROD', 'WCONINJE', 'TSTEP', 'END'}\n",
    "}\n",
    "\n",
    "def check_opm_compatibility(deck_text: str) -> List[str]:\n",
    "    \"\"\"Check deck for OPM Flow compatibility.\n",
    "    \n",
    "    Returns list of warnings for unsupported keywords.\n",
    "    \"\"\"\n",
    "    warnings = []\n",
    "    current_section = None\n",
    "    \n",
    "    all_supported = set()\n",
    "    for kws in OPM_SUPPORTED_KEYWORDS.values():\n",
    "        all_supported.update(kws)\n",
    "    \n",
    "    for line in deck_text.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('--'):\n",
    "            continue\n",
    "        \n",
    "        # Check for section headers\n",
    "        word = line.split()[0].upper()\n",
    "        if word in OPM_SUPPORTED_KEYWORDS:\n",
    "            current_section = word\n",
    "        elif word.isupper() and len(word) <= 8 and word not in all_supported:\n",
    "            if not any(c in word for c in ['/', '*', '.']):\n",
    "                warnings.append(f\"Unsupported keyword: {word}\")\n",
    "    \n",
    "    return warnings\n",
    "\n",
    "# Test compatibility\n",
    "warnings = check_opm_compatibility(complete_deck)\n",
    "if warnings:\n",
    "    print(\"Compatibility warnings:\")\n",
    "    for w in warnings:\n",
    "        print(f\"  - {w}\")\n",
    "else:\n",
    "    print(\"Deck is OPM Flow compatible!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned:\n",
    "\n",
    "1. **Deck Structure**: ECLIPSE decks have a strict section order (RUNSPEC -> GRID -> PROPS -> SOLUTION -> SCHEDULE)\n",
    "2. **Keyword Syntax**: Keywords are uppercase, data ends with `/`, `*` for repeats\n",
    "3. **Validation**: We can validate section ordering and keyword syntax programmatically\n",
    "4. **Generation**: CLARISSA generates each section from structured data\n",
    "5. **OPM Compatibility**: We check for keywords supported by the open-source simulator\n",
    "\n",
    "**Next Tutorial**: [02_OPM_Flow_Integration.ipynb](02_OPM_Flow_Integration.ipynb) - Running simulations with OPM Flow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}