{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé§ CLARISSA Voice Input Showcase\n",
    "\n",
    "**Talk to Your Reservoir Simulation**\n",
    "\n",
    "This notebook demonstrates CLARISSA's voice interface - control reservoir simulations through natural speech.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wolfram-laube/clarissa/blob/main/docs/tutorials/notebooks/16_Voice_Input_Showcase.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Speech-to-Text** - Convert voice to text with Whisper\n",
    "2. **Intent Recognition** - Parse commands into structured intents\n",
    "3. **Command Execution** - Trigger visualizations by voice\n",
    "4. **Full Pipeline** - End-to-end voice control demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openai plotly numpy ipywidgets\n",
    "\n",
    "# For local Whisper (optional - skip if using API)\n",
    "# !pip install -q faster-whisper\n",
    "\n",
    "print(\"‚úÖ Packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Any, Optional, List\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML, Audio\n",
    "import ipywidgets as widgets\n",
    "\n",
    "print(\"‚úÖ Imports ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key Setup\n",
    "# Option 1: Set directly (not recommended for shared notebooks)\n",
    "# os.environ['OPENAI_API_KEY'] = 'sk-...'\n",
    "\n",
    "# Option 2: Colab secrets (recommended)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"‚úÖ API key loaded from Colab secrets\")\n",
    "except:\n",
    "    if os.getenv('OPENAI_API_KEY'):\n",
    "        print(\"‚úÖ API key found in environment\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No API key found - text-only mode available\")\n",
    "        print(\"   Set OPENAI_API_KEY for full voice functionality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Core Voice Components\n",
    "\n",
    "These are simplified versions of the full CLARISSA voice module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intent Types\n",
    "class IntentType(Enum):\n",
    "    VISUALIZE_PROPERTY = \"visualize_property\"\n",
    "    QUERY_VALUE = \"query_value\"\n",
    "    NAVIGATE = \"navigate\"\n",
    "    HELP = \"help\"\n",
    "    CANCEL = \"cancel\"\n",
    "    CONFIRM = \"confirm\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "@dataclass\n",
    "class Intent:\n",
    "    \"\"\"Parsed intent from voice command.\"\"\"\n",
    "    type: IntentType\n",
    "    confidence: float\n",
    "    slots: Dict[str, Any] = field(default_factory=dict)\n",
    "    raw_text: str = \"\"\n",
    "\n",
    "@dataclass \n",
    "class VoiceResponse:\n",
    "    \"\"\"Response to voice command.\"\"\"\n",
    "    success: bool\n",
    "    text: str\n",
    "    intent: Optional[Intent] = None\n",
    "    visualization: Optional[go.Figure] = None\n",
    "\n",
    "print(\"‚úÖ Data classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain vocabulary for better recognition\n",
    "DOMAIN_VOCABULARY = \"\"\"\n",
    "Reservoir simulation terms: permeability, porosity, water saturation, \n",
    "oil saturation, pressure, BHP, bottomhole pressure, OOIP,\n",
    "waterflood, injector, producer, PROD1, INJ1, INJ2, INJ3, INJ4,\n",
    "millidarcy, mD, psi, bbl/day, STB, FOPT, FOPR, FWPT, FWPR, FWCT,\n",
    "water cut, layer, grid, cell, timestep, 3D, cross-section, animation\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìö Domain vocabulary loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Speech-to-Text (Whisper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Transcribe audio file using OpenAI Whisper API.\n",
    "    \n",
    "    Args:\n",
    "        audio_path: Path to audio file (WAV, MP3, etc.)\n",
    "        \n",
    "    Returns:\n",
    "        Transcribed text\n",
    "    \"\"\"\n",
    "    import openai\n",
    "    \n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    with open(audio_path, 'rb') as audio_file:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "            prompt=DOMAIN_VOCABULARY,\n",
    "            language=\"en\"\n",
    "        )\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "print(\"üé§ Whisper transcription function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Intent Parser (LLM-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTENT_PROMPT = \"\"\"\n",
    "You are a reservoir simulation assistant. Parse the user's voice command into a structured intent.\n",
    "\n",
    "Available intents:\n",
    "- visualize_property: Show reservoir properties (permeability, porosity, saturation, pressure)\n",
    "- query_value: Ask about simulation values (rates, pressures, water cut, cumulative production)\n",
    "- navigate: Go to different sections (results, sensitivity, model)\n",
    "- help: Ask for help or guidance\n",
    "- cancel: Stop or cancel current action\n",
    "\n",
    "Slots to extract:\n",
    "- property: permeability, porosity, water_saturation, oil_saturation, pressure\n",
    "- layer: integer (1-5 typically)\n",
    "- time_days: integer (simulation day)\n",
    "- view_type: 3d, cross_section_xy, cross_section_xz, animation\n",
    "- well: PROD1, INJ1, INJ2, INJ3, INJ4\n",
    "- target: results, sensitivity, model, export\n",
    "\n",
    "User said: \"{text}\"\n",
    "\n",
    "Respond with ONLY valid JSON (no markdown, no explanation):\n",
    "{{\"intent\": \"<type>\", \"confidence\": <0.0-1.0>, \"slots\": {{...}}}}\n",
    "\"\"\"\n",
    "\n",
    "def parse_intent(text: str) -> Intent:\n",
    "    \"\"\"\n",
    "    Parse text into structured intent using LLM.\n",
    "    \n",
    "    Args:\n",
    "        text: Transcribed voice command\n",
    "        \n",
    "    Returns:\n",
    "        Parsed Intent object\n",
    "    \"\"\"\n",
    "    # Quick pattern matching for simple commands\n",
    "    text_lower = text.lower().strip()\n",
    "    \n",
    "    if text_lower in [\"stop\", \"cancel\", \"never mind\", \"abort\"]:\n",
    "        return Intent(IntentType.CANCEL, 1.0, {}, text)\n",
    "    \n",
    "    if text_lower in [\"yes\", \"yeah\", \"yep\", \"confirm\", \"ok\", \"okay\", \"do it\"]:\n",
    "        return Intent(IntentType.CONFIRM, 1.0, {}, text)\n",
    "    \n",
    "    if text_lower == \"help\" or text_lower.startswith(\"what can\"):\n",
    "        return Intent(IntentType.HELP, 1.0, {}, text)\n",
    "    \n",
    "    # LLM parsing for complex commands\n",
    "    try:\n",
    "        import openai\n",
    "        client = openai.OpenAI()\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You parse voice commands into JSON. Respond with ONLY valid JSON.\"},\n",
    "                {\"role\": \"user\", \"content\": INTENT_PROMPT.format(text=text)}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        \n",
    "        result_text = response.choices[0].message.content.strip()\n",
    "        # Clean up potential markdown\n",
    "        if result_text.startswith(\"```\"):\n",
    "            result_text = result_text.split(\"```\")[1]\n",
    "            if result_text.startswith(\"json\"):\n",
    "                result_text = result_text[4:]\n",
    "        \n",
    "        data = json.loads(result_text)\n",
    "        \n",
    "        intent_type = IntentType(data.get(\"intent\", \"unknown\"))\n",
    "        confidence = float(data.get(\"confidence\", 0.5))\n",
    "        slots = data.get(\"slots\", {})\n",
    "        \n",
    "        return Intent(intent_type, confidence, slots, text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Parse error: {e}\")\n",
    "        return Intent(IntentType.UNKNOWN, 0.0, {}, text)\n",
    "\n",
    "print(\"üß† Intent parser ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Visualization Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic reservoir data for demo\n",
    "NX, NY, NZ = 10, 10, 5\n",
    "\n",
    "def generate_demo_data():\n",
    "    \"\"\"Generate synthetic reservoir properties.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Permeability with channel\n",
    "    perm = np.random.lognormal(mean=4.5, sigma=0.5, size=(NX, NY, NZ))\n",
    "    perm[3:7, :, :] *= 3  # High-perm channel\n",
    "    \n",
    "    # Porosity correlated with perm\n",
    "    poro = 0.15 + 0.1 * (np.log(perm) - 4) / 2\n",
    "    poro = np.clip(poro, 0.05, 0.35)\n",
    "    \n",
    "    # Water saturation (varies with time)\n",
    "    def get_saturation(time_days):\n",
    "        progress = min(time_days / 1800, 1.0)\n",
    "        sw = np.ones((NX, NY, NZ)) * 0.2  # Connate water\n",
    "        # Water front moving from injectors\n",
    "        for i in range(NX):\n",
    "            for j in range(NY):\n",
    "                dist = np.sqrt((i - NX//2)**2 + (j - NY//2)**2)\n",
    "                if dist < progress * NX * 0.7:\n",
    "                    sw[i, j, :] = 0.2 + 0.5 * (1 - dist / (NX * 0.7))\n",
    "        return np.clip(sw, 0.2, 0.8)\n",
    "    \n",
    "    return {\n",
    "        'permeability': perm,\n",
    "        'porosity': poro,\n",
    "        'get_saturation': get_saturation\n",
    "    }\n",
    "\n",
    "DEMO_DATA = generate_demo_data()\n",
    "print(\"üìä Demo data generated\")\n",
    "print(f\"   Grid: {NX}√ó{NY}√ó{NZ} = {NX*NY*NZ} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_visualization(prop_name: str, prop_data: np.ndarray) -> go.Figure:\n",
    "    \"\"\"Create 3D scatter plot of property.\"\"\"\n",
    "    x, y, z = [], [], []\n",
    "    values = []\n",
    "    \n",
    "    for i in range(NX):\n",
    "        for j in range(NY):\n",
    "            for k in range(NZ):\n",
    "                x.append(i)\n",
    "                y.append(j)\n",
    "                z.append(k)\n",
    "                values.append(prop_data[i, j, k])\n",
    "    \n",
    "    fig = go.Figure(data=go.Scatter3d(\n",
    "        x=x, y=y, z=z,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color=values,\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title=prop_name.title()),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"3D {prop_name.title()} Distribution\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\",\n",
    "            yaxis_title=\"Y\", \n",
    "            zaxis_title=\"Layer\",\n",
    "            aspectmode='cube'\n",
    "        ),\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_cross_section(prop_name: str, prop_data: np.ndarray, layer: int) -> go.Figure:\n",
    "    \"\"\"Create 2D heatmap cross-section.\"\"\"\n",
    "    layer_idx = max(0, min(layer - 1, NZ - 1))\n",
    "    data_2d = prop_data[:, :, layer_idx]\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=data_2d.T,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title=prop_name.title())\n",
    "    ))\n",
    "    \n",
    "    # Add well markers\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[NX//2], y=[NY//2],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=15, color='blue', symbol='circle'),\n",
    "        text=['PROD1'], textposition='top center',\n",
    "        name='Producer'\n",
    "    ))\n",
    "    \n",
    "    # Injectors at corners\n",
    "    inj_x = [1, 1, NX-2, NX-2]\n",
    "    inj_y = [1, NY-2, 1, NY-2]\n",
    "    inj_names = ['INJ1', 'INJ2', 'INJ3', 'INJ4']\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=inj_x, y=inj_y,\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=12, color='red', symbol='triangle-up'),\n",
    "        text=inj_names, textposition='top center',\n",
    "        name='Injectors'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"{prop_name.title()} at Layer {layer}\",\n",
    "        xaxis_title=\"X\",\n",
    "        yaxis_title=\"Y\",\n",
    "        height=450\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "print(\"üé® Visualization functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Command Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_intent(intent: Intent) -> VoiceResponse:\n",
    "    \"\"\"\n",
    "    Execute parsed intent and return response.\n",
    "    \n",
    "    Args:\n",
    "        intent: Parsed Intent object\n",
    "        \n",
    "    Returns:\n",
    "        VoiceResponse with text and optional visualization\n",
    "    \"\"\"\n",
    "    slots = intent.slots\n",
    "    \n",
    "    if intent.type == IntentType.VISUALIZE_PROPERTY:\n",
    "        prop = slots.get('property', 'permeability')\n",
    "        layer = slots.get('layer')\n",
    "        time_days = slots.get('time_days', 500)\n",
    "        view_type = slots.get('view_type', '3d')\n",
    "        \n",
    "        # Get property data\n",
    "        if 'saturation' in prop or prop == 'sw':\n",
    "            prop_data = DEMO_DATA['get_saturation'](time_days)\n",
    "            prop_name = 'water_saturation'\n",
    "        elif prop in ['permeability', 'perm']:\n",
    "            prop_data = DEMO_DATA['permeability']\n",
    "            prop_name = 'permeability'\n",
    "        elif prop in ['porosity', 'poro']:\n",
    "            prop_data = DEMO_DATA['porosity']\n",
    "            prop_name = 'porosity'\n",
    "        else:\n",
    "            prop_data = DEMO_DATA['permeability']\n",
    "            prop_name = 'permeability'\n",
    "        \n",
    "        # Create visualization\n",
    "        if layer or 'cross' in str(view_type):\n",
    "            layer = layer or 3\n",
    "            fig = create_cross_section(prop_name, prop_data, layer)\n",
    "            text = f\"Showing {prop_name.replace('_', ' ')} at layer {layer}.\"\n",
    "        else:\n",
    "            fig = create_3d_visualization(prop_name, prop_data)\n",
    "            text = f\"Showing {prop_name.replace('_', ' ')} in 3D.\"\n",
    "        \n",
    "        return VoiceResponse(True, text, intent, fig)\n",
    "    \n",
    "    elif intent.type == IntentType.QUERY_VALUE:\n",
    "        prop = slots.get('property', 'oil_rate')\n",
    "        \n",
    "        # Simulate query results\n",
    "        values = {\n",
    "            'oil_rate': ('1,250', 'bbl/day'),\n",
    "            'water_rate': ('450', 'bbl/day'),\n",
    "            'water_cut': ('26', '%'),\n",
    "            'pressure': ('3,450', 'psi'),\n",
    "            'bhp': ('3,450', 'psi'),\n",
    "            'cumulative_oil': ('2.3', 'MMSTB'),\n",
    "            'fopt': ('2.3', 'MMSTB'),\n",
    "        }\n",
    "        \n",
    "        prop_key = prop.lower().replace(' ', '_')\n",
    "        if prop_key in values:\n",
    "            val, unit = values[prop_key]\n",
    "            text = f\"The {prop.replace('_', ' ')} is {val} {unit}.\"\n",
    "        else:\n",
    "            text = f\"I don't have data for {prop}.\"\n",
    "        \n",
    "        return VoiceResponse(True, text, intent)\n",
    "    \n",
    "    elif intent.type == IntentType.HELP:\n",
    "        text = \"\"\"You can say things like:\n",
    "‚Ä¢ \"Show me the permeability\"\n",
    "‚Ä¢ \"Show layer 3\"\n",
    "‚Ä¢ \"What's the oil rate?\"\n",
    "‚Ä¢ \"Show saturation at day 500\"\n",
    "‚Ä¢ \"Stop\" or \"Cancel\" to abort\"\"\"\n",
    "        return VoiceResponse(True, text, intent)\n",
    "    \n",
    "    elif intent.type == IntentType.CANCEL:\n",
    "        return VoiceResponse(True, \"Cancelled.\", intent)\n",
    "    \n",
    "    elif intent.type == IntentType.CONFIRM:\n",
    "        return VoiceResponse(True, \"Confirmed.\", intent)\n",
    "    \n",
    "    else:\n",
    "        return VoiceResponse(\n",
    "            False, \n",
    "            \"I didn't understand that. Try saying 'help' for available commands.\",\n",
    "            intent\n",
    "        )\n",
    "\n",
    "print(\"‚ö° Command executor ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Voice Pipeline\n",
    "\n",
    "The complete voice processing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_voice_command(text_or_audio: str, is_audio: bool = False) -> VoiceResponse:\n",
    "    \"\"\"\n",
    "    Complete voice command processing pipeline.\n",
    "    \n",
    "    Args:\n",
    "        text_or_audio: Either text command or path to audio file\n",
    "        is_audio: True if input is audio file path\n",
    "        \n",
    "    Returns:\n",
    "        VoiceResponse with result\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    # Step 1: Transcribe if audio\n",
    "    if is_audio:\n",
    "        print(\"üé§ Step 1: Transcribing audio...\")\n",
    "        try:\n",
    "            text = transcribe_audio(text_or_audio)\n",
    "            print(f\"   Transcription: \\\"{text}\\\"\")\n",
    "        except Exception as e:\n",
    "            return VoiceResponse(False, f\"Transcription failed: {e}\")\n",
    "    else:\n",
    "        text = text_or_audio\n",
    "        print(f\"üìù Input: \\\"{text}\\\"\")\n",
    "    \n",
    "    # Step 2: Parse intent\n",
    "    print(\"\\nüß† Step 2: Parsing intent...\")\n",
    "    intent = parse_intent(text)\n",
    "    print(f\"   Intent: {intent.type.value}\")\n",
    "    print(f\"   Confidence: {intent.confidence:.0%}\")\n",
    "    if intent.slots:\n",
    "        print(f\"   Slots: {intent.slots}\")\n",
    "    \n",
    "    # Step 3: Execute\n",
    "    print(\"\\n‚ö° Step 3: Executing command...\")\n",
    "    response = execute_intent(intent)\n",
    "    \n",
    "    # Step 4: Response\n",
    "    print(f\"\\nüí¨ Response: {response.text}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"üöÄ Voice pipeline ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Interactive Demo\n",
    "\n",
    "Try voice commands! (Text mode - type what you would say)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: Show permeability in 3D\n",
    "response = process_voice_command(\"show me the permeability\")\n",
    "if response.visualization:\n",
    "    response.visualization.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 2: Cross-section at specific layer\n",
    "response = process_voice_command(\"show layer 3\")\n",
    "if response.visualization:\n",
    "    response.visualization.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: Query a value\n",
    "response = process_voice_command(\"what is the water cut?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 4: Show saturation at specific time\n",
    "response = process_voice_command(\"show water saturation at day 1000\")\n",
    "if response.visualization:\n",
    "    response.visualization.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 5: Help command\n",
    "response = process_voice_command(\"help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Interactive Widget\n",
    "\n",
    "Try your own commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widget\n",
    "text_input = widgets.Text(\n",
    "    placeholder='Type a command (e.g., \"show porosity in 3D\")',\n",
    "    description='üé§ Say:',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_submit(change):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if text_input.value:\n",
    "            response = process_voice_command(text_input.value)\n",
    "            if response.visualization:\n",
    "                display(response.visualization)\n",
    "\n",
    "text_input.on_submit(lambda x: on_submit(x))\n",
    "\n",
    "submit_btn = widgets.Button(description=\"Process\", button_style='primary')\n",
    "submit_btn.on_click(lambda x: on_submit(x))\n",
    "\n",
    "display(widgets.HBox([text_input, submit_btn]))\n",
    "display(output)\n",
    "\n",
    "print(\"\\nüí° Type a command and press Enter or click Process\")\n",
    "print(\"\\nExample commands:\")\n",
    "print('  ‚Ä¢ \"show me porosity\"')\n",
    "print('  ‚Ä¢ \"show saturation at layer 2\"')\n",
    "print('  ‚Ä¢ \"what is the oil rate\"')\n",
    "print('  ‚Ä¢ \"help\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Audio File Demo\n",
    "\n",
    "Upload an audio file to test real speech-to-text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File upload widget\n",
    "from google.colab import files\n",
    "\n",
    "def process_uploaded_audio():\n",
    "    \"\"\"Upload and process an audio file.\"\"\"\n",
    "    print(\"üìÅ Upload an audio file (WAV, MP3, M4A)...\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    for filename in uploaded.keys():\n",
    "        print(f\"\\nüéµ Processing: {filename}\")\n",
    "        response = process_voice_command(filename, is_audio=True)\n",
    "        \n",
    "        if response.visualization:\n",
    "            display(response.visualization)\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Uncomment to test with audio upload:\n",
    "# process_uploaded_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Test Suite\n",
    "\n",
    "Evaluate intent recognition accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "TEST_CASES = [\n",
    "    (\"show me the permeability\", \"visualize_property\", {\"property\": \"permeability\"}),\n",
    "    (\"display porosity in 3D\", \"visualize_property\", {\"property\": \"porosity\"}),\n",
    "    (\"show layer 3\", \"visualize_property\", {\"layer\": 3}),\n",
    "    (\"what is the oil rate\", \"query_value\", {\"property\": \"oil_rate\"}),\n",
    "    (\"what's the water cut\", \"query_value\", {\"property\": \"water_cut\"}),\n",
    "    (\"help\", \"help\", {}),\n",
    "    (\"stop\", \"cancel\", {}),\n",
    "    (\"yes\", \"confirm\", {}),\n",
    "]\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"Run test suite and report accuracy.\"\"\"\n",
    "    print(\"üß™ Running intent recognition tests...\\n\")\n",
    "    \n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for text, expected_intent, expected_slots in TEST_CASES:\n",
    "        intent = parse_intent(text)\n",
    "        \n",
    "        intent_match = intent.type.value == expected_intent\n",
    "        \n",
    "        if intent_match:\n",
    "            passed += 1\n",
    "            status = \"‚úÖ\"\n",
    "        else:\n",
    "            failed += 1\n",
    "            status = \"‚ùå\"\n",
    "        \n",
    "        print(f\"{status} \\\"{text}\\\"\")\n",
    "        print(f\"   Expected: {expected_intent}, Got: {intent.type.value}\")\n",
    "        if not intent_match:\n",
    "            print(f\"   Confidence: {intent.confidence:.0%}\")\n",
    "        print()\n",
    "    \n",
    "    total = passed + failed\n",
    "    accuracy = passed / total * 100 if total > 0 else 0\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(f\"üìä Results: {passed}/{total} passed ({accuracy:.0f}% accuracy)\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Uncomment to run tests (requires API key):\n",
    "# run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Speech-to-Text** - Whisper API transcription with domain vocabulary\n",
    "2. **Intent Parsing** - LLM-based command understanding\n",
    "3. **Slot Extraction** - Property, layer, time parameters\n",
    "4. **Visualization** - 3D and cross-section views triggered by voice\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Full Integration**: Connect to OPM Flow simulations\n",
    "- **Live Microphone**: Browser-based audio capture\n",
    "- **TTS Response**: Audio feedback with OpenAI TTS\n",
    "- **Offline Mode**: Local Whisper for air-gapped deployments\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Voice Input Tutorial](../guides/voice-input-tutorial.md)\n",
    "- [ADR-028: Voice Architecture](../../architecture/adr/ADR-028-voice-input-architecture.md)\n",
    "- [CLARISSA Source Code](https://gitlab.com/wolfram_laube/blauweiss_llc/clarissa)\n",
    "\n",
    "---\n",
    "\n",
    "*Part of CLARISSA - Conversational Language Agent for Reservoir Simulation*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
