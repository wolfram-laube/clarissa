{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6cCX74Durw6"
   },
   "source": [
    "# \ud83c\udfa4 CLARISSA Voice Input Showcase\n",
    "\n",
    "**Talk to Your Reservoir Simulation**\n",
    "\n",
    "This notebook demonstrates CLARISSA's voice interface - control reservoir simulations through natural speech.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wolfram-laube/clarissa/blob/main/docs/tutorials/notebooks/16_Voice_Input_Showcase.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Speech-to-Text** - Convert voice to text with Whisper\n",
    "2. **Intent Recognition** - Parse commands into structured intents\n",
    "3. **Command Execution** - Trigger visualizations by voice\n",
    "4. **Full Pipeline** - End-to-end voice control demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cH96bsanurw7"
   },
   "source": [
    "## 1\ufe0f\u20e3 Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwuM5Ff1urw7"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openai anthropic plotly numpy ipywidgets\n",
    "\n",
    "# For local Whisper (optional - skip if using API)\n",
    "# !pip install -q faster-whisper\n",
    "\n",
    "print(\"\u2705 Packages installed (OpenAI + Anthropic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9Nk8_z_urw8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Any, Optional, List\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML, Audio\n",
    "import ipywidgets as widgets\n",
    "\n",
    "print(\"\u2705 Imports ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDEnpG83urw8"
   },
   "outputs": [],
   "source": [
    "# API Key Setup - Choose your LLM provider\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# CLARISSA supports both OpenAI and Anthropic (Claude) for intent parsing.\n",
    "# Whisper (OpenAI) is always used for speech-to-text.\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "# Option 1: Colab secrets (recommended)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "\n",
    "    # Try Anthropic first (CLARISSA's native LLM)\n",
    "    try:\n",
    "        os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
    "        print(\"\u2705 Anthropic API key loaded (Claude)\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Also try OpenAI (for Whisper STT + optional intent parsing)\n",
    "    try:\n",
    "        os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "        print(\"\u2705 OpenAI API key loaded (Whisper STT)\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Check what's available\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print()\n",
    "print(\"\u2550\" * 50)\n",
    "print(\"LLM Configuration:\")\n",
    "print(\"\u2550\" * 50)\n",
    "\n",
    "if anthropic_key:\n",
    "    print(\"\ud83d\udfe2 Claude (Anthropic): Available - will use for intent parsing\")\n",
    "    LLM_PROVIDER = \"anthropic\"\n",
    "elif openai_key:\n",
    "    print(\"\ud83d\udfe2 GPT-4 (OpenAI): Available - will use for intent parsing\")\n",
    "    LLM_PROVIDER = \"openai\"\n",
    "else:\n",
    "    print(\"\ud83d\udfe1 No LLM API key - using rule-based parsing only\")\n",
    "    print(\"   (Works for common commands, limited for complex queries)\")\n",
    "    LLM_PROVIDER = \"rules\"\n",
    "\n",
    "if openai_key:\n",
    "    print(\"\ud83d\udfe2 Whisper STT: Available\")\n",
    "else:\n",
    "    print(\"\ud83d\udfe1 Whisper STT: Not available (no OpenAI key)\")\n",
    "    print(\"   (Text input mode only)\")\n",
    "\n",
    "print(\"\u2550\" * 50)\n",
    "print()\n",
    "print(\"\ud83d\udca1 To add API keys in Colab:\")\n",
    "print(\"   1. Click \ud83d\udd11 Secrets (left sidebar)\")\n",
    "print(\"   2. Add: ANTHROPIC_API_KEY and/or OPENAI_API_KEY\")\n",
    "print(\"   3. Enable notebook access\")\n",
    "print(\"   4. Restart runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB2r3EQsurw9"
   },
   "source": [
    "## 2\ufe0f\u20e3 Core Voice Components\n",
    "\n",
    "These are simplified versions of the full CLARISSA voice module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCBiFiWIurw9"
   },
   "outputs": [],
   "source": [
    "# Intent Types\n",
    "class IntentType(Enum):\n",
    "    VISUALIZE_PROPERTY = \"visualize_property\"\n",
    "    QUERY_VALUE = \"query_value\"\n",
    "    NAVIGATE = \"navigate\"\n",
    "    HELP = \"help\"\n",
    "    CANCEL = \"cancel\"\n",
    "    CONFIRM = \"confirm\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "@dataclass\n",
    "class Intent:\n",
    "    \"\"\"Parsed intent from voice command.\"\"\"\n",
    "    type: IntentType\n",
    "    confidence: float\n",
    "    slots: Dict[str, Any] = field(default_factory=dict)\n",
    "    raw_text: str = \"\"\n",
    "\n",
    "@dataclass\n",
    "class VoiceResponse:\n",
    "    \"\"\"Response to voice command.\"\"\"\n",
    "    success: bool\n",
    "    text: str\n",
    "    intent: Optional[Intent] = None\n",
    "    visualization: Optional[go.Figure] = None\n",
    "\n",
    "print(\"\u2705 Data classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmVKdD62urw-"
   },
   "outputs": [],
   "source": [
    "# Domain vocabulary for better recognition\n",
    "DOMAIN_VOCABULARY = \"\"\"\n",
    "Reservoir simulation terms: permeability, porosity, water saturation,\n",
    "oil saturation, pressure, BHP, bottomhole pressure, OOIP,\n",
    "waterflood, injector, producer, PROD1, INJ1, INJ2, INJ3, INJ4,\n",
    "millidarcy, mD, psi, bbl/day, STB, FOPT, FOPR, FWPT, FWPR, FWCT,\n",
    "water cut, layer, grid, cell, timestep, 3D, cross-section, animation\n",
    "\"\"\"\n",
    "\n",
    "print(\"\ud83d\udcda Domain vocabulary loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFR6mzl0urw-"
   },
   "source": [
    "### 2.1 Speech-to-Text (Whisper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAkU8o8curw-"
   },
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Transcribe audio file using OpenAI Whisper API.\n",
    "\n",
    "    Args:\n",
    "        audio_path: Path to audio file (WAV, MP3, etc.)\n",
    "\n",
    "    Returns:\n",
    "        Transcribed text\n",
    "    \"\"\"\n",
    "    import openai\n",
    "\n",
    "    client = openai.OpenAI()\n",
    "\n",
    "    with open(audio_path, 'rb') as audio_file:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "            prompt=DOMAIN_VOCABULARY,\n",
    "            language=\"en\"\n",
    "        )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "print(\"\ud83c\udfa4 Whisper transcription function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OjhhUU8urw-"
   },
   "source": [
    "### 2.2 Intent Parser (LLM-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgU53_lTurw_"
   },
   "outputs": [],
   "source": [
    "INTENT_PROMPT = \"\"\"You are a reservoir simulation assistant. Parse the user's voice command into a structured intent.\n",
    "\n",
    "Available intents:\n",
    "- visualize_property: Show reservoir properties (permeability, porosity, saturation, pressure)\n",
    "- query_value: Ask about simulation values (rates, pressures, water cut, cumulative production)\n",
    "- navigate: Go to different sections (results, sensitivity, model)\n",
    "- help: Ask for help or guidance\n",
    "- cancel: Stop or cancel current action\n",
    "- confirm: Confirm a pending action\n",
    "\n",
    "Slots to extract:\n",
    "- property: permeability, porosity, water_saturation, oil_saturation, pressure\n",
    "- layer: integer (1-5 typically)\n",
    "- time_days: integer (simulation day)\n",
    "- view_type: 3d, cross_section_xy, cross_section_xz, animation\n",
    "- well: PROD1, INJ1, INJ2, INJ3, INJ4\n",
    "- target: results, sensitivity, model, export\n",
    "\n",
    "User said: \"{text}\"\n",
    "\n",
    "Respond with ONLY valid JSON (no markdown, no explanation):\n",
    "{{\"intent\": \"<type>\", \"confidence\": <0.0-1.0>, \"slots\": {{...}}}}\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_intent_rules(text: str) -> Intent:\n",
    "    \"\"\"Rule-based intent parsing - works WITHOUT API key.\"\"\"\n",
    "    text_lower = text.lower().strip()\n",
    "    slots = {}\n",
    "\n",
    "    # Cancel / Confirm / Help\n",
    "    if text_lower in [\"stop\", \"cancel\", \"never mind\", \"abort\", \"quit\"]:\n",
    "        return Intent(IntentType.CANCEL, 1.0, {}, text)\n",
    "    if text_lower in [\"yes\", \"yeah\", \"yep\", \"confirm\", \"ok\", \"okay\", \"do it\", \"go ahead\"]:\n",
    "        return Intent(IntentType.CONFIRM, 1.0, {}, text)\n",
    "    if text_lower == \"help\" or \"what can\" in text_lower:\n",
    "        return Intent(IntentType.HELP, 1.0, {}, text)\n",
    "\n",
    "    # Visualization\n",
    "    viz_keywords = [\"show\", \"display\", \"visualize\", \"plot\", \"view\", \"see\"]\n",
    "    if any(kw in text_lower for kw in viz_keywords):\n",
    "        if \"perm\" in text_lower: slots[\"property\"] = \"permeability\"\n",
    "        elif \"poro\" in text_lower: slots[\"property\"] = \"porosity\"\n",
    "        elif \"saturation\" in text_lower or \" sw\" in text_lower: slots[\"property\"] = \"water_saturation\"\n",
    "        elif \"pressure\" in text_lower: slots[\"property\"] = \"pressure\"\n",
    "\n",
    "        layer_match = re.search(r'layer\\s*(\\d+)', text_lower)\n",
    "        if layer_match: slots[\"layer\"] = int(layer_match.group(1))\n",
    "\n",
    "        time_match = re.search(r'(?:day|time)\\s*(\\d+)', text_lower)\n",
    "        if time_match: slots[\"time_days\"] = int(time_match.group(1))\n",
    "\n",
    "        if not slots.get(\"property\") and not slots.get(\"layer\"):\n",
    "            slots[\"property\"] = \"permeability\"\n",
    "\n",
    "        return Intent(IntentType.VISUALIZE_PROPERTY, 0.95, slots, text)\n",
    "\n",
    "    # Query\n",
    "    if any(kw in text_lower for kw in [\"what\", \"how much\", \"tell me\"]):\n",
    "        if \"oil rate\" in text_lower: slots[\"property\"] = \"oil_rate\"\n",
    "        elif \"water cut\" in text_lower: slots[\"property\"] = \"water_cut\"\n",
    "        elif \"water rate\" in text_lower: slots[\"property\"] = \"water_rate\"\n",
    "        elif \"pressure\" in text_lower: slots[\"property\"] = \"pressure\"\n",
    "        if slots:\n",
    "            return Intent(IntentType.QUERY_VALUE, 0.9, slots, text)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_with_claude(text: str) -> Intent:\n",
    "    \"\"\"Parse intent using Claude (Anthropic).\"\"\"\n",
    "    import anthropic\n",
    "    client = anthropic.Anthropic()\n",
    "\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=200,\n",
    "        messages=[{\"role\": \"user\", \"content\": INTENT_PROMPT.format(text=text)}]\n",
    "    )\n",
    "\n",
    "    result_text = response.content[0].text.strip()\n",
    "    if result_text.startswith(\"```\"):\n",
    "        result_text = result_text.split(\"```\")[1].replace(\"json\", \"\", 1)\n",
    "\n",
    "    data = json.loads(result_text)\n",
    "    return Intent(\n",
    "        IntentType(data.get(\"intent\", \"unknown\")),\n",
    "        float(data.get(\"confidence\", 0.8)),\n",
    "        data.get(\"slots\", {}),\n",
    "        text\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_with_openai(text: str) -> Intent:\n",
    "    \"\"\"Parse intent using GPT-4 (OpenAI).\"\"\"\n",
    "    import openai\n",
    "    client = openai.OpenAI()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Parse voice commands into JSON. Respond with ONLY valid JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": INTENT_PROMPT.format(text=text)}\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    result_text = response.choices[0].message.content.strip()\n",
    "    if result_text.startswith(\"```\"):\n",
    "        result_text = result_text.split(\"```\")[1].replace(\"json\", \"\", 1)\n",
    "\n",
    "    data = json.loads(result_text)\n",
    "    return Intent(\n",
    "        IntentType(data.get(\"intent\", \"unknown\")),\n",
    "        float(data.get(\"confidence\", 0.8)),\n",
    "        data.get(\"slots\", {}),\n",
    "        text\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_intent(text: str) -> Intent:\n",
    "    \"\"\"\n",
    "    Parse text into structured intent.\n",
    "\n",
    "    Priority:\n",
    "    1. Rule-based (instant, no API)\n",
    "    2. Claude (CLARISSA native)\n",
    "    3. OpenAI GPT-4\n",
    "    4. Fallback to unknown\n",
    "    \"\"\"\n",
    "    # Try rules first\n",
    "    rule_result = parse_intent_rules(text)\n",
    "    if rule_result is not None:\n",
    "        print(f\"   \ud83d\udccb Parsed with rules\")\n",
    "        return rule_result\n",
    "\n",
    "    # Try Claude (CLARISSA's native LLM)\n",
    "    if os.getenv('ANTHROPIC_API_KEY'):\n",
    "        try:\n",
    "            result = parse_with_claude(text)\n",
    "            print(f\"   \ud83e\udd16 Parsed with Claude\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"   \u26a0\ufe0f Claude error: {e}\")\n",
    "\n",
    "    # Try OpenAI\n",
    "    if os.getenv('OPENAI_API_KEY'):\n",
    "        try:\n",
    "            result = parse_with_openai(text)\n",
    "            print(f\"   \ud83e\udd16 Parsed with GPT-4\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"   \u26a0\ufe0f OpenAI error: {e}\")\n",
    "\n",
    "    # No LLM available\n",
    "    print(f\"   \u2139\ufe0f No LLM available for complex command\")\n",
    "    return Intent(IntentType.UNKNOWN, 0.0, {}, text)\n",
    "\n",
    "print(\"\ud83e\udde0 Intent parser ready\")\n",
    "print(\"   Priority: Rules \u2192 Claude \u2192 GPT-4 \u2192 Fallback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHNW0YAAurw_"
   },
   "source": [
    "### 2.3 Visualization Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i80CKwUnurw_"
   },
   "outputs": [],
   "source": [
    "# Create synthetic reservoir data for demo\n",
    "NX, NY, NZ = 10, 10, 5\n",
    "\n",
    "def generate_demo_data():\n",
    "    \"\"\"Generate synthetic reservoir properties.\"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Permeability with channel\n",
    "    perm = np.random.lognormal(mean=4.5, sigma=0.5, size=(NX, NY, NZ))\n",
    "    perm[3:7, :, :] *= 3  # High-perm channel\n",
    "\n",
    "    # Porosity correlated with perm\n",
    "    poro = 0.15 + 0.1 * (np.log(perm) - 4) / 2\n",
    "    poro = np.clip(poro, 0.05, 0.35)\n",
    "\n",
    "    # Water saturation (varies with time)\n",
    "    def get_saturation(time_days):\n",
    "        progress = min(time_days / 1800, 1.0)\n",
    "        sw = np.ones((NX, NY, NZ)) * 0.2  # Connate water\n",
    "        # Water front moving from injectors\n",
    "        for i in range(NX):\n",
    "            for j in range(NY):\n",
    "                dist = np.sqrt((i - NX//2)**2 + (j - NY//2)**2)\n",
    "                if dist < progress * NX * 0.7:\n",
    "                    sw[i, j, :] = 0.2 + 0.5 * (1 - dist / (NX * 0.7))\n",
    "        return np.clip(sw, 0.2, 0.8)\n",
    "\n",
    "    return {\n",
    "        'permeability': perm,\n",
    "        'porosity': poro,\n",
    "        'get_saturation': get_saturation\n",
    "    }\n",
    "\n",
    "DEMO_DATA = generate_demo_data()\n",
    "print(\"\ud83d\udcca Demo data generated\")\n",
    "print(f\"   Grid: {NX}\u00d7{NY}\u00d7{NZ} = {NX*NY*NZ} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CECGcZnurxA"
   },
   "outputs": [],
   "source": [
    "def create_3d_visualization(prop_name: str, prop_data: np.ndarray) -> go.Figure:\n",
    "    \"\"\"Create 3D scatter plot of property.\"\"\"\n",
    "    x, y, z = [], [], []\n",
    "    values = []\n",
    "\n",
    "    for i in range(NX):\n",
    "        for j in range(NY):\n",
    "            for k in range(NZ):\n",
    "                x.append(i)\n",
    "                y.append(j)\n",
    "                z.append(k)\n",
    "                values.append(prop_data[i, j, k])\n",
    "\n",
    "    fig = go.Figure(data=go.Scatter3d(\n",
    "        x=x, y=y, z=z,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color=values,\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title=prop_name.title()),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"3D {prop_name.title()} Distribution\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\",\n",
    "            yaxis_title=\"Y\",\n",
    "            zaxis_title=\"Layer\",\n",
    "            aspectmode='cube'\n",
    "        ),\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "def create_cross_section(prop_name: str, prop_data: np.ndarray, layer: int) -> go.Figure:\n",
    "    \"\"\"Create 2D heatmap cross-section.\"\"\"\n",
    "    layer_idx = max(0, min(layer - 1, NZ - 1))\n",
    "    data_2d = prop_data[:, :, layer_idx]\n",
    "\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=data_2d.T,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title=prop_name.title())\n",
    "    ))\n",
    "\n",
    "    # Add well markers\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[NX//2], y=[NY//2],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=15, color='blue', symbol='circle'),\n",
    "        text=['PROD1'], textposition='top center',\n",
    "        name='Producer'\n",
    "    ))\n",
    "\n",
    "    # Injectors at corners\n",
    "    inj_x = [1, 1, NX-2, NX-2]\n",
    "    inj_y = [1, NY-2, 1, NY-2]\n",
    "    inj_names = ['INJ1', 'INJ2', 'INJ3', 'INJ4']\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=inj_x, y=inj_y,\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=12, color='red', symbol='triangle-up'),\n",
    "        text=inj_names, textposition='top center',\n",
    "        name='Injectors'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"{prop_name.title()} at Layer {layer}\",\n",
    "        xaxis_title=\"X\",\n",
    "        yaxis_title=\"Y\",\n",
    "        height=450\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "print(\"\ud83c\udfa8 Visualization functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnjJipOaurxA"
   },
   "source": [
    "### 2.4 Command Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RehSY5zurxA"
   },
   "outputs": [],
   "source": [
    "def execute_intent(intent: Intent) -> VoiceResponse:\n",
    "    \"\"\"\n",
    "    Execute parsed intent and return response.\n",
    "\n",
    "    Args:\n",
    "        intent: Parsed Intent object\n",
    "\n",
    "    Returns:\n",
    "        VoiceResponse with text and optional visualization\n",
    "    \"\"\"\n",
    "    slots = intent.slots\n",
    "\n",
    "    if intent.type == IntentType.VISUALIZE_PROPERTY:\n",
    "        prop = slots.get('property', 'permeability')\n",
    "        layer = slots.get('layer')\n",
    "        time_days = slots.get('time_days', 500)\n",
    "        view_type = slots.get('view_type', '3d')\n",
    "\n",
    "        # Get property data\n",
    "        if 'saturation' in prop or prop == 'sw':\n",
    "            prop_data = DEMO_DATA['get_saturation'](time_days)\n",
    "            prop_name = 'water_saturation'\n",
    "        elif prop in ['permeability', 'perm']:\n",
    "            prop_data = DEMO_DATA['permeability']\n",
    "            prop_name = 'permeability'\n",
    "        elif prop in ['porosity', 'poro']:\n",
    "            prop_data = DEMO_DATA['porosity']\n",
    "            prop_name = 'porosity'\n",
    "        else:\n",
    "            prop_data = DEMO_DATA['permeability']\n",
    "            prop_name = 'permeability'\n",
    "\n",
    "        # Create visualization\n",
    "        if layer or 'cross' in str(view_type):\n",
    "            layer = layer or 3\n",
    "            fig = create_cross_section(prop_name, prop_data, layer)\n",
    "            text = f\"Showing {prop_name.replace('_', ' ')} at layer {layer}.\"\n",
    "        else:\n",
    "            fig = create_3d_visualization(prop_name, prop_data)\n",
    "            text = f\"Showing {prop_name.replace('_', ' ')} in 3D.\"\n",
    "\n",
    "        return VoiceResponse(True, text, intent, fig)\n",
    "\n",
    "    elif intent.type == IntentType.QUERY_VALUE:\n",
    "        prop = slots.get('property', 'oil_rate')\n",
    "\n",
    "        # Simulate query results\n",
    "        values = {\n",
    "            'oil_rate': ('1,250', 'bbl/day'),\n",
    "            'water_rate': ('450', 'bbl/day'),\n",
    "            'water_cut': ('26', '%'),\n",
    "            'pressure': ('3,450', 'psi'),\n",
    "            'bhp': ('3,450', 'psi'),\n",
    "            'cumulative_oil': ('2.3', 'MMSTB'),\n",
    "            'fopt': ('2.3', 'MMSTB'),\n",
    "        }\n",
    "\n",
    "        prop_key = prop.lower().replace(' ', '_')\n",
    "        if prop_key in values:\n",
    "            val, unit = values[prop_key]\n",
    "            text = f\"The {prop.replace('_', ' ')} is {val} {unit}.\"\n",
    "        else:\n",
    "            text = f\"I don't have data for {prop}.\"\n",
    "\n",
    "        return VoiceResponse(True, text, intent)\n",
    "\n",
    "    elif intent.type == IntentType.HELP:\n",
    "        text = \"\"\"You can say things like:\n",
    "\u2022 \"Show me the permeability\"\n",
    "\u2022 \"Show layer 3\"\n",
    "\u2022 \"What's the oil rate?\"\n",
    "\u2022 \"Show saturation at day 500\"\n",
    "\u2022 \"Stop\" or \"Cancel\" to abort\"\"\"\n",
    "        return VoiceResponse(True, text, intent)\n",
    "\n",
    "    elif intent.type == IntentType.CANCEL:\n",
    "        return VoiceResponse(True, \"Cancelled.\", intent)\n",
    "\n",
    "    elif intent.type == IntentType.CONFIRM:\n",
    "        return VoiceResponse(True, \"Confirmed.\", intent)\n",
    "\n",
    "    else:\n",
    "        return VoiceResponse(\n",
    "            False,\n",
    "            \"I didn't understand that. Try saying 'help' for available commands.\",\n",
    "            intent\n",
    "        )\n",
    "\n",
    "print(\"\u26a1 Command executor ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyCIkqSHurxA"
   },
   "source": [
    "## 3\ufe0f\u20e3 Voice Pipeline\n",
    "\n",
    "The complete voice processing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEtGbVCTurxA"
   },
   "outputs": [],
   "source": [
    "def process_voice_command(text_or_audio: str, is_audio: bool = False) -> VoiceResponse:\n",
    "    \"\"\"\n",
    "    Complete voice command processing pipeline.\n",
    "\n",
    "    Args:\n",
    "        text_or_audio: Either text command or path to audio file\n",
    "        is_audio: True if input is audio file path\n",
    "\n",
    "    Returns:\n",
    "        VoiceResponse with result\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "    # Step 1: Transcribe if audio\n",
    "    if is_audio:\n",
    "        print(\"\ud83c\udfa4 Step 1: Transcribing audio...\")\n",
    "        try:\n",
    "            text = transcribe_audio(text_or_audio)\n",
    "            print(f\"   Transcription: \\\"{text}\\\"\")\n",
    "        except Exception as e:\n",
    "            return VoiceResponse(False, f\"Transcription failed: {e}\")\n",
    "    else:\n",
    "        text = text_or_audio\n",
    "        print(f\"\ud83d\udcdd Input: \\\"{text}\\\"\")\n",
    "\n",
    "    # Step 2: Parse intent\n",
    "    print(\"\\n\ud83e\udde0 Step 2: Parsing intent...\")\n",
    "    intent = parse_intent(text)\n",
    "    print(f\"   Intent: {intent.type.value}\")\n",
    "    print(f\"   Confidence: {intent.confidence:.0%}\")\n",
    "    if intent.slots:\n",
    "        print(f\"   Slots: {intent.slots}\")\n",
    "\n",
    "    # Step 3: Execute\n",
    "    print(\"\\n\u26a1 Step 3: Executing command...\")\n",
    "    response = execute_intent(intent)\n",
    "\n",
    "    # Step 4: Response\n",
    "    print(f\"\\n\ud83d\udcac Response: {response.text}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    return response\n",
    "\n",
    "print(\"\ud83d\ude80 Voice pipeline ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUG9dxZPurxB"
   },
   "source": [
    "## 4\ufe0f\u20e3 Interactive Demo\n",
    "\n",
    "Try voice commands! (Text mode - type what you would say)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1sm_soxurxB"
   },
   "outputs": [],
   "source": [
    "# Demo 1: Show permeability in 3D\n",
    "response = process_voice_command(\"show me the permeability\")\n",
    "if response.visualization:\n",
    "    response.visualization.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3K2igmMBurxB"
   },
   "outputs": [],
   "source": [
    "# Demo 2: Cross-section at specific layer\n",
    "response = process_voice_command(\"show layer 3\")\n",
    "if response.visualization:\n",
    "    response.visualization.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VaGfngGurxB"
   },
   "outputs": [],
   "source": [
    "# Demo 3: Query a value\n",
    "response = process_voice_command(\"what is the water cut?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTrsyPQpurxB"
   },
   "outputs": [],
   "source": [
    "# Demo 4: Show saturation at specific time\n",
    "response = process_voice_command(\"show water saturation at day 1000\")\n",
    "if response.visualization:\n",
    "    response.visualization.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNLNjoTvurxB"
   },
   "outputs": [],
   "source": [
    "# Demo 5: Help command\n",
    "response = process_voice_command(\"help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVz3DPi5urxB"
   },
   "source": [
    "## 5\ufe0f\u20e3 Interactive Widget\n",
    "\n",
    "Try your own commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YkAJyRPWurxB"
   },
   "outputs": [],
   "source": [
    "# Create interactive widget\n",
    "text_input = widgets.Text(\n",
    "    placeholder='Type a command (e.g., \"show porosity in 3D\")',\n",
    "    description='\ud83c\udfa4 Say:',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_submit(change):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if text_input.value:\n",
    "            response = process_voice_command(text_input.value)\n",
    "            if response.visualization:\n",
    "                display(response.visualization)\n",
    "\n",
    "text_input.on_submit(lambda x: on_submit(x))\n",
    "\n",
    "submit_btn = widgets.Button(description=\"Process\", button_style='primary')\n",
    "submit_btn.on_click(lambda x: on_submit(x))\n",
    "\n",
    "display(widgets.HBox([text_input, submit_btn]))\n",
    "display(output)\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Type a command and press Enter or click Process\")\n",
    "print(\"\\nExample commands:\")\n",
    "print('  \u2022 \"show me porosity\"')\n",
    "print('  \u2022 \"show saturation at layer 2\"')\n",
    "print('  \u2022 \"what is the oil rate\"')\n",
    "print('  \u2022 \"help\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_zxjPTDurxB"
   },
   "source": [
    "## 6\ufe0f\u20e3 Audio File Demo\n",
    "\n",
    "Upload an audio file to test real speech-to-text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQmkSjYiurxC"
   },
   "outputs": [],
   "source": [
    "# File upload widget\n",
    "from google.colab import files\n",
    "\n",
    "def process_uploaded_audio():\n",
    "    \"\"\"Upload and process an audio file.\"\"\"\n",
    "    print(\"\ud83d\udcc1 Upload an audio file (WAV, MP3, M4A)...\")\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    for filename in uploaded.keys():\n",
    "        print(f\"\\n\ud83c\udfb5 Processing: {filename}\")\n",
    "        response = process_voice_command(filename, is_audio=True)\n",
    "\n",
    "        if response.visualization:\n",
    "            display(response.visualization)\n",
    "\n",
    "        return response\n",
    "\n",
    "# Uncomment to test with audio upload:\n",
    "# process_uploaded_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\ufe0f\u20e3 Interactive Voice Input \ud83c\udfa4\n\n### \u2705 Voice Recording Works in Colab!\n\nUsing `google.colab.output.eval_js()` we can access your microphone directly from Colab. \n\n**How it works:**\n1. Run the cell below\n2. Click **\"Start Recording\"**\n3. **Allow microphone access** when your browser asks\n4. Speak your command (e.g., *\"show me the permeability\"*)\n5. Click **\"Stop & Process\"**\n\n**Example commands to try:**\n- *\"Show me the permeability\"*\n- *\"What is the water cut\"*\n- *\"Display pressure at layer 5\"*\n- *\"Help\"*\n\n> \ud83d\udca1 **Tip:** For Whisper transcription, set `OPENAI_API_KEY`. Without it, the system uses a demo transcript but still tests the intent parser."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# \ud83c\udfa4 VOICE RECORDING - Works in Colab!\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nfrom IPython.display import display, Javascript, HTML, Audio\nfrom google.colab.output import eval_js\nfrom base64 import b64decode\nimport os\n\nRECORD_JS = \"\"\"\nasync function recordAudio() {\n    const div = document.createElement('div');\n    div.style.cssText = 'font-family: -apple-system, sans-serif; padding: 25px; background: linear-gradient(135deg, #1a1a2e, #16213e); border-radius: 16px; text-align: center; color: white; max-width: 420px; margin: 10px auto; box-shadow: 0 8px 32px rgba(0,0,0,0.3);';\n    \n    const title = document.createElement('h3');\n    title.textContent = '\ud83c\udfa4 CLARISSA Voice Recording';\n    title.style.cssText = 'margin: 0 0 5px 0; font-size: 1.3em;';\n    \n    const subtitle = document.createElement('p');\n    subtitle.textContent = 'Speak to control reservoir simulation';\n    subtitle.style.cssText = 'color: #888; margin: 0 0 20px 0; font-size: 0.9em;';\n    \n    const status = document.createElement('p');\n    status.textContent = '\ud83d\udc46 Click Start to begin';\n    status.style.cssText = 'color: #888; margin: 15px 0; font-size: 1.1em; min-height: 30px;';\n    status.id = 'rec-status';\n    \n    const startBtn = document.createElement('button');\n    startBtn.textContent = '\ud83c\udfa4 Start Recording';\n    startBtn.style.cssText = 'padding: 15px 30px; font-size: 16px; font-weight: 600; background: linear-gradient(145deg, #e94560, #c23a51); color: white; border: none; border-radius: 50px; cursor: pointer; margin: 5px; box-shadow: 0 4px 15px rgba(233,69,96,0.4); transition: transform 0.2s;';\n    \n    const stopBtn = document.createElement('button');\n    stopBtn.textContent = '\u23f9\ufe0f Stop & Process';\n    stopBtn.style.cssText = 'padding: 15px 30px; font-size: 16px; font-weight: 600; background: linear-gradient(145deg, #4caf50, #388e3c); color: white; border: none; border-radius: 50px; cursor: pointer; margin: 5px; box-shadow: 0 4px 15px rgba(76,175,80,0.4); display: none;';\n    \n    const hint = document.createElement('p');\n    hint.innerHTML = '\ud83d\udca1 <em>Try: \"show permeability\" or \"what is water cut\"</em>';\n    hint.style.cssText = 'color: #666; font-size: 0.85em; margin-top: 20px;';\n    \n    div.appendChild(title);\n    div.appendChild(subtitle);\n    div.appendChild(startBtn);\n    div.appendChild(stopBtn);\n    div.appendChild(status);\n    div.appendChild(hint);\n    document.body.appendChild(div);\n    \n    await new Promise(resolve => startBtn.onclick = resolve);\n    \n    try {\n        status.textContent = '\ud83d\udd04 Requesting microphone access...';\n        status.style.color = '#00d9ff';\n        \n        const stream = await navigator.mediaDevices.getUserMedia({audio: true});\n        const recorder = new MediaRecorder(stream);\n        const chunks = [];\n        \n        recorder.ondataavailable = e => chunks.push(e.data);\n        \n        startBtn.style.display = 'none';\n        stopBtn.style.display = 'inline-block';\n        status.innerHTML = '\ud83d\udd34 <strong>Recording...</strong> Speak now!';\n        status.style.color = '#ff6b6b';\n        \n        recorder.start();\n        \n        await new Promise(resolve => stopBtn.onclick = resolve);\n        \n        status.textContent = '\u23f3 Processing audio...';\n        status.style.color = '#00d9ff';\n        stopBtn.disabled = true;\n        \n        recorder.stop();\n        \n        const blob = await new Promise(resolve => {\n            recorder.onstop = () => resolve(new Blob(chunks, {type: 'audio/webm'}));\n        });\n        \n        const reader = new FileReader();\n        const base64 = await new Promise(resolve => {\n            reader.onloadend = () => resolve(reader.result);\n            reader.readAsDataURL(blob);\n        });\n        \n        stream.getAudioTracks()[0].stop();\n        status.textContent = '\u2705 Recording complete!';\n        status.style.color = '#4caf50';\n        \n        return base64;\n        \n    } catch(err) {\n        status.innerHTML = '\u274c <strong>Error:</strong> ' + err.message;\n        status.style.color = '#ff6b6b';\n        hint.innerHTML = '\ud83d\udca1 Make sure to <strong>allow microphone access</strong> when prompted';\n        return 'ERROR:' + err.message;\n    }\n}\n\"\"\"\n\ndef record_and_process():\n    \"\"\"Record voice and process with CLARISSA.\"\"\"\n    print(\"\u2550\" * 60)\n    print(\"\ud83c\udfa4 CLARISSA Voice Input\")\n    print(\"\u2550\" * 60)\n    print()\n    \n    # Display the recording UI\n    display(Javascript(RECORD_JS))\n    \n    # Wait for recording (this blocks until user clicks stop)\n    print(\"\u23f3 Waiting for recording...\")\n    result = eval_js('recordAudio()')\n    \n    if not result or result.startswith('ERROR:'):\n        print(f\"\u274c Recording failed: {result}\")\n        return\n    \n    # Decode audio\n    audio_data = result.split(',')[1]\n    audio_bytes = b64decode(audio_data)\n    print(f\"\u2705 Recorded {len(audio_bytes):,} bytes of audio\")\n    \n    # Save for playback\n    with open('/tmp/recording.webm', 'wb') as f:\n        f.write(audio_bytes)\n    \n    # Playback option\n    print()\n    display(Audio('/tmp/recording.webm'))\n    \n    print()\n    print(\"\u2500\" * 60)\n    print(\"\ud83d\udcdd TRANSCRIPTION & INTENT PARSING\")\n    print(\"\u2500\" * 60)\n    \n    # Transcribe with Whisper\n    transcript = None\n    if os.getenv(\"OPENAI_API_KEY\"):\n        try:\n            from openai import OpenAI\n            client = OpenAI()\n            with open('/tmp/recording.webm', 'rb') as f:\n                result = client.audio.transcriptions.create(\n                    model=\"whisper-1\", file=f, language=\"en\"\n                )\n            transcript = result.text\n            print(f\"\ud83d\udde3\ufe0f You said: \\\"{transcript}\\\"\")\n        except Exception as e:\n            print(f\"\u26a0\ufe0f Whisper error: {e}\")\n    \n    if not transcript:\n        print(\"\u26a0\ufe0f No OPENAI_API_KEY - using demo transcript\")\n        transcript = \"show me the permeability\"\n        print(f\"\ud83d\udde3\ufe0f Demo: \\\"{transcript}\\\"\")\n    \n    # Parse intent\n    print()\n    intent = parse_intent(transcript)\n    print(f\"\ud83c\udfaf Intent: {intent.type.value}\")\n    print(f\"\ud83d\udcca Confidence: {intent.confidence:.0%}\")\n    if intent.slots:\n        print(f\"\ud83d\udce6 Slots: {intent.slots}\")\n    \n    # Generate response\n    if intent.type == IntentType.VISUALIZE_PROPERTY:\n        p = intent.slots.get('property', 'data')\n        l = intent.slots.get('layer')\n        t = intent.slots.get('time_days')\n        response = f\"Visualizing {p}\" + (f\" at layer {l}\" if l else \"\") + (f\" at day {t}\" if t else \"\") + \".\"\n    elif intent.type == IntentType.QUERY_VALUE:\n        response = f\"Querying {intent.slots.get('property', 'value')}...\"\n    else:\n        response = {\n            IntentType.CANCEL: \"Operation cancelled.\",\n            IntentType.CONFIRM: \"Confirmed! Executing...\",\n            IntentType.HELP: \"Available: show [property], what is [value], help, cancel\",\n            IntentType.UNKNOWN: \"I didn't understand. Try 'show permeability'.\",\n        }.get(intent.type, \"Processing...\")\n    \n    print()\n    print(f\"\ud83d\udcac CLARISSA: {response}\")\n    print()\n    print(\"\u2550\" * 60)\n\n# Run it!\nrecord_and_process()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8\ufe0f\u20e3 SPE Benchmark Test Suite \ud83e\uddea\n\nTests based on **SPE Comparative Solution Projects** - industry-standard reservoir simulation benchmarks:\n\n| Model | Grid | Description |\n|-------|------|-------------|\n| **SPE1** | 10\u00d710\u00d73 | Simple black-oil, gas injection |\n| **SPE9** | 24\u00d725\u00d715 | Waterflood, 26 wells |\n| **SPE10** | 60\u00d7220\u00d785 | Upscaling benchmark (1.1M cells) |\n\nRun the cell below to test intent parsing with **real-world reservoir engineering queries**!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# \ud83e\uddea SPE BENCHMARK TEST SUITE\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Tests based on SPE Comparative Solution Projects (industry-standard benchmarks)\n\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Callable, Dict, Any\n\n@dataclass  \nclass TestResult:\n    name: str\n    passed: bool\n    error: Optional[str] = None\n\nclass SPETestRunner:\n    \"\"\"Test runner with SPE model context.\"\"\"\n    \n    def __init__(self):\n        self.results: List[TestResult] = []\n        self._tests: List[Callable] = []\n    \n    def test(self, name: str, model: str = \"\"):\n        \"\"\"Decorator to register a test function.\"\"\"\n        display_name = f\"[{model}] {name}\" if model else name\n        def decorator(func):\n            def wrapper():\n                try:\n                    func()\n                    self.results.append(TestResult(display_name, True))\n                    print(f\"  \u2705 {display_name}\")\n                except AssertionError as e:\n                    self.results.append(TestResult(display_name, False, str(e)))\n                    print(f\"  \u274c {display_name}\")\n                    print(f\"     \u2514\u2500 {e}\")\n                except Exception as e:\n                    self.results.append(TestResult(display_name, False, str(e)))\n                    print(f\"  \ud83d\udca5 {display_name}\")\n                    print(f\"     \u2514\u2500 {e}\")\n            self._tests.append(wrapper)\n            return wrapper\n        return decorator\n    \n    def run_all(self):\n        \"\"\"Execute all registered tests.\"\"\"\n        print(\"\u2550\" * 65)\n        print(\"\ud83e\uddea CLARISSA Voice Module - SPE Benchmark Test Suite\")\n        print(\"\u2550\" * 65)\n        print()\n        \n        for test_func in self._tests:\n            test_func()\n        \n        passed = sum(1 for r in self.results if r.passed)\n        failed = len(self.results) - passed\n        \n        print()\n        print(\"\u2500\" * 65)\n        if failed == 0:\n            print(f\"\u2705 ALL {passed} TESTS PASSED!\")\n        else:\n            print(f\"\u274c {failed} FAILED, {passed} passed\")\n        print(\"\u2550\" * 65)\n        \n        return failed == 0\n\nrunner = SPETestRunner()\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# GENERAL COMMANDS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@runner.test(\"Cancel/Stop commands\")\ndef test_cancel():\n    for cmd in [\"cancel\", \"stop\", \"abort\", \"quit\"]:\n        r = parse_intent(cmd)\n        assert r.type == IntentType.CANCEL, f\"'{cmd}' \u2192 {r.type}\"\n\n@runner.test(\"Confirm commands\")\ndef test_confirm():\n    for cmd in [\"yes\", \"yes run it\", \"confirm\", \"ok\", \"do it\"]:\n        r = parse_intent(cmd)\n        assert r.type == IntentType.CONFIRM, f\"'{cmd}' \u2192 {r.type}\"\n\n@runner.test(\"Help command\")\ndef test_help():\n    assert parse_intent(\"help\").type == IntentType.HELP\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# SPE1 - Simple Black-Oil Model (10x10x3, gas injection)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@runner.test(\"Show pressure distribution\", model=\"SPE1\")\ndef test_spe1_pressure():\n    r = parse_intent(\"show me the pressure distribution\")\n    assert r.type == IntentType.VISUALIZE_PROPERTY\n    assert r.slots.get(\"property\") == \"pressure\"\n\n@runner.test(\"Query GOR at producer\", model=\"SPE1\")\ndef test_spe1_gor():\n    r = parse_intent(\"what is the gas oil ratio at the producer\")\n    assert r.type == IntentType.QUERY_VALUE\n    assert \"gor\" in r.slots.get(\"property\", \"\").lower() or \"gas\" in r.slots.get(\"property\", \"\").lower()\n\n@runner.test(\"Oil saturation at layer 2\", model=\"SPE1\")\ndef test_spe1_oil_sat():\n    r = parse_intent(\"display the oil saturation at layer 2\")\n    assert r.type == IntentType.VISUALIZE_PROPERTY\n    assert r.slots.get(\"layer\") == 2\n\n@runner.test(\"3D porosity visualization\", model=\"SPE1\")\ndef test_spe1_poro_3d():\n    r = parse_intent(\"show porosity in 3D\")\n    assert r.type == IntentType.VISUALIZE_PROPERTY\n    assert r.slots.get(\"property\") == \"porosity\"\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# SPE9 - Waterflood Model (24x25x15, 26 wells)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@runner.test(\"Water saturation at day 500\", model=\"SPE9\")\ndef test_spe9_wsat():\n    r = parse_intent(\"show water saturation at day 500\")\n    assert r.type == IntentType.VISUALIZE_PROPERTY\n    assert r.slots.get(\"property\") == \"water_saturation\"\n    assert r.slots.get(\"time_days\") == 500\n\n@runner.test(\"Water cut at producer 10\", model=\"SPE9\")\ndef test_spe9_wct():\n    r = parse_intent(\"what is the water cut at producer 10\")\n    assert r.type == IntentType.QUERY_VALUE\n    assert r.slots.get(\"property\") == \"water_cut\"\n\n@runner.test(\"Permeability at layer 8\", model=\"SPE9\")\ndef test_spe9_perm():\n    r = parse_intent(\"display the permeability at layer 8\")\n    assert r.type == IntentType.VISUALIZE_PROPERTY\n    assert r.slots.get(\"property\") == \"permeability\"\n    assert r.slots.get(\"layer\") == 8\n\n@runner.test(\"Field oil production rate\", model=\"SPE9\")\ndef test_spe9_fopr():\n    r = parse_intent(\"show field oil production rate\")\n    assert r.type == IntentType.QUERY_VALUE\n    assert \"oil\" in r.slots.get(\"property\", \"\").lower()\n\n@runner.test(\"Cumulative oil production\", model=\"SPE9\")\ndef test_spe9_fopt():\n    r = parse_intent(\"what is the cumulative oil production\")\n    assert r.type == IntentType.QUERY_VALUE\n\n@runner.test(\"Pressure at layer 15, time 1000\", model=\"SPE9\")\ndef test_spe9_pressure_complex():\n    r = parse_intent(\"visualize pressure at layer 15 time 1000\")\n    assert r.type == IntentType.VISUALIZE_PROPERTY\n    assert r.slots.get(\"property\") == \"pressure\"\n    assert r.slots.get(\"layer\") == 15\n    assert r.slots.get(\"time_days\") == 1000\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# SPE10 - Upscaling Benchmark (1.1M cells)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@runner.test(\"Permeability heterogeneity\", model=\"SPE10\")\ndef test_spe10_perm():\n    r = parse_intent(\"show the permeability heterogeneity\")\n    assert r.type == IntentType.VISUALIZE_PROPERTY\n    assert r.slots.get(\"property\") == \"permeability\"\n\n@runner.test(\"Porosity at layer 50\", model=\"SPE10\")\ndef test_spe10_poro():\n    r = parse_intent(\"display porosity at layer 50\")\n    assert r.type == IntentType.VISUALIZE_PROPERTY\n    assert r.slots.get(\"property\") == \"porosity\"\n    assert r.slots.get(\"layer\") == 50\n\n@runner.test(\"Pore volume query\", model=\"SPE10\")\ndef test_spe10_pv():\n    r = parse_intent(\"what is the pore volume\")\n    assert r.type == IntentType.QUERY_VALUE\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# RUN ALL TESTS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nrunner.run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izbBdH3XurxC"
   },
   "source": [
    "## \ud83d\udcda Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Speech-to-Text** - Whisper API transcription with domain vocabulary\n",
    "2. **Intent Parsing** - LLM-based command understanding\n",
    "3. **Slot Extraction** - Property, layer, time parameters\n",
    "4. **Visualization** - 3D and cross-section views triggered by voice\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Full Integration**: Connect to OPM Flow simulations\n",
    "- **Live Microphone**: Browser-based audio capture\n",
    "- **TTS Response**: Audio feedback with OpenAI TTS\n",
    "- **Offline Mode**: Local Whisper for air-gapped deployments\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Voice Input Tutorial](../guides/voice-input-tutorial.md)\n",
    "- [ADR-028: Voice Architecture](../../architecture/adr/ADR-028-voice-input-architecture.md)\n",
    "- [CLARISSA Source Code](https://gitlab.com/wolfram_laube/blauweiss_llc/clarissa)\n",
    "\n",
    "---\n",
    "\n",
    "*Part of CLARISSA - Conversational Language Agent for Reservoir Simulation*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}