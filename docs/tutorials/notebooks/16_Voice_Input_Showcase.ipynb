{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfa4 CLARISSA Voice Input Showcase\n",
        "\n",
        "**Talk to Your Reservoir Simulation**\n",
        "\n",
        "This notebook demonstrates CLARISSA's voice interface for controlling reservoir simulations through natural language commands.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udd04 Workflow\n",
        "\n",
        "| Step | Where | What |\n",
        "|------|-------|------|\n",
        "| 1\ufe0f\u20e3 | **Web Demo** | Record your voice command |\n",
        "| 2\ufe0f\u20e3 | **This Notebook** | Upload + Transcribe + Process |\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\ude80 Step 1: Record Your Voice\n",
        "\n",
        "\ud83d\udc49 **[Open Voice Demo](https://irena-40cc50.gitlab.io/demos/voice-demo.html)** (opens in new tab)\n",
        "\n",
        "1. Click **\"Start Recording\"**\n",
        "2. Speak your command (e.g., *\"show permeability distribution\"*)\n",
        "3. Click **\"Stop\"**\n",
        "4. Click **\"Download WAV\"**\n",
        "5. Come back here and upload the file\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup (run once)\n",
        "!pip install -q openai\n",
        "\n",
        "import os\n",
        "from IPython.display import display, HTML, Audio\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\u2705 Ready! Upload your audio file below.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83d\udce4 Step 2: Upload Your Recording"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload your recorded audio file\n",
        "print(\"\ud83d\udcc2 Select your audio file (WAV, WebM, MP3, etc.)\")\n",
        "print()\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    audio_bytes = uploaded[filename]\n",
        "    \n",
        "    print()\n",
        "    print(f\"\u2705 Uploaded: {filename} ({len(audio_bytes):,} bytes)\")\n",
        "    print()\n",
        "    print(\"\ud83d\udd0a Playback:\")\n",
        "    display(Audio(audio_bytes, autoplay=False))\n",
        "else:\n",
        "    print(\"\u274c No file uploaded\")\n",
        "    audio_bytes = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83d\udcdd Step 3: Transcribe with Whisper\n",
        "\n",
        "Enter your OpenAI API key to transcribe the audio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transcribe the uploaded audio\n",
        "import tempfile\n",
        "from getpass import getpass\n",
        "\n",
        "# Get API key\n",
        "if not os.environ.get('OPENAI_API_KEY'):\n",
        "    os.environ['OPENAI_API_KEY'] = getpass(\"OpenAI API Key: \")\n",
        "\n",
        "if audio_bytes:\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI()\n",
        "    \n",
        "    # Save to temp file\n",
        "    ext = filename.split('.')[-1] if '.' in filename else 'wav'\n",
        "    with tempfile.NamedTemporaryFile(suffix=f'.{ext}', delete=False) as f:\n",
        "        f.write(audio_bytes)\n",
        "        temp_path = f.name\n",
        "    \n",
        "    print(\"\ud83d\udd04 Transcribing...\")\n",
        "    \n",
        "    with open(temp_path, 'rb') as audio_file:\n",
        "        transcript = client.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=audio_file,\n",
        "            language=\"en\",\n",
        "            prompt=\"Reservoir simulation commands: permeability, porosity, pressure, saturation, water cut, oil rate, injection, production, layers, wells, grid\"\n",
        "        )\n",
        "    \n",
        "    os.unlink(temp_path)\n",
        "    \n",
        "    print()\n",
        "    print(\"\u2550\" * 50)\n",
        "    print(\"\ud83d\udcdd TRANSCRIPT\")\n",
        "    print(\"\u2550\" * 50)\n",
        "    print()\n",
        "    print(f'   \"{transcript.text}\"')\n",
        "    print()\n",
        "    \n",
        "    # Store for next cell\n",
        "    command_text = transcript.text\n",
        "else:\n",
        "    print(\"\u274c No audio to transcribe. Run the upload cell first.\")\n",
        "    command_text = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83e\udde0 Step 4: Parse Intent\n",
        "\n",
        "Analyze the voice command to extract the user's intent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse the intent from the transcript\n",
        "if command_text:\n",
        "    # Simple keyword-based intent detection\n",
        "    text_lower = command_text.lower()\n",
        "    \n",
        "    # Define intents\n",
        "    intents = []\n",
        "    \n",
        "    # Property queries\n",
        "    if any(w in text_lower for w in ['permeability', 'perm']):\n",
        "        intents.append(('SHOW_PROPERTY', 'permeability'))\n",
        "    if any(w in text_lower for w in ['porosity', 'poro']):\n",
        "        intents.append(('SHOW_PROPERTY', 'porosity'))\n",
        "    if 'pressure' in text_lower:\n",
        "        intents.append(('SHOW_PROPERTY', 'pressure'))\n",
        "    if any(w in text_lower for w in ['saturation', 'sat']):\n",
        "        intents.append(('SHOW_PROPERTY', 'saturation'))\n",
        "    if any(w in text_lower for w in ['water cut', 'watercut']):\n",
        "        intents.append(('SHOW_METRIC', 'water_cut'))\n",
        "    if any(w in text_lower for w in ['oil rate', 'production rate']):\n",
        "        intents.append(('SHOW_METRIC', 'oil_rate'))\n",
        "    \n",
        "    # Actions\n",
        "    if any(w in text_lower for w in ['run', 'simulate', 'execute']):\n",
        "        intents.append(('RUN_SIMULATION', None))\n",
        "    if any(w in text_lower for w in ['stop', 'cancel', 'abort']):\n",
        "        intents.append(('STOP_SIMULATION', None))\n",
        "    \n",
        "    # Questions\n",
        "    if any(w in text_lower for w in ['what is', 'what are', 'how much', 'how many']):\n",
        "        intents.append(('QUERY', 'general'))\n",
        "    \n",
        "    print(\"\u2550\" * 50)\n",
        "    print(\"\ud83e\udde0 INTENT ANALYSIS\")\n",
        "    print(\"\u2550\" * 50)\n",
        "    print()\n",
        "    print(f\"Input: \\\"{command_text}\\\"\")\n",
        "    print()\n",
        "    \n",
        "    if intents:\n",
        "        print(\"Detected intents:\")\n",
        "        for intent_type, intent_value in intents:\n",
        "            if intent_value:\n",
        "                print(f\"  \u2022 {intent_type}: {intent_value}\")\n",
        "            else:\n",
        "                print(f\"  \u2022 {intent_type}\")\n",
        "    else:\n",
        "        print(\"  \u26a0\ufe0f No specific intent detected\")\n",
        "        print(\"  \u2192 Would pass to LLM for interpretation\")\n",
        "    \n",
        "    print()\n",
        "    print(\"\u2500\" * 50)\n",
        "    print(\"\ud83d\udca1 In production, this would trigger CLARISSA actions\")\n",
        "else:\n",
        "    print(\"\u274c No transcript available. Run the transcription cell first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83d\udd17 Resources\n",
        "\n",
        "| Resource | Link |\n",
        "|----------|------|\n",
        "| \ud83c\udfa4 Voice Demo | [irena-40cc50.gitlab.io/demos/voice-demo.html](https://irena-40cc50.gitlab.io/demos/voice-demo.html) |\n",
        "| \ud83c\udfac Recording Suite | [irena-40cc50.gitlab.io/demos/demo-recording-suite.html](https://irena-40cc50.gitlab.io/demos/demo-recording-suite.html) |\n",
        "| \ud83d\udcda CLARISSA Docs | [irena-40cc50.gitlab.io](https://irena-40cc50.gitlab.io/) |\n",
        "| \ud83d\udcbb Source Code | [GitLab Repository](https://gitlab.com/wolfram_laube/blauweiss_llc/irena) |\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udccb Example Commands to Try\n",
        "\n",
        "- *\"Show me the permeability distribution\"*\n",
        "- *\"What is the current water cut?\"*\n",
        "- *\"Display pressure in layer 3\"*\n",
        "- *\"Run the simulation\"*\n",
        "- *\"What are the oil production rates?\"*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}