{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfa4 CLARISSA Voice Input Showcase\n",
        "\n",
        "**Talk to Your Reservoir Simulation**\n",
        "\n",
        "This notebook demonstrates CLARISSA's voice interface for controlling reservoir simulations through natural language commands.\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\ude80 Quick Start\n",
        "\n",
        "**Just run the cell below!** It will:\n",
        "1. Set up everything automatically\n",
        "2. Show a voice recording interface\n",
        "3. Transcribe your speech (if API key is set)\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83c\udf10 Web Demo\n",
        "\n",
        "For an even simpler experience, use the **standalone web demo** (no setup required):\n",
        "\n",
        "\ud83d\udc49 **[Voice Notebook Demo](https://irena-40cc50.gitlab.io/demos/voice-demo.html)**\n",
        "\n",
        "\ud83d\udc49 **[Recording Suite (Voice + Screen)](https://irena-40cc50.gitlab.io/demos/demo-recording-suite.html)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# \ud83d\ude80 QUICK START - Just run this cell!\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "#\n",
        "# This single cell sets up everything and launches the voice interface.\n",
        "# After recording, your audio is automatically transcribed and ready to use.\n",
        "#\n",
        "# \ud83d\udca1 For the standalone web demo (no setup needed), visit:\n",
        "#    https://irena-40cc50.gitlab.io/demos/voice-demo.html\n",
        "#\n",
        "\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# Silent Setup\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Install packages quietly\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"openai\"], \n",
        "               capture_output=True)\n",
        "\n",
        "from IPython.display import display, Javascript, HTML, Audio, clear_output\n",
        "from base64 import b64decode\n",
        "import os\n",
        "\n",
        "# Check environment\n",
        "try:\n",
        "    from google.colab import output\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"\u26a0\ufe0f  This notebook works best in Google Colab!\")\n",
        "    print(\"   Open in Colab: https://colab.research.google.com/github/wolfram-laube/clarissa/blob/main/docs/tutorials/notebooks/16_Voice_Input_Showcase.ipynb\")\n",
        "    print()\n",
        "    print(\"   Or use the web demo: https://irena-40cc50.gitlab.io/demos/voice-demo.html\")\n",
        "\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# Voice Recorder (Colab-compatible)\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "\n",
        "VOICE_UI = \"\"\"\n",
        "(function() {\n",
        "    // Remove any existing UI\n",
        "    const existing = document.getElementById('clarissa-voice-ui');\n",
        "    if (existing) existing.remove();\n",
        "    \n",
        "    // State\n",
        "    let mediaRecorder, audioChunks = [], audioContext, analyser, dataArray;\n",
        "    let isRecording = false, timerInterval, seconds = 0;\n",
        "    \n",
        "    // Create UI\n",
        "    const container = document.createElement('div');\n",
        "    container.id = 'clarissa-voice-ui';\n",
        "    container.innerHTML = `\n",
        "        <style>\n",
        "            #clarissa-voice-ui * { box-sizing: border-box; }\n",
        "            .cv-container {\n",
        "                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "                background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);\n",
        "                border-radius: 20px;\n",
        "                padding: 30px;\n",
        "                max-width: 500px;\n",
        "                margin: 20px auto;\n",
        "                box-shadow: 0 15px 50px rgba(0,0,0,0.5);\n",
        "                color: white;\n",
        "            }\n",
        "            .cv-header { text-align: center; margin-bottom: 25px; }\n",
        "            .cv-title {\n",
        "                font-size: 1.8em;\n",
        "                font-weight: 700;\n",
        "                background: linear-gradient(90deg, #e94560, #0f3460);\n",
        "                -webkit-background-clip: text;\n",
        "                -webkit-text-fill-color: transparent;\n",
        "                margin: 0;\n",
        "            }\n",
        "            .cv-subtitle { color: #888; margin-top: 8px; font-size: 0.95em; }\n",
        "            .cv-waveform {\n",
        "                height: 80px;\n",
        "                background: rgba(0,0,0,0.4);\n",
        "                border-radius: 12px;\n",
        "                display: flex;\n",
        "                align-items: center;\n",
        "                justify-content: center;\n",
        "                gap: 3px;\n",
        "                padding: 0 15px;\n",
        "                margin: 20px 0;\n",
        "            }\n",
        "            .cv-bar {\n",
        "                width: 4px;\n",
        "                height: 15px;\n",
        "                background: linear-gradient(180deg, #e94560 0%, #0f3460 100%);\n",
        "                border-radius: 2px;\n",
        "                transition: height 0.05s ease-out;\n",
        "            }\n",
        "            .cv-timer {\n",
        "                text-align: center;\n",
        "                font-size: 2.5em;\n",
        "                font-weight: 700;\n",
        "                font-family: 'SF Mono', Monaco, monospace;\n",
        "                color: #4caf50;\n",
        "                margin: 15px 0;\n",
        "            }\n",
        "            .cv-status {\n",
        "                text-align: center;\n",
        "                color: #aaa;\n",
        "                min-height: 24px;\n",
        "                margin: 15px 0;\n",
        "            }\n",
        "            .cv-status.recording { color: #e94560; font-weight: 600; }\n",
        "            .cv-status.success { color: #4caf50; }\n",
        "            .cv-status.error { color: #ff6b6b; }\n",
        "            .cv-buttons {\n",
        "                display: flex;\n",
        "                justify-content: center;\n",
        "                gap: 15px;\n",
        "                margin-top: 20px;\n",
        "            }\n",
        "            .cv-btn {\n",
        "                padding: 15px 35px;\n",
        "                font-size: 16px;\n",
        "                font-weight: 600;\n",
        "                border: none;\n",
        "                border-radius: 30px;\n",
        "                cursor: pointer;\n",
        "                transition: all 0.3s ease;\n",
        "                display: flex;\n",
        "                align-items: center;\n",
        "                gap: 8px;\n",
        "            }\n",
        "            .cv-btn:hover { transform: translateY(-2px); }\n",
        "            .cv-btn-record {\n",
        "                background: linear-gradient(145deg, #e94560, #c23a51);\n",
        "                color: white;\n",
        "                box-shadow: 0 4px 20px rgba(233,69,96,0.4);\n",
        "            }\n",
        "            .cv-btn-stop {\n",
        "                background: linear-gradient(145deg, #4caf50, #388e3c);\n",
        "                color: white;\n",
        "                box-shadow: 0 4px 20px rgba(76,175,80,0.4);\n",
        "            }\n",
        "            .cv-hint {\n",
        "                text-align: center;\n",
        "                color: #666;\n",
        "                font-size: 0.85em;\n",
        "                margin-top: 20px;\n",
        "                font-style: italic;\n",
        "            }\n",
        "            .cv-link {\n",
        "                text-align: center;\n",
        "                margin-top: 15px;\n",
        "                padding-top: 15px;\n",
        "                border-top: 1px solid rgba(255,255,255,0.1);\n",
        "            }\n",
        "            .cv-link a { color: #e94560; text-decoration: none; font-size: 0.85em; }\n",
        "            .cv-link a:hover { text-decoration: underline; }\n",
        "            @keyframes pulse {\n",
        "                0%, 100% { box-shadow: 0 4px 20px rgba(233,69,96,0.4); }\n",
        "                50% { box-shadow: 0 4px 35px rgba(233,69,96,0.7); }\n",
        "            }\n",
        "            .cv-btn-record.recording { animation: pulse 1s ease-in-out infinite; }\n",
        "        </style>\n",
        "        <div class=\"cv-container\">\n",
        "            <div class=\"cv-header\">\n",
        "                <h2 class=\"cv-title\">\ud83c\udfa4 CLARISSA Voice Input</h2>\n",
        "                <p class=\"cv-subtitle\">Speak to control reservoir simulation</p>\n",
        "            </div>\n",
        "            <div class=\"cv-waveform\" id=\"cv-waveform\"></div>\n",
        "            <div class=\"cv-timer\" id=\"cv-timer\">00:00</div>\n",
        "            <div class=\"cv-status\" id=\"cv-status\">Click \"Start Recording\" to begin</div>\n",
        "            <div class=\"cv-buttons\">\n",
        "                <button class=\"cv-btn cv-btn-record\" id=\"cv-record\">\ud83c\udfa4 Start Recording</button>\n",
        "                <button class=\"cv-btn cv-btn-stop\" id=\"cv-stop\" style=\"display:none\">\u23f9\ufe0f Stop</button>\n",
        "            </div>\n",
        "            <p class=\"cv-hint\">\ud83d\udca1 Try: \"show permeability\" or \"what is the water cut?\"</p>\n",
        "            <div class=\"cv-link\">\n",
        "                <a href=\"https://irena-40cc50.gitlab.io/demos/voice-demo.html\" target=\"_blank\">\n",
        "                    Open full demo in new tab \u2197\n",
        "                </a>\n",
        "            </div>\n",
        "        </div>\n",
        "    `;\n",
        "    document.body.appendChild(container);\n",
        "    \n",
        "    // Create waveform bars\n",
        "    const waveform = document.getElementById('cv-waveform');\n",
        "    for (let i = 0; i < 35; i++) {\n",
        "        const bar = document.createElement('div');\n",
        "        bar.className = 'cv-bar';\n",
        "        waveform.appendChild(bar);\n",
        "    }\n",
        "    const bars = waveform.querySelectorAll('.cv-bar');\n",
        "    \n",
        "    const recordBtn = document.getElementById('cv-record');\n",
        "    const stopBtn = document.getElementById('cv-stop');\n",
        "    const status = document.getElementById('cv-status');\n",
        "    const timer = document.getElementById('cv-timer');\n",
        "    \n",
        "    function animateWaveform() {\n",
        "        if (!isRecording) return;\n",
        "        analyser.getByteFrequencyData(dataArray);\n",
        "        bars.forEach((bar, i) => {\n",
        "            const value = dataArray[i % dataArray.length] || 0;\n",
        "            bar.style.height = Math.max(8, value / 3) + 'px';\n",
        "        });\n",
        "        requestAnimationFrame(animateWaveform);\n",
        "    }\n",
        "    \n",
        "    function updateTimer() {\n",
        "        seconds++;\n",
        "        const mins = Math.floor(seconds / 60);\n",
        "        const secs = seconds % 60;\n",
        "        timer.textContent = mins.toString().padStart(2, '0') + ':' + secs.toString().padStart(2, '0');\n",
        "    }\n",
        "    \n",
        "    recordBtn.onclick = async () => {\n",
        "        try {\n",
        "            status.textContent = '\ud83d\udd04 Requesting microphone...';\n",
        "            status.className = 'cv-status';\n",
        "            \n",
        "            const stream = await navigator.mediaDevices.getUserMedia({ \n",
        "                audio: { channelCount: 1, sampleRate: 16000, echoCancellation: true, noiseSuppression: true }\n",
        "            });\n",
        "            \n",
        "            audioContext = new AudioContext();\n",
        "            analyser = audioContext.createAnalyser();\n",
        "            analyser.fftSize = 128;\n",
        "            dataArray = new Uint8Array(analyser.frequencyBinCount);\n",
        "            audioContext.createMediaStreamSource(stream).connect(analyser);\n",
        "            \n",
        "            mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });\n",
        "            audioChunks = [];\n",
        "            mediaRecorder.ondataavailable = e => audioChunks.push(e.data);\n",
        "            mediaRecorder.start(100);\n",
        "            \n",
        "            isRecording = true;\n",
        "            seconds = 0;\n",
        "            timerInterval = setInterval(updateTimer, 1000);\n",
        "            animateWaveform();\n",
        "            \n",
        "            recordBtn.style.display = 'none';\n",
        "            stopBtn.style.display = 'flex';\n",
        "            status.innerHTML = '\ud83d\udd34 <b>Recording...</b> Speak now!';\n",
        "            status.className = 'cv-status recording';\n",
        "            recordBtn.classList.add('recording');\n",
        "            \n",
        "        } catch (err) {\n",
        "            status.textContent = '\u274c ' + err.message;\n",
        "            status.className = 'cv-status error';\n",
        "        }\n",
        "    };\n",
        "    \n",
        "    stopBtn.onclick = () => {\n",
        "        if (!isRecording) return;\n",
        "        isRecording = false;\n",
        "        clearInterval(timerInterval);\n",
        "        \n",
        "        mediaRecorder.stop();\n",
        "        mediaRecorder.stream.getTracks().forEach(t => t.stop());\n",
        "        \n",
        "        status.textContent = '\u23f3 Processing...';\n",
        "        status.className = 'cv-status';\n",
        "        stopBtn.style.display = 'none';\n",
        "        bars.forEach(bar => bar.style.height = '15px');\n",
        "        \n",
        "        mediaRecorder.onstop = async () => {\n",
        "            const blob = new Blob(audioChunks, { type: 'audio/webm' });\n",
        "            const reader = new FileReader();\n",
        "            reader.onloadend = () => {\n",
        "                window._clarissaAudioResult = reader.result;\n",
        "                status.textContent = '\u2705 Recording complete! Processing...';\n",
        "                status.className = 'cv-status success';\n",
        "                google.colab.kernel.invokeFunction('notebook.process_audio', [reader.result], {});\n",
        "            };\n",
        "            reader.readAsDataURL(blob);\n",
        "            if (audioContext) audioContext.close();\n",
        "        };\n",
        "    };\n",
        "})();\n",
        "\"\"\"\n",
        "\n",
        "# Python callback to process audio\n",
        "def process_audio(audio_base64):\n",
        "    \"\"\"Process recorded audio - called from JavaScript.\"\"\"\n",
        "    global last_recording, last_transcript\n",
        "    \n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    audio_data = audio_base64.split(',')[1]\n",
        "    audio_bytes = b64decode(audio_data)\n",
        "    last_recording = audio_bytes\n",
        "    \n",
        "    print(\"\u2550\" * 60)\n",
        "    print(\"\u2705 Recording captured!\")\n",
        "    print(\"\u2550\" * 60)\n",
        "    print(f\"   Audio size: {len(audio_bytes):,} bytes\")\n",
        "    print()\n",
        "    print(\"\ud83d\udd0a Your recording:\")\n",
        "    display(Audio(audio_bytes, autoplay=False))\n",
        "    \n",
        "    api_key = os.getenv('OPENAI_API_KEY')\n",
        "    if api_key:\n",
        "        print()\n",
        "        print(\"\u2500\" * 60)\n",
        "        print(\"\ud83d\udcdd Transcribing with Whisper...\")\n",
        "        print(\"\u2500\" * 60)\n",
        "        \n",
        "        try:\n",
        "            from openai import OpenAI\n",
        "            import tempfile\n",
        "            \n",
        "            client = OpenAI(api_key=api_key)\n",
        "            \n",
        "            with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as f:\n",
        "                f.write(audio_bytes)\n",
        "                temp_path = f.name\n",
        "            \n",
        "            with open(temp_path, 'rb') as audio_file:\n",
        "                transcript = client.audio.transcriptions.create(\n",
        "                    model=\"whisper-1\",\n",
        "                    file=audio_file,\n",
        "                    language=\"en\",\n",
        "                    prompt=\"Reservoir simulation: permeability, porosity, pressure, saturation, water cut, oil rate\"\n",
        "                )\n",
        "            \n",
        "            os.unlink(temp_path)\n",
        "            last_transcript = transcript.text\n",
        "            \n",
        "            print()\n",
        "            print(f'   \"{transcript.text}\"')\n",
        "            print()\n",
        "            print(\"\u2500\" * 60)\n",
        "            print(\"\ud83d\udca1 Use `last_transcript` variable to access this text\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   \u274c Transcription failed: {e}\")\n",
        "            last_transcript = None\n",
        "    else:\n",
        "        print()\n",
        "        print(\"\u2500\" * 60)\n",
        "        print(\"\ud83d\udca1 To enable transcription, set your OpenAI API key:\")\n",
        "        print('   os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"')\n",
        "        print(\"   Then run this cell again.\")\n",
        "        print()\n",
        "        print(\"\ud83d\udca1 Use `last_recording` variable to access audio bytes\")\n",
        "        last_transcript = None\n",
        "    \n",
        "    print()\n",
        "    print(\"\ud83c\udfa4 Run this cell again to record another command\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    output.register_callback('notebook.process_audio', process_audio)\n",
        "\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# Launch UI\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "\n",
        "last_recording = None\n",
        "last_transcript = None\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"\ud83c\udfa4 CLARISSA Voice Input Ready!\")\n",
        "    print(\"\u2500\" * 40)\n",
        "    print()\n",
        "    display(Javascript(VOICE_UI))\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83d\udd11 Optional: Enable Transcription\n",
        "\n",
        "To automatically transcribe your recordings with OpenAI Whisper, run this cell and enter your API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set your OpenAI API key for automatic transcription\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.getenv('OPENAI_API_KEY'):\n",
        "    api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "    print(\"\u2705 API key set! Recordings will now be automatically transcribed.\")\n",
        "else:\n",
        "    print(\"\u2705 API key already configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83d\udcda Working with Results\n",
        "\n",
        "After recording, you can access your data:\n",
        "\n",
        "```python\n",
        "# Audio bytes (webm format)\n",
        "last_recording\n",
        "\n",
        "# Transcribed text (if API key set)\n",
        "last_transcript\n",
        "```\n",
        "\n",
        "### Example: Process the transcript\n",
        "\n",
        "```python\n",
        "if last_transcript:\n",
        "    # Parse intent\n",
        "    if \"permeability\" in last_transcript.lower():\n",
        "        print(\"User wants to see permeability data!\")\n",
        "    elif \"water cut\" in last_transcript.lower():\n",
        "        print(\"User is asking about water cut!\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udd17 Related Resources\n",
        "\n",
        "- **[Web Demo](https://irena-40cc50.gitlab.io/demos/voice-demo.html)** - Standalone voice interface\n",
        "- **[Recording Suite](https://irena-40cc50.gitlab.io/demos/demo-recording-suite.html)** - Voice + Screen recording\n",
        "- **[CLARISSA Documentation](https://irena-40cc50.gitlab.io/)** - Full project docs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}