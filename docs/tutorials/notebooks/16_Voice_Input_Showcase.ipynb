{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6cCX74Durw6"
      },
      "source": [
        "# üé§ CLARISSA Voice Input Showcase\n",
        "\n",
        "**Talk to Your Reservoir Simulation**\n",
        "\n",
        "This notebook demonstrates CLARISSA's voice interface - control reservoir simulations through natural speech.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wolfram-laube/clarissa/blob/main/docs/tutorials/notebooks/16_Voice_Input_Showcase.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "1. **Speech-to-Text** - Convert voice to text with Whisper\n",
        "2. **Intent Recognition** - Parse commands into structured intents\n",
        "3. **Command Execution** - Trigger visualizations by voice\n",
        "4. **Full Pipeline** - End-to-end voice control demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH96bsanurw7"
      },
      "source": [
        "## 1Ô∏è‚É£ Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwuM5Ff1urw7"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q openai anthropic plotly numpy ipywidgets\n",
        "\n",
        "# For local Whisper (optional - skip if using API)\n",
        "# !pip install -q faster-whisper\n",
        "\n",
        "print(\"‚úÖ Packages installed (OpenAI + Anthropic)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9Nk8_z_urw8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import base64\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Any, Optional, List\n",
        "from enum import Enum\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from IPython.display import display, HTML, Audio\n",
        "import ipywidgets as widgets\n",
        "\n",
        "print(\"‚úÖ Imports ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDEnpG83urw8"
      },
      "outputs": [],
      "source": [
        "# API Key Setup - Choose your LLM provider\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "# CLARISSA supports both OpenAI and Anthropic (Claude) for intent parsing.\n",
        "# Whisper (OpenAI) is always used for speech-to-text.\n",
        "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "# Option 1: Colab secrets (recommended)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "\n",
        "    # Try Anthropic first (CLARISSA's native LLM)\n",
        "    try:\n",
        "        os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
        "        print(\"‚úÖ Anthropic API key loaded (Claude)\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Also try OpenAI (for Whisper STT + optional intent parsing)\n",
        "    try:\n",
        "        os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "        print(\"‚úÖ OpenAI API key loaded (Whisper STT)\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# Check what's available\n",
        "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
        "openai_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "print()\n",
        "print(\"‚ïê\" * 50)\n",
        "print(\"LLM Configuration:\")\n",
        "print(\"‚ïê\" * 50)\n",
        "\n",
        "if anthropic_key:\n",
        "    print(\"üü¢ Claude (Anthropic): Available - will use for intent parsing\")\n",
        "    LLM_PROVIDER = \"anthropic\"\n",
        "elif openai_key:\n",
        "    print(\"üü¢ GPT-4 (OpenAI): Available - will use for intent parsing\")\n",
        "    LLM_PROVIDER = \"openai\"\n",
        "else:\n",
        "    print(\"üü° No LLM API key - using rule-based parsing only\")\n",
        "    print(\"   (Works for common commands, limited for complex queries)\")\n",
        "    LLM_PROVIDER = \"rules\"\n",
        "\n",
        "if openai_key:\n",
        "    print(\"üü¢ Whisper STT: Available\")\n",
        "else:\n",
        "    print(\"üü° Whisper STT: Not available (no OpenAI key)\")\n",
        "    print(\"   (Text input mode only)\")\n",
        "\n",
        "print(\"‚ïê\" * 50)\n",
        "print()\n",
        "print(\"üí° To add API keys in Colab:\")\n",
        "print(\"   1. Click üîë Secrets (left sidebar)\")\n",
        "print(\"   2. Add: ANTHROPIC_API_KEY and/or OPENAI_API_KEY\")\n",
        "print(\"   3. Enable notebook access\")\n",
        "print(\"   4. Restart runtime\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB2r3EQsurw9"
      },
      "source": [
        "## 2Ô∏è‚É£ Core Voice Components\n",
        "\n",
        "These are simplified versions of the full CLARISSA voice module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCBiFiWIurw9"
      },
      "outputs": [],
      "source": [
        "# Intent Types\n",
        "class IntentType(Enum):\n",
        "    VISUALIZE_PROPERTY = \"visualize_property\"\n",
        "    QUERY_VALUE = \"query_value\"\n",
        "    NAVIGATE = \"navigate\"\n",
        "    HELP = \"help\"\n",
        "    CANCEL = \"cancel\"\n",
        "    CONFIRM = \"confirm\"\n",
        "    UNKNOWN = \"unknown\"\n",
        "\n",
        "@dataclass\n",
        "class Intent:\n",
        "    \"\"\"Parsed intent from voice command.\"\"\"\n",
        "    type: IntentType\n",
        "    confidence: float\n",
        "    slots: Dict[str, Any] = field(default_factory=dict)\n",
        "    raw_text: str = \"\"\n",
        "\n",
        "@dataclass\n",
        "class VoiceResponse:\n",
        "    \"\"\"Response to voice command.\"\"\"\n",
        "    success: bool\n",
        "    text: str\n",
        "    intent: Optional[Intent] = None\n",
        "    visualization: Optional[go.Figure] = None\n",
        "\n",
        "print(\"‚úÖ Data classes defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmVKdD62urw-"
      },
      "outputs": [],
      "source": [
        "# Domain vocabulary for better recognition\n",
        "DOMAIN_VOCABULARY = \"\"\"\n",
        "Reservoir simulation terms: permeability, porosity, water saturation,\n",
        "oil saturation, pressure, BHP, bottomhole pressure, OOIP,\n",
        "waterflood, injector, producer, PROD1, INJ1, INJ2, INJ3, INJ4,\n",
        "millidarcy, mD, psi, bbl/day, STB, FOPT, FOPR, FWPT, FWPR, FWCT,\n",
        "water cut, layer, grid, cell, timestep, 3D, cross-section, animation\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìö Domain vocabulary loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFR6mzl0urw-"
      },
      "source": [
        "### 2.1 Speech-to-Text (Whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAkU8o8curw-"
      },
      "outputs": [],
      "source": [
        "def transcribe_audio(audio_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Transcribe audio file using OpenAI Whisper API.\n",
        "\n",
        "    Args:\n",
        "        audio_path: Path to audio file (WAV, MP3, etc.)\n",
        "\n",
        "    Returns:\n",
        "        Transcribed text\n",
        "    \"\"\"\n",
        "    import openai\n",
        "\n",
        "    client = openai.OpenAI()\n",
        "\n",
        "    with open(audio_path, 'rb') as audio_file:\n",
        "        response = client.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=audio_file,\n",
        "            prompt=DOMAIN_VOCABULARY,\n",
        "            language=\"en\"\n",
        "        )\n",
        "\n",
        "    return response.text\n",
        "\n",
        "print(\"üé§ Whisper transcription function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OjhhUU8urw-"
      },
      "source": [
        "### 2.2 Intent Parser (LLM-based)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgU53_lTurw_"
      },
      "outputs": [],
      "source": [
        "INTENT_PROMPT = \"\"\"You are a reservoir simulation assistant. Parse the user's voice command into a structured intent.\n",
        "\n",
        "Available intents:\n",
        "- visualize_property: Show reservoir properties (permeability, porosity, saturation, pressure)\n",
        "- query_value: Ask about simulation values (rates, pressures, water cut, cumulative production)\n",
        "- navigate: Go to different sections (results, sensitivity, model)\n",
        "- help: Ask for help or guidance\n",
        "- cancel: Stop or cancel current action\n",
        "- confirm: Confirm a pending action\n",
        "\n",
        "Slots to extract:\n",
        "- property: permeability, porosity, water_saturation, oil_saturation, pressure\n",
        "- layer: integer (1-5 typically)\n",
        "- time_days: integer (simulation day)\n",
        "- view_type: 3d, cross_section_xy, cross_section_xz, animation\n",
        "- well: PROD1, INJ1, INJ2, INJ3, INJ4\n",
        "- target: results, sensitivity, model, export\n",
        "\n",
        "User said: \"{text}\"\n",
        "\n",
        "Respond with ONLY valid JSON (no markdown, no explanation):\n",
        "{{\"intent\": \"<type>\", \"confidence\": <0.0-1.0>, \"slots\": {{...}}}}\"\"\"\n",
        "\n",
        "import re\n",
        "\n",
        "def parse_intent_rules(text: str) -> Intent:\n",
        "    \"\"\"Rule-based intent parsing - works WITHOUT API key.\"\"\"\n",
        "    text_lower = text.lower().strip()\n",
        "    slots = {}\n",
        "\n",
        "    # Cancel / Confirm / Help\n",
        "    if text_lower in [\"stop\", \"cancel\", \"never mind\", \"abort\", \"quit\"]:\n",
        "        return Intent(IntentType.CANCEL, 1.0, {}, text)\n",
        "    if text_lower in [\"yes\", \"yeah\", \"yep\", \"confirm\", \"ok\", \"okay\", \"do it\", \"go ahead\"]:\n",
        "        return Intent(IntentType.CONFIRM, 1.0, {}, text)\n",
        "    if text_lower == \"help\" or \"what can\" in text_lower:\n",
        "        return Intent(IntentType.HELP, 1.0, {}, text)\n",
        "\n",
        "    # Visualization\n",
        "    viz_keywords = [\"show\", \"display\", \"visualize\", \"plot\", \"view\", \"see\"]\n",
        "    if any(kw in text_lower for kw in viz_keywords):\n",
        "        if \"perm\" in text_lower: slots[\"property\"] = \"permeability\"\n",
        "        elif \"poro\" in text_lower: slots[\"property\"] = \"porosity\"\n",
        "        elif \"saturation\" in text_lower or \" sw\" in text_lower: slots[\"property\"] = \"water_saturation\"\n",
        "        elif \"pressure\" in text_lower: slots[\"property\"] = \"pressure\"\n",
        "\n",
        "        layer_match = re.search(r'layer\\s*(\\d+)', text_lower)\n",
        "        if layer_match: slots[\"layer\"] = int(layer_match.group(1))\n",
        "\n",
        "        time_match = re.search(r'(?:day|time)\\s*(\\d+)', text_lower)\n",
        "        if time_match: slots[\"time_days\"] = int(time_match.group(1))\n",
        "\n",
        "        if not slots.get(\"property\") and not slots.get(\"layer\"):\n",
        "            slots[\"property\"] = \"permeability\"\n",
        "\n",
        "        return Intent(IntentType.VISUALIZE_PROPERTY, 0.95, slots, text)\n",
        "\n",
        "    # Query\n",
        "    if any(kw in text_lower for kw in [\"what\", \"how much\", \"tell me\"]):\n",
        "        if \"oil rate\" in text_lower: slots[\"property\"] = \"oil_rate\"\n",
        "        elif \"water cut\" in text_lower: slots[\"property\"] = \"water_cut\"\n",
        "        elif \"water rate\" in text_lower: slots[\"property\"] = \"water_rate\"\n",
        "        elif \"pressure\" in text_lower: slots[\"property\"] = \"pressure\"\n",
        "        if slots:\n",
        "            return Intent(IntentType.QUERY_VALUE, 0.9, slots, text)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def parse_with_claude(text: str) -> Intent:\n",
        "    \"\"\"Parse intent using Claude (Anthropic).\"\"\"\n",
        "    import anthropic\n",
        "    client = anthropic.Anthropic()\n",
        "\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-sonnet-4-20250514\",\n",
        "        max_tokens=200,\n",
        "        messages=[{\"role\": \"user\", \"content\": INTENT_PROMPT.format(text=text)}]\n",
        "    )\n",
        "\n",
        "    result_text = response.content[0].text.strip()\n",
        "    if result_text.startswith(\"```\"):\n",
        "        result_text = result_text.split(\"```\")[1].replace(\"json\", \"\", 1)\n",
        "\n",
        "    data = json.loads(result_text)\n",
        "    return Intent(\n",
        "        IntentType(data.get(\"intent\", \"unknown\")),\n",
        "        float(data.get(\"confidence\", 0.8)),\n",
        "        data.get(\"slots\", {}),\n",
        "        text\n",
        "    )\n",
        "\n",
        "\n",
        "def parse_with_openai(text: str) -> Intent:\n",
        "    \"\"\"Parse intent using GPT-4 (OpenAI).\"\"\"\n",
        "    import openai\n",
        "    client = openai.OpenAI()\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Parse voice commands into JSON. Respond with ONLY valid JSON.\"},\n",
        "            {\"role\": \"user\", \"content\": INTENT_PROMPT.format(text=text)}\n",
        "        ],\n",
        "        temperature=0.1,\n",
        "        max_tokens=200\n",
        "    )\n",
        "\n",
        "    result_text = response.choices[0].message.content.strip()\n",
        "    if result_text.startswith(\"```\"):\n",
        "        result_text = result_text.split(\"```\")[1].replace(\"json\", \"\", 1)\n",
        "\n",
        "    data = json.loads(result_text)\n",
        "    return Intent(\n",
        "        IntentType(data.get(\"intent\", \"unknown\")),\n",
        "        float(data.get(\"confidence\", 0.8)),\n",
        "        data.get(\"slots\", {}),\n",
        "        text\n",
        "    )\n",
        "\n",
        "\n",
        "def parse_intent(text: str) -> Intent:\n",
        "    \"\"\"\n",
        "    Parse text into structured intent.\n",
        "\n",
        "    Priority:\n",
        "    1. Rule-based (instant, no API)\n",
        "    2. Claude (CLARISSA native)\n",
        "    3. OpenAI GPT-4\n",
        "    4. Fallback to unknown\n",
        "    \"\"\"\n",
        "    # Try rules first\n",
        "    rule_result = parse_intent_rules(text)\n",
        "    if rule_result is not None:\n",
        "        print(f\"   üìã Parsed with rules\")\n",
        "        return rule_result\n",
        "\n",
        "    # Try Claude (CLARISSA's native LLM)\n",
        "    if os.getenv('ANTHROPIC_API_KEY'):\n",
        "        try:\n",
        "            result = parse_with_claude(text)\n",
        "            print(f\"   ü§ñ Parsed with Claude\")\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è Claude error: {e}\")\n",
        "\n",
        "    # Try OpenAI\n",
        "    if os.getenv('OPENAI_API_KEY'):\n",
        "        try:\n",
        "            result = parse_with_openai(text)\n",
        "            print(f\"   ü§ñ Parsed with GPT-4\")\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è OpenAI error: {e}\")\n",
        "\n",
        "    # No LLM available\n",
        "    print(f\"   ‚ÑπÔ∏è No LLM available for complex command\")\n",
        "    return Intent(IntentType.UNKNOWN, 0.0, {}, text)\n",
        "\n",
        "print(\"üß† Intent parser ready\")\n",
        "print(\"   Priority: Rules ‚Üí Claude ‚Üí GPT-4 ‚Üí Fallback\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHNW0YAAurw_"
      },
      "source": [
        "### 2.3 Visualization Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i80CKwUnurw_"
      },
      "outputs": [],
      "source": [
        "# Create synthetic reservoir data for demo\n",
        "NX, NY, NZ = 10, 10, 5\n",
        "\n",
        "def generate_demo_data():\n",
        "    \"\"\"Generate synthetic reservoir properties.\"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Permeability with channel\n",
        "    perm = np.random.lognormal(mean=4.5, sigma=0.5, size=(NX, NY, NZ))\n",
        "    perm[3:7, :, :] *= 3  # High-perm channel\n",
        "\n",
        "    # Porosity correlated with perm\n",
        "    poro = 0.15 + 0.1 * (np.log(perm) - 4) / 2\n",
        "    poro = np.clip(poro, 0.05, 0.35)\n",
        "\n",
        "    # Water saturation (varies with time)\n",
        "    def get_saturation(time_days):\n",
        "        progress = min(time_days / 1800, 1.0)\n",
        "        sw = np.ones((NX, NY, NZ)) * 0.2  # Connate water\n",
        "        # Water front moving from injectors\n",
        "        for i in range(NX):\n",
        "            for j in range(NY):\n",
        "                dist = np.sqrt((i - NX//2)**2 + (j - NY//2)**2)\n",
        "                if dist < progress * NX * 0.7:\n",
        "                    sw[i, j, :] = 0.2 + 0.5 * (1 - dist / (NX * 0.7))\n",
        "        return np.clip(sw, 0.2, 0.8)\n",
        "\n",
        "    return {\n",
        "        'permeability': perm,\n",
        "        'porosity': poro,\n",
        "        'get_saturation': get_saturation\n",
        "    }\n",
        "\n",
        "DEMO_DATA = generate_demo_data()\n",
        "print(\"üìä Demo data generated\")\n",
        "print(f\"   Grid: {NX}√ó{NY}√ó{NZ} = {NX*NY*NZ} cells\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CECGcZnurxA"
      },
      "outputs": [],
      "source": [
        "def create_3d_visualization(prop_name: str, prop_data: np.ndarray) -> go.Figure:\n",
        "    \"\"\"Create 3D scatter plot of property.\"\"\"\n",
        "    x, y, z = [], [], []\n",
        "    values = []\n",
        "\n",
        "    for i in range(NX):\n",
        "        for j in range(NY):\n",
        "            for k in range(NZ):\n",
        "                x.append(i)\n",
        "                y.append(j)\n",
        "                z.append(k)\n",
        "                values.append(prop_data[i, j, k])\n",
        "\n",
        "    fig = go.Figure(data=go.Scatter3d(\n",
        "        x=x, y=y, z=z,\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=8,\n",
        "            color=values,\n",
        "            colorscale='Viridis',\n",
        "            colorbar=dict(title=prop_name.title()),\n",
        "            opacity=0.8\n",
        "        )\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"3D {prop_name.title()} Distribution\",\n",
        "        scene=dict(\n",
        "            xaxis_title=\"X\",\n",
        "            yaxis_title=\"Y\",\n",
        "            zaxis_title=\"Layer\",\n",
        "            aspectmode='cube'\n",
        "        ),\n",
        "        height=500\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def create_cross_section(prop_name: str, prop_data: np.ndarray, layer: int) -> go.Figure:\n",
        "    \"\"\"Create 2D heatmap cross-section.\"\"\"\n",
        "    layer_idx = max(0, min(layer - 1, NZ - 1))\n",
        "    data_2d = prop_data[:, :, layer_idx]\n",
        "\n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "        z=data_2d.T,\n",
        "        colorscale='Viridis',\n",
        "        colorbar=dict(title=prop_name.title())\n",
        "    ))\n",
        "\n",
        "    # Add well markers\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=[NX//2], y=[NY//2],\n",
        "        mode='markers+text',\n",
        "        marker=dict(size=15, color='blue', symbol='circle'),\n",
        "        text=['PROD1'], textposition='top center',\n",
        "        name='Producer'\n",
        "    ))\n",
        "\n",
        "    # Injectors at corners\n",
        "    inj_x = [1, 1, NX-2, NX-2]\n",
        "    inj_y = [1, NY-2, 1, NY-2]\n",
        "    inj_names = ['INJ1', 'INJ2', 'INJ3', 'INJ4']\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=inj_x, y=inj_y,\n",
        "        mode='markers+text',\n",
        "        marker=dict(size=12, color='red', symbol='triangle-up'),\n",
        "        text=inj_names, textposition='top center',\n",
        "        name='Injectors'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"{prop_name.title()} at Layer {layer}\",\n",
        "        xaxis_title=\"X\",\n",
        "        yaxis_title=\"Y\",\n",
        "        height=450\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "print(\"üé® Visualization functions ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnjJipOaurxA"
      },
      "source": [
        "### 2.4 Command Executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RehSY5zurxA"
      },
      "outputs": [],
      "source": [
        "def execute_intent(intent: Intent) -> VoiceResponse:\n",
        "    \"\"\"\n",
        "    Execute parsed intent and return response.\n",
        "\n",
        "    Args:\n",
        "        intent: Parsed Intent object\n",
        "\n",
        "    Returns:\n",
        "        VoiceResponse with text and optional visualization\n",
        "    \"\"\"\n",
        "    slots = intent.slots\n",
        "\n",
        "    if intent.type == IntentType.VISUALIZE_PROPERTY:\n",
        "        prop = slots.get('property', 'permeability')\n",
        "        layer = slots.get('layer')\n",
        "        time_days = slots.get('time_days', 500)\n",
        "        view_type = slots.get('view_type', '3d')\n",
        "\n",
        "        # Get property data\n",
        "        if 'saturation' in prop or prop == 'sw':\n",
        "            prop_data = DEMO_DATA['get_saturation'](time_days)\n",
        "            prop_name = 'water_saturation'\n",
        "        elif prop in ['permeability', 'perm']:\n",
        "            prop_data = DEMO_DATA['permeability']\n",
        "            prop_name = 'permeability'\n",
        "        elif prop in ['porosity', 'poro']:\n",
        "            prop_data = DEMO_DATA['porosity']\n",
        "            prop_name = 'porosity'\n",
        "        else:\n",
        "            prop_data = DEMO_DATA['permeability']\n",
        "            prop_name = 'permeability'\n",
        "\n",
        "        # Create visualization\n",
        "        if layer or 'cross' in str(view_type):\n",
        "            layer = layer or 3\n",
        "            fig = create_cross_section(prop_name, prop_data, layer)\n",
        "            text = f\"Showing {prop_name.replace('_', ' ')} at layer {layer}.\"\n",
        "        else:\n",
        "            fig = create_3d_visualization(prop_name, prop_data)\n",
        "            text = f\"Showing {prop_name.replace('_', ' ')} in 3D.\"\n",
        "\n",
        "        return VoiceResponse(True, text, intent, fig)\n",
        "\n",
        "    elif intent.type == IntentType.QUERY_VALUE:\n",
        "        prop = slots.get('property', 'oil_rate')\n",
        "\n",
        "        # Simulate query results\n",
        "        values = {\n",
        "            'oil_rate': ('1,250', 'bbl/day'),\n",
        "            'water_rate': ('450', 'bbl/day'),\n",
        "            'water_cut': ('26', '%'),\n",
        "            'pressure': ('3,450', 'psi'),\n",
        "            'bhp': ('3,450', 'psi'),\n",
        "            'cumulative_oil': ('2.3', 'MMSTB'),\n",
        "            'fopt': ('2.3', 'MMSTB'),\n",
        "        }\n",
        "\n",
        "        prop_key = prop.lower().replace(' ', '_')\n",
        "        if prop_key in values:\n",
        "            val, unit = values[prop_key]\n",
        "            text = f\"The {prop.replace('_', ' ')} is {val} {unit}.\"\n",
        "        else:\n",
        "            text = f\"I don't have data for {prop}.\"\n",
        "\n",
        "        return VoiceResponse(True, text, intent)\n",
        "\n",
        "    elif intent.type == IntentType.HELP:\n",
        "        text = \"\"\"You can say things like:\n",
        "‚Ä¢ \"Show me the permeability\"\n",
        "‚Ä¢ \"Show layer 3\"\n",
        "‚Ä¢ \"What's the oil rate?\"\n",
        "‚Ä¢ \"Show saturation at day 500\"\n",
        "‚Ä¢ \"Stop\" or \"Cancel\" to abort\"\"\"\n",
        "        return VoiceResponse(True, text, intent)\n",
        "\n",
        "    elif intent.type == IntentType.CANCEL:\n",
        "        return VoiceResponse(True, \"Cancelled.\", intent)\n",
        "\n",
        "    elif intent.type == IntentType.CONFIRM:\n",
        "        return VoiceResponse(True, \"Confirmed.\", intent)\n",
        "\n",
        "    else:\n",
        "        return VoiceResponse(\n",
        "            False,\n",
        "            \"I didn't understand that. Try saying 'help' for available commands.\",\n",
        "            intent\n",
        "        )\n",
        "\n",
        "print(\"‚ö° Command executor ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyCIkqSHurxA"
      },
      "source": [
        "## 3Ô∏è‚É£ Voice Pipeline\n",
        "\n",
        "The complete voice processing pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEtGbVCTurxA"
      },
      "outputs": [],
      "source": [
        "def process_voice_command(text_or_audio: str, is_audio: bool = False) -> VoiceResponse:\n",
        "    \"\"\"\n",
        "    Complete voice command processing pipeline.\n",
        "\n",
        "    Args:\n",
        "        text_or_audio: Either text command or path to audio file\n",
        "        is_audio: True if input is audio file path\n",
        "\n",
        "    Returns:\n",
        "        VoiceResponse with result\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "    # Step 1: Transcribe if audio\n",
        "    if is_audio:\n",
        "        print(\"üé§ Step 1: Transcribing audio...\")\n",
        "        try:\n",
        "            text = transcribe_audio(text_or_audio)\n",
        "            print(f\"   Transcription: \\\"{text}\\\"\")\n",
        "        except Exception as e:\n",
        "            return VoiceResponse(False, f\"Transcription failed: {e}\")\n",
        "    else:\n",
        "        text = text_or_audio\n",
        "        print(f\"üìù Input: \\\"{text}\\\"\")\n",
        "\n",
        "    # Step 2: Parse intent\n",
        "    print(\"\\nüß† Step 2: Parsing intent...\")\n",
        "    intent = parse_intent(text)\n",
        "    print(f\"   Intent: {intent.type.value}\")\n",
        "    print(f\"   Confidence: {intent.confidence:.0%}\")\n",
        "    if intent.slots:\n",
        "        print(f\"   Slots: {intent.slots}\")\n",
        "\n",
        "    # Step 3: Execute\n",
        "    print(\"\\n‚ö° Step 3: Executing command...\")\n",
        "    response = execute_intent(intent)\n",
        "\n",
        "    # Step 4: Response\n",
        "    print(f\"\\nüí¨ Response: {response.text}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    return response\n",
        "\n",
        "print(\"üöÄ Voice pipeline ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUG9dxZPurxB"
      },
      "source": [
        "## 4Ô∏è‚É£ Interactive Demo\n",
        "\n",
        "Try voice commands! (Text mode - type what you would say)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1sm_soxurxB"
      },
      "outputs": [],
      "source": [
        "# Demo 1: Show permeability in 3D\n",
        "response = process_voice_command(\"show me the permeability\")\n",
        "if response.visualization:\n",
        "    response.visualization.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K2igmMBurxB"
      },
      "outputs": [],
      "source": [
        "# Demo 2: Cross-section at specific layer\n",
        "response = process_voice_command(\"show layer 3\")\n",
        "if response.visualization:\n",
        "    response.visualization.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VaGfngGurxB"
      },
      "outputs": [],
      "source": [
        "# Demo 3: Query a value\n",
        "response = process_voice_command(\"what is the water cut?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTrsyPQpurxB"
      },
      "outputs": [],
      "source": [
        "# Demo 4: Show saturation at specific time\n",
        "response = process_voice_command(\"show water saturation at day 1000\")\n",
        "if response.visualization:\n",
        "    response.visualization.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNLNjoTvurxB"
      },
      "outputs": [],
      "source": [
        "# Demo 5: Help command\n",
        "response = process_voice_command(\"help\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVz3DPi5urxB"
      },
      "source": [
        "## 5Ô∏è‚É£ Interactive Widget\n",
        "\n",
        "Try your own commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkAJyRPWurxB"
      },
      "outputs": [],
      "source": [
        "# Create interactive widget\n",
        "text_input = widgets.Text(\n",
        "    placeholder='Type a command (e.g., \"show porosity in 3D\")',\n",
        "    description='üé§ Say:',\n",
        "    layout=widgets.Layout(width='80%')\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_submit(change):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        if text_input.value:\n",
        "            response = process_voice_command(text_input.value)\n",
        "            if response.visualization:\n",
        "                display(response.visualization)\n",
        "\n",
        "text_input.on_submit(lambda x: on_submit(x))\n",
        "\n",
        "submit_btn = widgets.Button(description=\"Process\", button_style='primary')\n",
        "submit_btn.on_click(lambda x: on_submit(x))\n",
        "\n",
        "display(widgets.HBox([text_input, submit_btn]))\n",
        "display(output)\n",
        "\n",
        "print(\"\\nüí° Type a command and press Enter or click Process\")\n",
        "print(\"\\nExample commands:\")\n",
        "print('  ‚Ä¢ \"show me porosity\"')\n",
        "print('  ‚Ä¢ \"show saturation at layer 2\"')\n",
        "print('  ‚Ä¢ \"what is the oil rate\"')\n",
        "print('  ‚Ä¢ \"help\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_zxjPTDurxB"
      },
      "source": [
        "## 6Ô∏è‚É£ Audio File Demo\n",
        "\n",
        "Upload an audio file to test real speech-to-text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQmkSjYiurxC"
      },
      "outputs": [],
      "source": [
        "# File upload widget\n",
        "from google.colab import files\n",
        "\n",
        "def process_uploaded_audio():\n",
        "    \"\"\"Upload and process an audio file.\"\"\"\n",
        "    print(\"üìÅ Upload an audio file (WAV, MP3, M4A)...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"\\nüéµ Processing: {filename}\")\n",
        "        response = process_voice_command(filename, is_audio=True)\n",
        "\n",
        "        if response.visualization:\n",
        "            display(response.visualization)\n",
        "\n",
        "        return response\n",
        "\n",
        "# Uncomment to test with audio upload:\n",
        "# process_uploaded_audio()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaDjnzo_urxC"
      },
      "source": [
        "## 7Ô∏è‚É£ Test Suite\n",
        "\n",
        "Evaluate intent recognition accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NgtQPOaurxC"
      },
      "outputs": [],
      "source": [
        "# Test cases\n",
        "TEST_CASES = [\n",
        "    (\"show me the permeability\", \"visualize_property\", {\"property\": \"permeability\"}),\n",
        "    (\"display porosity in 3D\", \"visualize_property\", {\"property\": \"porosity\"}),\n",
        "    (\"show layer 3\", \"visualize_property\", {\"layer\": 3}),\n",
        "    (\"what is the oil rate\", \"query_value\", {\"property\": \"oil_rate\"}),\n",
        "    (\"what's the water cut\", \"query_value\", {\"property\": \"water_cut\"}),\n",
        "    (\"help\", \"help\", {}),\n",
        "    (\"stop\", \"cancel\", {}),\n",
        "    (\"yes\", \"confirm\", {}),\n",
        "]\n",
        "\n",
        "def run_tests():\n",
        "    \"\"\"Run test suite and report accuracy.\"\"\"\n",
        "    print(\"üß™ Running intent recognition tests...\\n\")\n",
        "\n",
        "    passed = 0\n",
        "    failed = 0\n",
        "\n",
        "    for text, expected_intent, expected_slots in TEST_CASES:\n",
        "        intent = parse_intent(text)\n",
        "\n",
        "        intent_match = intent.type.value == expected_intent\n",
        "\n",
        "        if intent_match:\n",
        "            passed += 1\n",
        "            status = \"‚úÖ\"\n",
        "        else:\n",
        "            failed += 1\n",
        "            status = \"‚ùå\"\n",
        "\n",
        "        print(f\"{status} \\\"{text}\\\"\")\n",
        "        print(f\"   Expected: {expected_intent}, Got: {intent.type.value}\")\n",
        "        if not intent_match:\n",
        "            print(f\"   Confidence: {intent.confidence:.0%}\")\n",
        "        print()\n",
        "\n",
        "    total = passed + failed\n",
        "    accuracy = passed / total * 100 if total > 0 else 0\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(f\"üìä Results: {passed}/{total} passed ({accuracy:.0f}% accuracy)\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Uncomment to run tests (requires API key):\n",
        "# run_tests()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbBdH3XurxC"
      },
      "source": [
        "## üìö Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **Speech-to-Text** - Whisper API transcription with domain vocabulary\n",
        "2. **Intent Parsing** - LLM-based command understanding\n",
        "3. **Slot Extraction** - Property, layer, time parameters\n",
        "4. **Visualization** - 3D and cross-section views triggered by voice\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Full Integration**: Connect to OPM Flow simulations\n",
        "- **Live Microphone**: Browser-based audio capture\n",
        "- **TTS Response**: Audio feedback with OpenAI TTS\n",
        "- **Offline Mode**: Local Whisper for air-gapped deployments\n",
        "\n",
        "### Resources\n",
        "\n",
        "- [Voice Input Tutorial](../guides/voice-input-tutorial.md)\n",
        "- [ADR-028: Voice Architecture](../../architecture/adr/ADR-028-voice-input-architecture.md)\n",
        "- [CLARISSA Source Code](https://gitlab.com/wolfram_laube/blauweiss_llc/clarissa)\n",
        "\n",
        "---\n",
        "\n",
        "*Part of CLARISSA - Conversational Language Agent for Reservoir Simulation*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}