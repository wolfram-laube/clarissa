{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6cCX74Durw6"
      },
      "source": [
        "# \ud83c\udfa4 CLARISSA Voice Input Showcase\n",
        "\n",
        "**Talk to Your Reservoir Simulation**\n",
        "\n",
        "This notebook demonstrates CLARISSA's voice interface with **professional waveform visualization** - control reservoir simulations through natural speech.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wolfram-laube/clarissa/blob/main/docs/tutorials/notebooks/16_Voice_Input_Showcase.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "## \u2728 Features\n",
        "\n",
        "- **Real-time Waveform Animation** - 30-bar WebAudio visualizer\n",
        "- **Speech-to-Text** - OpenAI Whisper integration\n",
        "- **Intent Recognition** - LLM-based command parsing\n",
        "- **3D Visualization** - Plotly reservoir property displays\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1\ufe0f\u20e3 Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q openai anthropic plotly numpy ipywidgets\n",
        "\n",
        "print(\"\u2705 Packages installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import base64\n",
        "import tempfile\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Any, Optional, List\n",
        "from enum import Enum\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from IPython.display import display, HTML, Audio, Javascript\n",
        "import ipywidgets as widgets\n",
        "\n",
        "print(\"\u2705 Imports ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# \ud83d\udd11 API Key Setup\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "\n",
        "# Option 1: Colab secrets (recommended)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    \n",
        "    try:\n",
        "        os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "        print(\"\u2705 OpenAI API key loaded from Colab secrets\")\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "    try:\n",
        "        os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
        "        print(\"\u2705 Anthropic API key loaded from Colab secrets\")\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "except ImportError:\n",
        "    print(\"\u2139\ufe0f  Not running in Colab - set API keys manually\")\n",
        "\n",
        "# Check what's available\n",
        "openai_key = os.getenv('OPENAI_API_KEY')\n",
        "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
        "\n",
        "print()\n",
        "print(\"\u2550\" * 50)\n",
        "print(\"Configuration Status:\")\n",
        "print(\"\u2550\" * 50)\n",
        "\n",
        "if openai_key:\n",
        "    print(\"\ud83d\udfe2 Whisper STT: Available\")\n",
        "    print(\"\ud83d\udfe2 GPT-4 Intent Parsing: Available\")\n",
        "else:\n",
        "    print(\"\ud83d\udfe1 Whisper STT: Not available (no OpenAI key)\")\n",
        "    print(\"   \u2192 Text input mode only\")\n",
        "\n",
        "if anthropic_key:\n",
        "    print(\"\ud83d\udfe2 Claude Intent Parsing: Available\")\n",
        "\n",
        "print(\"\u2550\" * 50)\n",
        "print()\n",
        "print(\"\ud83d\udca1 To add API keys in Colab:\")\n",
        "print(\"   1. Click \ud83d\udd11 Secrets (left sidebar)\")\n",
        "print(\"   2. Add: OPENAI_API_KEY\")\n",
        "print(\"   3. Enable notebook access\")\n",
        "print(\"   4. Re-run this cell\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2\ufe0f\u20e3 Core Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# Intent Types & Data Classes\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "\n",
        "class IntentType(Enum):\n",
        "    VISUALIZE_PROPERTY = \"visualize_property\"\n",
        "    QUERY_VALUE = \"query_value\"\n",
        "    NAVIGATE = \"navigate\"\n",
        "    HELP = \"help\"\n",
        "    CANCEL = \"cancel\"\n",
        "    CONFIRM = \"confirm\"\n",
        "    UNKNOWN = \"unknown\"\n",
        "\n",
        "@dataclass\n",
        "class Intent:\n",
        "    type: IntentType\n",
        "    confidence: float\n",
        "    slots: Dict[str, Any] = field(default_factory=dict)\n",
        "    raw_text: str = \"\"\n",
        "\n",
        "@dataclass\n",
        "class VoiceResponse:\n",
        "    success: bool\n",
        "    text: str\n",
        "    intent: Optional[Intent] = None\n",
        "    visualization: Optional[go.Figure] = None\n",
        "\n",
        "print(\"\u2705 Data classes defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# Demo Reservoir Data\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "\n",
        "NX, NY, NZ = 10, 10, 5\n",
        "\n",
        "def generate_demo_data():\n",
        "    \"\"\"Generate synthetic reservoir properties.\"\"\"\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # Permeability with channel (high-perm streak)\n",
        "    perm = np.random.lognormal(5, 1, (NX, NY, NZ))\n",
        "    for j in range(3, 7):\n",
        "        perm[4:7, j, :] *= 5  # High-perm channel\n",
        "    \n",
        "    # Porosity correlated with permeability\n",
        "    poro = 0.1 + 0.2 * (np.log(perm) - np.log(perm).min()) / (np.log(perm).max() - np.log(perm).min())\n",
        "    poro += np.random.normal(0, 0.02, poro.shape)\n",
        "    poro = np.clip(poro, 0.05, 0.35)\n",
        "    \n",
        "    # Water saturation (waterflood front)\n",
        "    sw = np.zeros((NX, NY, NZ))\n",
        "    for i in range(NX):\n",
        "        sw[i, :, :] = 0.2 + 0.6 * (i / NX)\n",
        "    sw += np.random.normal(0, 0.05, sw.shape)\n",
        "    sw = np.clip(sw, 0.2, 0.8)\n",
        "    \n",
        "    # Pressure declining toward producer\n",
        "    pressure = np.zeros((NX, NY, NZ))\n",
        "    for i in range(NX):\n",
        "        for j in range(NY):\n",
        "            pressure[i, j, :] = 4000 - 500 * np.sqrt((i/NX)**2 + (j/NY)**2)\n",
        "    \n",
        "    return {\n",
        "        'permeability': perm,\n",
        "        'porosity': poro,\n",
        "        'water_saturation': sw,\n",
        "        'pressure': pressure\n",
        "    }\n",
        "\n",
        "DEMO_DATA = generate_demo_data()\n",
        "print(\"\u2705 Demo reservoir data generated (10\u00d710\u00d75 grid)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# Intent Parser (Rule-based + LLM fallback)\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "import re\n",
        "\n",
        "def parse_intent(text: str) -> Intent:\n",
        "    \"\"\"Parse natural language into structured intent.\"\"\"\n",
        "    text_lower = text.lower().strip()\n",
        "    slots = {}\n",
        "    \n",
        "    # Cancel/Stop\n",
        "    if any(kw in text_lower for kw in [\"cancel\", \"stop\", \"abort\", \"quit\", \"nevermind\"]):\n",
        "        return Intent(IntentType.CANCEL, 1.0, {}, text)\n",
        "    \n",
        "    # Confirm\n",
        "    if text_lower in [\"yes\", \"yeah\", \"yep\", \"confirm\", \"ok\", \"okay\", \"do it\", \"go ahead\"]:\n",
        "        return Intent(IntentType.CONFIRM, 1.0, {}, text)\n",
        "    \n",
        "    # Help\n",
        "    if text_lower == \"help\" or \"what can\" in text_lower or \"how do\" in text_lower:\n",
        "        return Intent(IntentType.HELP, 1.0, {}, text)\n",
        "    \n",
        "    # Visualization\n",
        "    viz_keywords = [\"show\", \"display\", \"visualize\", \"plot\", \"view\", \"see\"]\n",
        "    if any(kw in text_lower for kw in viz_keywords):\n",
        "        # Extract property\n",
        "        if \"perm\" in text_lower:\n",
        "            slots[\"property\"] = \"permeability\"\n",
        "        elif \"poro\" in text_lower:\n",
        "            slots[\"property\"] = \"porosity\"\n",
        "        elif \"saturation\" in text_lower or \" sw\" in text_lower or \"water sat\" in text_lower:\n",
        "            slots[\"property\"] = \"water_saturation\"\n",
        "        elif \"pressure\" in text_lower:\n",
        "            slots[\"property\"] = \"pressure\"\n",
        "        \n",
        "        # Extract layer\n",
        "        layer_match = re.search(r'layer\\s*(\\d+)', text_lower)\n",
        "        if layer_match:\n",
        "            slots[\"layer\"] = int(layer_match.group(1))\n",
        "        \n",
        "        # Extract time\n",
        "        time_match = re.search(r'(?:day|time|t=?)\\s*(\\d+)', text_lower)\n",
        "        if time_match:\n",
        "            slots[\"time_days\"] = int(time_match.group(1))\n",
        "        \n",
        "        # Default to permeability if no property specified\n",
        "        if not slots.get(\"property\") and not slots.get(\"layer\"):\n",
        "            slots[\"property\"] = \"permeability\"\n",
        "        \n",
        "        return Intent(IntentType.VISUALIZE_PROPERTY, 0.95, slots, text)\n",
        "    \n",
        "    # Query\n",
        "    if any(kw in text_lower for kw in [\"what\", \"how much\", \"tell me\", \"get\"]):\n",
        "        if \"oil rate\" in text_lower or \"fopr\" in text_lower:\n",
        "            slots[\"property\"] = \"oil_rate\"\n",
        "        elif \"water cut\" in text_lower or \"wct\" in text_lower:\n",
        "            slots[\"property\"] = \"water_cut\"\n",
        "        elif \"pressure\" in text_lower or \"bhp\" in text_lower:\n",
        "            slots[\"property\"] = \"pressure\"\n",
        "        elif \"gor\" in text_lower or \"gas oil\" in text_lower:\n",
        "            slots[\"property\"] = \"gor\"\n",
        "        elif \"cumulative\" in text_lower or \"total\" in text_lower:\n",
        "            slots[\"property\"] = \"cumulative_oil\"\n",
        "        else:\n",
        "            slots[\"property\"] = \"value\"\n",
        "        \n",
        "        return Intent(IntentType.QUERY_VALUE, 0.9, slots, text)\n",
        "    \n",
        "    return Intent(IntentType.UNKNOWN, 0.3, {}, text)\n",
        "\n",
        "# Test\n",
        "test_result = parse_intent(\"show me the permeability\")\n",
        "print(f\"\u2705 Intent parser ready\")\n",
        "print(f\"   Test: 'show me the permeability' \u2192 {test_result.type.value}, slots={test_result.slots}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# Visualization Functions\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "\n",
        "def create_3d_visualization(prop_name: str, prop_data: np.ndarray) -> go.Figure:\n",
        "    \"\"\"Create 3D scatter plot of property.\"\"\"\n",
        "    x, y, z, values = [], [], [], []\n",
        "    \n",
        "    for i in range(NX):\n",
        "        for j in range(NY):\n",
        "            for k in range(NZ):\n",
        "                x.append(i)\n",
        "                y.append(j)\n",
        "                z.append(k)\n",
        "                values.append(prop_data[i, j, k])\n",
        "    \n",
        "    # Color scale based on property\n",
        "    colorscale = 'Viridis' if prop_name != 'pressure' else 'RdYlBu'\n",
        "    \n",
        "    fig = go.Figure(data=[go.Scatter3d(\n",
        "        x=x, y=y, z=z,\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=8,\n",
        "            color=values,\n",
        "            colorscale=colorscale,\n",
        "            colorbar=dict(title=prop_name.replace('_', ' ').title()),\n",
        "            opacity=0.8\n",
        "        )\n",
        "    )])\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=f\"3D {prop_name.replace('_', ' ').title()} Distribution\",\n",
        "        scene=dict(\n",
        "            xaxis_title='I',\n",
        "            yaxis_title='J',\n",
        "            zaxis_title='K'\n",
        "        ),\n",
        "        template='plotly_dark',\n",
        "        height=500\n",
        "    )\n",
        "    \n",
        "    return fig\n",
        "\n",
        "def create_cross_section(prop_name: str, prop_data: np.ndarray, layer: int) -> go.Figure:\n",
        "    \"\"\"Create 2D heatmap at specified layer.\"\"\"\n",
        "    layer = max(1, min(layer, NZ)) - 1  # Convert to 0-indexed\n",
        "    \n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "        z=prop_data[:, :, layer],\n",
        "        colorscale='Viridis',\n",
        "        colorbar=dict(title=prop_name.replace('_', ' ').title())\n",
        "    ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=f\"{prop_name.replace('_', ' ').title()} - Layer {layer + 1}\",\n",
        "        xaxis_title='J',\n",
        "        yaxis_title='I',\n",
        "        template='plotly_dark',\n",
        "        height=450\n",
        "    )\n",
        "    \n",
        "    return fig\n",
        "\n",
        "print(\"\ud83c\udfa8 Visualization functions ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# Command Executor\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "\n",
        "def execute_intent(intent: Intent) -> VoiceResponse:\n",
        "    \"\"\"Execute parsed intent and return response.\"\"\"\n",
        "    slots = intent.slots\n",
        "    \n",
        "    if intent.type == IntentType.VISUALIZE_PROPERTY:\n",
        "        prop = slots.get('property', 'permeability')\n",
        "        layer = slots.get('layer')\n",
        "        \n",
        "        # Get data\n",
        "        if prop in DEMO_DATA:\n",
        "            prop_data = DEMO_DATA[prop]\n",
        "            prop_name = prop\n",
        "        else:\n",
        "            prop_data = DEMO_DATA['permeability']\n",
        "            prop_name = 'permeability'\n",
        "        \n",
        "        # Create visualization\n",
        "        if layer:\n",
        "            fig = create_cross_section(prop_name, prop_data, layer)\n",
        "            text = f\"Showing {prop_name.replace('_', ' ')} at layer {layer}.\"\n",
        "        else:\n",
        "            fig = create_3d_visualization(prop_name, prop_data)\n",
        "            text = f\"Showing {prop_name.replace('_', ' ')} in 3D.\"\n",
        "        \n",
        "        return VoiceResponse(True, text, intent, fig)\n",
        "    \n",
        "    elif intent.type == IntentType.QUERY_VALUE:\n",
        "        prop = slots.get('property', 'value')\n",
        "        \n",
        "        # Simulated values\n",
        "        values = {\n",
        "            'oil_rate': '2,450 STB/day',\n",
        "            'water_cut': '35%',\n",
        "            'pressure': '3,200 psi',\n",
        "            'gor': '850 scf/STB',\n",
        "            'cumulative_oil': '1.2 MMSTB'\n",
        "        }\n",
        "        \n",
        "        value = values.get(prop, 'Unknown')\n",
        "        return VoiceResponse(True, f\"The {prop.replace('_', ' ')} is {value}.\", intent)\n",
        "    \n",
        "    elif intent.type == IntentType.HELP:\n",
        "        help_text = \"\"\"Available commands:\n",
        "\u2022 \"Show permeability\" - 3D property view\n",
        "\u2022 \"Show layer 3\" - Cross-section at layer\n",
        "\u2022 \"What is the water cut?\" - Query values\n",
        "\u2022 \"Show saturation at day 500\" - Time-specific view\"\"\"\n",
        "        return VoiceResponse(True, help_text, intent)\n",
        "    \n",
        "    elif intent.type == IntentType.CANCEL:\n",
        "        return VoiceResponse(True, \"Operation cancelled.\", intent)\n",
        "    \n",
        "    elif intent.type == IntentType.CONFIRM:\n",
        "        return VoiceResponse(True, \"Confirmed! Executing...\", intent)\n",
        "    \n",
        "    else:\n",
        "        return VoiceResponse(False, \"I didn't understand. Try 'show permeability' or 'help'.\", intent)\n",
        "\n",
        "print(\"\u26a1 Command executor ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3\ufe0f\u20e3 \ud83c\udfa4 Voice Recording with Waveform Visualization\n",
        "\n",
        "**Professional recording interface with real-time audio visualization!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# \ud83c\udfa4 COLAB-COMPATIBLE VOICE RECORDER\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# \n",
        "# This uses the proven Colab audio pattern that works with getUserMedia()\n",
        "# Reference: https://gist.github.com/korakot/c21c3476c024ad6d56d5f48b0bca92be\n",
        "#\n",
        "\n",
        "from IPython.display import display, Javascript, HTML, Audio\n",
        "from base64 import b64decode\n",
        "import os\n",
        "\n",
        "# Check if we're in Colab\n",
        "try:\n",
        "    from google.colab import output\n",
        "    IN_COLAB = True\n",
        "    print(\"\u2705 Running in Google Colab - microphone access available\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"\u2139\ufe0f  Not in Colab - use the GitLab Pages demo for voice input:\")\n",
        "    print(\"   https://irena-40cc50.gitlab.io/demos/voice-demo.html\")\n",
        "\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# JavaScript code for audio recording (must be injected first, then called)\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "\n",
        "RECORDER_JS = \"\"\"\n",
        "const sleep = time => new Promise(resolve => setTimeout(resolve, time));\n",
        "\n",
        "const b2text = blob => new Promise((resolve, reject) => {\n",
        "    const reader = new FileReader();\n",
        "    reader.onloadend = e => resolve(e.target.result);\n",
        "    reader.onerror = e => reject(new Error('Failed to read blob'));\n",
        "    reader.readAsDataURL(blob);\n",
        "});\n",
        "\n",
        "// Main recording function with visual countdown\n",
        "var clarissaRecord = (durationMs) => new Promise(async (resolve, reject) => {\n",
        "    // Create UI\n",
        "    const container = document.createElement('div');\n",
        "    container.id = 'clarissa-recorder-ui';\n",
        "    container.innerHTML = `\n",
        "        <div style=\"font-family: -apple-system, BlinkMacSystemFont, sans-serif; \n",
        "                    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);\n",
        "                    border-radius: 16px; padding: 25px; max-width: 400px; margin: 15px auto;\n",
        "                    box-shadow: 0 8px 32px rgba(0,0,0,0.4); color: white; text-align: center;\">\n",
        "            <h3 style=\"margin: 0 0 10px 0; background: linear-gradient(90deg, #e94560, #0f3460);\n",
        "                       -webkit-background-clip: text; -webkit-text-fill-color: transparent;\">\n",
        "                \ud83c\udfa4 CLARISSA Voice Input\n",
        "            </h3>\n",
        "            <div id=\"cr-status\" style=\"color: #aaa; margin: 10px 0;\">Initializing...</div>\n",
        "            <div id=\"cr-timer\" style=\"font-size: 36px; font-weight: bold; color: #4caf50; margin: 15px 0;\">\n",
        "                --:--\n",
        "            </div>\n",
        "            <div id=\"cr-waveform\" style=\"height: 50px; background: rgba(0,0,0,0.3); border-radius: 8px;\n",
        "                                         display: flex; align-items: center; justify-content: center; gap: 2px;\n",
        "                                         margin: 15px 0; padding: 0 10px;\">\n",
        "            </div>\n",
        "            <button id=\"cr-stop\" style=\"padding: 12px 30px; font-size: 16px; font-weight: 600;\n",
        "                                        background: linear-gradient(145deg, #e94560, #c23a51);\n",
        "                                        color: white; border: none; border-radius: 25px; cursor: pointer;\n",
        "                                        display: none;\">\n",
        "                \u23f9\ufe0f Stop Recording\n",
        "            </button>\n",
        "        </div>\n",
        "    `;\n",
        "    document.body.appendChild(container);\n",
        "    \n",
        "    const status = document.getElementById('cr-status');\n",
        "    const timer = document.getElementById('cr-timer');\n",
        "    const waveform = document.getElementById('cr-waveform');\n",
        "    const stopBtn = document.getElementById('cr-stop');\n",
        "    \n",
        "    // Create waveform bars\n",
        "    for (let i = 0; i < 25; i++) {\n",
        "        const bar = document.createElement('div');\n",
        "        bar.className = 'cr-bar';\n",
        "        bar.style.cssText = 'width: 4px; height: 10px; background: linear-gradient(180deg, #e94560, #0f3460); border-radius: 2px; transition: height 0.05s;';\n",
        "        waveform.appendChild(bar);\n",
        "    }\n",
        "    const bars = waveform.querySelectorAll('.cr-bar');\n",
        "    \n",
        "    let stream, recorder, audioContext, analyser, dataArray, animationId, timerInterval;\n",
        "    \n",
        "    try {\n",
        "        status.textContent = '\ud83d\udd04 Requesting microphone...';\n",
        "        \n",
        "        stream = await navigator.mediaDevices.getUserMedia({ \n",
        "            audio: { channelCount: 1, sampleRate: 16000, echoCancellation: true, noiseSuppression: true }\n",
        "        });\n",
        "        \n",
        "        // Setup audio analysis\n",
        "        audioContext = new AudioContext();\n",
        "        analyser = audioContext.createAnalyser();\n",
        "        const source = audioContext.createMediaStreamSource(stream);\n",
        "        source.connect(analyser);\n",
        "        analyser.fftSize = 64;\n",
        "        dataArray = new Uint8Array(analyser.frequencyBinCount);\n",
        "        \n",
        "        // Start recording\n",
        "        recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });\n",
        "        const chunks = [];\n",
        "        recorder.ondataavailable = e => chunks.push(e.data);\n",
        "        recorder.start(100);\n",
        "        \n",
        "        // Update UI\n",
        "        status.innerHTML = '\ud83d\udd34 <b>Recording...</b> Speak now!';\n",
        "        status.style.color = '#e94560';\n",
        "        stopBtn.style.display = 'inline-block';\n",
        "        \n",
        "        // Timer\n",
        "        let seconds = 0;\n",
        "        timerInterval = setInterval(() => {\n",
        "            seconds++;\n",
        "            const mins = Math.floor(seconds / 60);\n",
        "            const secs = seconds % 60;\n",
        "            timer.textContent = mins.toString().padStart(2, '0') + ':' + secs.toString().padStart(2, '0');\n",
        "        }, 1000);\n",
        "        \n",
        "        // Waveform animation\n",
        "        function animate() {\n",
        "            analyser.getByteFrequencyData(dataArray);\n",
        "            bars.forEach((bar, i) => {\n",
        "                const value = dataArray[i] || 0;\n",
        "                bar.style.height = Math.max(8, value / 4) + 'px';\n",
        "            });\n",
        "            animationId = requestAnimationFrame(animate);\n",
        "        }\n",
        "        animate();\n",
        "        \n",
        "        // Wait for stop button or timeout\n",
        "        await new Promise(res => {\n",
        "            stopBtn.onclick = () => res('button');\n",
        "            setTimeout(() => res('timeout'), durationMs);\n",
        "        });\n",
        "        \n",
        "        // Cleanup\n",
        "        clearInterval(timerInterval);\n",
        "        cancelAnimationFrame(animationId);\n",
        "        recorder.stop();\n",
        "        stream.getTracks().forEach(t => t.stop());\n",
        "        \n",
        "        status.textContent = '\u23f3 Processing...';\n",
        "        status.style.color = '#aaa';\n",
        "        stopBtn.style.display = 'none';\n",
        "        \n",
        "        // Wait for data\n",
        "        await new Promise(res => recorder.onstop = res);\n",
        "        const blob = new Blob(chunks, { type: 'audio/webm' });\n",
        "        const base64 = await b2text(blob);\n",
        "        \n",
        "        status.textContent = '\u2705 Recording complete!';\n",
        "        status.style.color = '#4caf50';\n",
        "        \n",
        "        // Remove UI after delay\n",
        "        setTimeout(() => container.remove(), 2000);\n",
        "        \n",
        "        audioContext.close();\n",
        "        resolve(base64);\n",
        "        \n",
        "    } catch (err) {\n",
        "        status.innerHTML = '\u274c Error: ' + err.message;\n",
        "        status.style.color = '#ff6b6b';\n",
        "        console.error('Recording error:', err);\n",
        "        setTimeout(() => container.remove(), 3000);\n",
        "        reject(err);\n",
        "    }\n",
        "});\n",
        "\"\"\"\n",
        "\n",
        "print(\"\u2705 Voice recorder code ready!\")\n",
        "print(\"   Run the next cell to start recording.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# \ud83c\udf99\ufe0f RECORD VOICE COMMAND  \n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "\n",
        "def record_voice_command(max_duration_seconds=30):\n",
        "    \"\"\"\n",
        "    Record voice with visual feedback and return audio data.\n",
        "    \n",
        "    Args:\n",
        "        max_duration_seconds: Maximum recording time (default 30s)\n",
        "    \n",
        "    Returns:\n",
        "        bytes: Audio data (webm format) or None on error\n",
        "    \"\"\"\n",
        "    if not IN_COLAB:\n",
        "        print(\"\u274c Voice recording only works in Google Colab!\")\n",
        "        print(\"   Use the web demo instead: https://irena-40cc50.gitlab.io/demos/voice-demo.html\")\n",
        "        return None\n",
        "    \n",
        "    print(\"\u2550\" * 60)\n",
        "    print(\"\ud83c\udfa4 CLARISSA Voice Input\")\n",
        "    print(\"\u2550\" * 60)\n",
        "    print()\n",
        "    print(\"\ud83d\udccb Instructions:\")\n",
        "    print(\"   1. Allow microphone access when prompted\")\n",
        "    print(\"   2. Speak your command clearly\")\n",
        "    print(\"   3. Click 'Stop Recording' when done\")\n",
        "    print()\n",
        "    \n",
        "    try:\n",
        "        # IMPORTANT: Inject JS first, then call the function\n",
        "        # This is the key pattern that makes Colab audio work!\n",
        "        display(Javascript(RECORDER_JS))\n",
        "        \n",
        "        # Call the recording function via eval_js\n",
        "        result = output.eval_js(f'clarissaRecord({max_duration_seconds * 1000})')\n",
        "        \n",
        "        if not result or not result.startswith('data:'):\n",
        "            print(\"\u274c No audio data received\")\n",
        "            return None\n",
        "        \n",
        "        # Decode audio\n",
        "        audio_data = result.split(',')[1]\n",
        "        audio_bytes = b64decode(audio_data)\n",
        "        print(f\"\\n\u2705 Recorded {len(audio_bytes):,} bytes of audio\")\n",
        "        \n",
        "        # Playback\n",
        "        print(\"\\n\ud83d\udd0a Your recording:\")\n",
        "        display(Audio(audio_bytes, autoplay=False))\n",
        "        \n",
        "        return audio_bytes\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n\u274c Recording failed: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def transcribe_audio(audio_bytes, openai_client=None):\n",
        "    \"\"\"\n",
        "    Transcribe audio using OpenAI Whisper.\n",
        "    \n",
        "    Args:\n",
        "        audio_bytes: Audio data (webm format)\n",
        "        openai_client: OpenAI client instance\n",
        "    \n",
        "    Returns:\n",
        "        str: Transcription text or None\n",
        "    \"\"\"\n",
        "    if audio_bytes is None:\n",
        "        return None\n",
        "    \n",
        "    if openai_client is None:\n",
        "        api_key = os.getenv('OPENAI_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"\u26a0\ufe0f  No OpenAI API key found - set OPENAI_API_KEY to enable transcription\")\n",
        "            return None\n",
        "        from openai import OpenAI\n",
        "        openai_client = OpenAI(api_key=api_key)\n",
        "    \n",
        "    print(\"\\n\ud83d\udd04 Transcribing with Whisper...\")\n",
        "    \n",
        "    import tempfile\n",
        "    with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as f:\n",
        "        f.write(audio_bytes)\n",
        "        temp_path = f.name\n",
        "    \n",
        "    try:\n",
        "        with open(temp_path, 'rb') as audio_file:\n",
        "            transcript = openai_client.audio.transcriptions.create(\n",
        "                model=\"whisper-1\",\n",
        "                file=audio_file,\n",
        "                language=\"en\",\n",
        "                prompt=\"Reservoir simulation: permeability, porosity, pressure, saturation, water cut, oil rate, layers, wells, SPE10, aquifer\"\n",
        "            )\n",
        "        \n",
        "        print(f\"\\n\ud83d\udcdd Transcription:\")\n",
        "        print(f'   \"{transcript.text}\"')\n",
        "        return transcript.text\n",
        "        \n",
        "    finally:\n",
        "        os.unlink(temp_path)\n",
        "\n",
        "\n",
        "# Quick helper function\n",
        "def voice_command(max_duration=30):\n",
        "    \"\"\"Record and transcribe in one step.\"\"\"\n",
        "    audio = record_voice_command(max_duration)\n",
        "    if audio:\n",
        "        return transcribe_audio(audio)\n",
        "    return None\n",
        "\n",
        "\n",
        "print(\"\u2705 Voice command functions ready!\")\n",
        "print()\n",
        "print(\"Usage:\")\n",
        "print(\"   audio = record_voice_command()      # Just record\")\n",
        "print(\"   text = voice_command()              # Record + transcribe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4\ufe0f\u20e3 Text Input Alternative\n",
        "\n",
        "If microphone doesn't work, use text input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# \ud83d\udcdd TEXT INPUT DEMO\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "\n",
        "def process_text_command(text: str):\n",
        "    \"\"\"Process a text command through CLARISSA.\"\"\"\n",
        "    print(f'\ud83d\udcdd Command: \"{text}\"')\n",
        "    print()\n",
        "    \n",
        "    intent = parse_intent(text)\n",
        "    print(f\"\ud83c\udfaf Intent: {intent.type.value}\")\n",
        "    print(f\"\ud83d\udcca Confidence: {intent.confidence:.0%}\")\n",
        "    if intent.slots:\n",
        "        print(f\"\ud83d\udce6 Slots: {intent.slots}\")\n",
        "    print()\n",
        "    \n",
        "    response = execute_intent(intent)\n",
        "    print(f\"\ud83d\udcac CLARISSA: {response.text}\")\n",
        "    \n",
        "    if response.visualization:\n",
        "        response.visualization.show()\n",
        "    \n",
        "    return response\n",
        "\n",
        "# Demo commands\n",
        "print(\"\u2550\" * 60)\n",
        "print(\"\ud83d\udcdd TEXT INPUT DEMOS\")\n",
        "print(\"\u2550\" * 60)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo 1: Show permeability\n",
        "process_text_command(\"show me the permeability\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo 2: Layer cross-section\n",
        "process_text_command(\"show layer 3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo 3: Query value\n",
        "process_text_command(\"what is the water cut?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo 4: Water saturation\n",
        "process_text_command(\"show water saturation at day 500\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive text input\n",
        "text_input = widgets.Text(\n",
        "    placeholder='Type a command (e.g., \"show porosity\")',\n",
        "    description='Command:',\n",
        "    layout=widgets.Layout(width='80%')\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_submit(change):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        if text_input.value:\n",
        "            process_text_command(text_input.value)\n",
        "\n",
        "text_input.on_submit(lambda x: on_submit(x))\n",
        "submit_btn = widgets.Button(description=\"Process\", button_style='primary')\n",
        "submit_btn.on_click(lambda x: on_submit(x))\n",
        "\n",
        "display(widgets.HBox([text_input, submit_btn]))\n",
        "display(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5\ufe0f\u20e3 SPE Benchmark Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "# \ud83e\uddea SPE BENCHMARK TEST SUITE\n",
        "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
        "\n",
        "def run_tests():\n",
        "    \"\"\"Run SPE benchmark tests for voice module.\"\"\"\n",
        "    \n",
        "    tests = [\n",
        "        # General commands\n",
        "        (\"cancel\", IntentType.CANCEL, {}),\n",
        "        (\"stop\", IntentType.CANCEL, {}),\n",
        "        (\"yes\", IntentType.CONFIRM, {}),\n",
        "        (\"help\", IntentType.HELP, {}),\n",
        "        \n",
        "        # SPE1 - Simple model\n",
        "        (\"show me the pressure distribution\", IntentType.VISUALIZE_PROPERTY, {\"property\": \"pressure\"}),\n",
        "        (\"display the oil saturation at layer 2\", IntentType.VISUALIZE_PROPERTY, {\"layer\": 2}),\n",
        "        (\"show porosity in 3D\", IntentType.VISUALIZE_PROPERTY, {\"property\": \"porosity\"}),\n",
        "        \n",
        "        # SPE9 - Waterflood\n",
        "        (\"show water saturation at day 500\", IntentType.VISUALIZE_PROPERTY, {\"property\": \"water_saturation\", \"time_days\": 500}),\n",
        "        (\"what is the water cut\", IntentType.QUERY_VALUE, {\"property\": \"water_cut\"}),\n",
        "        (\"display the permeability at layer 8\", IntentType.VISUALIZE_PROPERTY, {\"property\": \"permeability\", \"layer\": 8}),\n",
        "        \n",
        "        # SPE10 - Large model\n",
        "        (\"show the permeability heterogeneity\", IntentType.VISUALIZE_PROPERTY, {\"property\": \"permeability\"}),\n",
        "        (\"display porosity at layer 50\", IntentType.VISUALIZE_PROPERTY, {\"property\": \"porosity\", \"layer\": 50}),\n",
        "    ]\n",
        "    \n",
        "    print(\"\u2550\" * 65)\n",
        "    print(\"\ud83e\uddea CLARISSA Voice Module - SPE Benchmark Test Suite\")\n",
        "    print(\"\u2550\" * 65)\n",
        "    print()\n",
        "    \n",
        "    passed = 0\n",
        "    failed = 0\n",
        "    \n",
        "    for text, expected_type, expected_slots in tests:\n",
        "        result = parse_intent(text)\n",
        "        \n",
        "        type_ok = result.type == expected_type\n",
        "        slots_ok = all(result.slots.get(k) == v for k, v in expected_slots.items())\n",
        "        \n",
        "        if type_ok and slots_ok:\n",
        "            print(f\"  \u2705 '{text[:40]}...'\" if len(text) > 40 else f\"  \u2705 '{text}'\")\n",
        "            passed += 1\n",
        "        else:\n",
        "            print(f\"  \u274c '{text}'\")\n",
        "            if not type_ok:\n",
        "                print(f\"     \u2514\u2500 Expected {expected_type.value}, got {result.type.value}\")\n",
        "            if not slots_ok:\n",
        "                print(f\"     \u2514\u2500 Expected slots {expected_slots}, got {result.slots}\")\n",
        "            failed += 1\n",
        "    \n",
        "    print()\n",
        "    print(\"\u2500\" * 65)\n",
        "    if failed == 0:\n",
        "        print(f\"\u2705 ALL {passed} TESTS PASSED!\")\n",
        "    else:\n",
        "        print(f\"\u274c {failed} FAILED, {passed} passed\")\n",
        "    print(\"\u2550\" * 65)\n",
        "    \n",
        "    return failed == 0\n",
        "\n",
        "run_tests()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83d\udcda Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **\ud83c\udfa4 Voice Recording** - Professional waveform visualization with WebAudio API\n",
        "2. **\ud83d\udcdd Speech-to-Text** - Whisper API transcription with domain vocabulary\n",
        "3. **\ud83c\udfaf Intent Parsing** - Rule-based command understanding\n",
        "4. **\ud83d\udcca Visualization** - 3D and cross-section reservoir property views\n",
        "5. **\ud83e\uddea Testing** - SPE benchmark validation\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Full Integration**: Connect to OPM Flow simulations\n",
        "- **LLM Parsing**: Use Claude/GPT-4 for complex commands\n",
        "- **Production**: Browser-based standalone demo\n",
        "\n",
        "---\n",
        "\n",
        "*CLARISSA - Conversational Language Agent for Reservoir Integrated Simulation System Analysis*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}