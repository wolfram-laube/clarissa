<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CLARISSA Voice Capture</title>
    <style>
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --success: #22c55e;
            --danger: #ef4444;
            --bg: #0f172a;
            --card: #1e293b;
            --text: #f1f5f9;
            --muted: #94a3b8;
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg);
            color: var(--text);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 2rem;
        }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .subtitle { color: var(--muted); margin-bottom: 2rem; }
        .card {
            background: var(--card);
            border-radius: 1rem;
            padding: 2rem;
            width: 100%;
            max-width: 500px;
            margin-bottom: 1rem;
        }
        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: var(--primary);
            color: white;
            font-size: 3rem;
            cursor: pointer;
            transition: all 0.2s;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto 1.5rem;
        }
        .mic-button:hover { background: var(--primary-dark); transform: scale(1.05); }
        .mic-button.recording {
            background: var(--danger);
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }
        .status { text-align: center; color: var(--muted); margin-bottom: 1rem; }
        .status.recording { color: var(--danger); }
        .visualizer {
            height: 60px;
            background: rgba(0,0,0,0.2);
            border-radius: 0.5rem;
            margin-bottom: 1rem;
            overflow: hidden;
        }
        .visualizer canvas { width: 100%; height: 100%; }
        .transcript {
            background: rgba(0,0,0,0.2);
            border-radius: 0.5rem;
            padding: 1rem;
            min-height: 80px;
            margin-bottom: 1rem;
        }
        .transcript-label { font-size: 0.75rem; color: var(--muted); margin-bottom: 0.5rem; }
        .transcript-text { font-size: 1.1rem; line-height: 1.5; }
        .transcript-text.placeholder { color: var(--muted); font-style: italic; }
        .intent-box {
            background: rgba(99, 102, 241, 0.1);
            border: 1px solid var(--primary);
            border-radius: 0.5rem;
            padding: 1rem;
            margin-bottom: 1rem;
        }
        .intent-label { font-size: 0.75rem; color: var(--primary); margin-bottom: 0.5rem; }
        .intent-type { font-weight: bold; font-size: 1.1rem; margin-bottom: 0.5rem; }
        .intent-slots { font-family: monospace; font-size: 0.9rem; color: var(--muted); }
        .confidence {
            display: inline-block;
            padding: 0.25rem 0.5rem;
            background: var(--success);
            border-radius: 0.25rem;
            font-size: 0.75rem;
            margin-left: 0.5rem;
        }
        .confidence.low { background: var(--danger); }
        .actions { display: flex; gap: 0.5rem; margin-top: 1rem; }
        .btn {
            flex: 1;
            padding: 0.75rem;
            border: none;
            border-radius: 0.5rem;
            font-size: 1rem;
            cursor: pointer;
            transition: all 0.2s;
        }
        .btn-primary { background: var(--primary); color: white; }
        .btn-primary:hover { background: var(--primary-dark); }
        .btn-primary:disabled { background: var(--muted); cursor: not-allowed; }
        .btn-secondary { background: rgba(255,255,255,0.1); color: var(--text); }
        .btn-secondary:hover { background: rgba(255,255,255,0.2); }
        .btn-secondary:disabled { opacity: 0.5; cursor: not-allowed; }
        .settings { font-size: 0.85rem; }
        .setting-row {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.5rem 0;
            border-bottom: 1px solid rgba(255,255,255,0.1);
        }
        .setting-row:last-child { border-bottom: none; }
        select, input {
            background: rgba(0,0,0,0.3);
            border: 1px solid rgba(255,255,255,0.2);
            color: var(--text);
            padding: 0.5rem;
            border-radius: 0.25rem;
        }
        .error {
            background: rgba(239, 68, 68, 0.1);
            border: 1px solid var(--danger);
            color: var(--danger);
            padding: 1rem;
            border-radius: 0.5rem;
            margin-bottom: 1rem;
        }
        .hidden { display: none; }
        .response-box {
            background: rgba(34, 197, 94, 0.1);
            border: 1px solid var(--success);
            border-radius: 0.5rem;
            padding: 1rem;
        }
        .response-label { font-size: 0.75rem; color: var(--success); margin-bottom: 0.5rem; }
    </style>
</head>
<body>
    <h1>üé§ CLARISSA Voice Capture</h1>
    <p class="subtitle">Browser-based voice input prototype</p>
    
    <div class="card">
        <div id="error" class="error hidden"></div>
        
        <button id="micBtn" class="mic-button">üé§</button>
        <p id="status" class="status">Click microphone or press Space to record</p>
        
        <div class="visualizer">
            <canvas id="visualizer"></canvas>
        </div>
        
        <div class="transcript">
            <div class="transcript-label">üìù Transcription</div>
            <div id="transcript" class="transcript-text placeholder">
                Speak after clicking the microphone...
            </div>
        </div>
        
        <div id="intentBox" class="intent-box hidden">
            <div class="intent-label">üß† Parsed Intent</div>
            <div class="intent-type">
                <span id="intentType">-</span>
                <span id="confidence" class="confidence">95%</span>
            </div>
            <div id="intentSlots" class="intent-slots"></div>
        </div>
        
        <div id="responseBox" class="response-box hidden">
            <div class="response-label">üí¨ CLARISSA Response</div>
            <div id="responseText"></div>
        </div>
        
        <div class="actions">
            <button id="playBtn" class="btn btn-secondary" disabled>‚ñ∂Ô∏è Play</button>
            <button id="downloadBtn" class="btn btn-secondary" disabled>üíæ Save</button>
            <button id="sendBtn" class="btn btn-primary" disabled>üöÄ Send</button>
        </div>
    </div>
    
    <div class="card settings">
        <div class="setting-row">
            <span>API Endpoint</span>
            <input id="apiEndpoint" type="text" value="http://localhost:8000/api/voice" style="width: 200px;">
        </div>
        <div class="setting-row">
            <span>Auto-stop on silence</span>
            <select id="silenceTimeout">
                <option value="1500">1.5 sec</option>
                <option value="2000" selected>2 sec</option>
                <option value="3000">3 sec</option>
                <option value="0">Off</option>
            </select>
        </div>
    </div>

    <script>
        // State
        let mediaRecorder = null;
        let audioChunks = [];
        let audioBlob = null;
        let audioUrl = null;
        let audioContext = null;
        let analyser = null;
        let isRecording = false;
        let silenceStart = null;
        
        // Elements
        const micBtn = document.getElementById('micBtn');
        const status = document.getElementById('status');
        const transcript = document.getElementById('transcript');
        const intentBox = document.getElementById('intentBox');
        const intentType = document.getElementById('intentType');
        const confidence = document.getElementById('confidence');
        const intentSlots = document.getElementById('intentSlots');
        const responseBox = document.getElementById('responseBox');
        const responseText = document.getElementById('responseText');
        const playBtn = document.getElementById('playBtn');
        const downloadBtn = document.getElementById('downloadBtn');
        const sendBtn = document.getElementById('sendBtn');
        const errorDiv = document.getElementById('error');
        const canvas = document.getElementById('visualizer');
        const canvasCtx = canvas.getContext('2d');
        
        // Initialize
        async function init() {
            try {
                if (!navigator.mediaDevices?.getUserMedia) {
                    throw new Error('Microphone not supported');
                }
                await navigator.mediaDevices.getUserMedia({ audio: true });
                showStatus('Ready - click üé§ or press Space');
            } catch (err) {
                showError(`Mic error: ${err.message}`);
            }
        }
        
        // Start recording
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: { channelCount: 1, echoCancellation: true, noiseSuppression: true }
                });
                
                // Audio visualization
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                audioContext.createMediaStreamSource(stream).connect(analyser);
                analyser.fftSize = 256;
                visualize();
                
                // Recorder
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
                audioChunks = [];
                
                mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
                mediaRecorder.onstop = () => {
                    audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    audioUrl = URL.createObjectURL(audioBlob);
                    playBtn.disabled = false;
                    downloadBtn.disabled = false;
                    sendBtn.disabled = false;
                    showStatus('Recording complete');
                    stream.getTracks().forEach(t => t.stop());
                };
                
                mediaRecorder.start(100);
                isRecording = true;
                silenceStart = null;
                
                micBtn.classList.add('recording');
                micBtn.textContent = '‚èπÔ∏è';
                status.classList.add('recording');
                showStatus('Recording... click to stop');
                
                // Silence detection
                detectSilence();
            } catch (err) {
                showError(`Recording error: ${err.message}`);
            }
        }
        
        // Stop recording
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                micBtn.classList.remove('recording');
                micBtn.textContent = 'üé§';
                status.classList.remove('recording');
            }
        }
        
        // Silence detection
        function detectSilence() {
            const timeout = parseInt(document.getElementById('silenceTimeout').value);
            if (timeout === 0 || !isRecording) return;
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            
            function check() {
                if (!isRecording) return;
                analyser.getByteFrequencyData(dataArray);
                const avg = dataArray.reduce((a, b) => a + b) / dataArray.length;
                
                if (avg < 10) {
                    if (!silenceStart) silenceStart = Date.now();
                    else if (Date.now() - silenceStart > timeout) {
                        showStatus('Silence detected...');
                        stopRecording();
                        return;
                    }
                } else {
                    silenceStart = null;
                }
                requestAnimationFrame(check);
            }
            check();
        }
        
        // Visualizer
        function visualize() {
            if (!analyser) return;
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            canvas.width = canvas.offsetWidth * 2;
            canvas.height = canvas.offsetHeight * 2;
            
            function draw() {
                if (!isRecording) return;
                requestAnimationFrame(draw);
                analyser.getByteFrequencyData(dataArray);
                
                canvasCtx.fillStyle = 'rgba(0,0,0,0.2)';
                canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
                
                const barWidth = (canvas.width / bufferLength) * 2.5;
                let x = 0;
                for (let i = 0; i < bufferLength; i++) {
                    const barHeight = (dataArray[i] / 255) * canvas.height;
                    canvasCtx.fillStyle = `hsl(${240 + i}, 80%, 60%)`;
                    canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                    x += barWidth + 1;
                }
            }
            draw();
        }
        
        // Play/Download
        playBtn.onclick = () => audioUrl && new Audio(audioUrl).play();
        downloadBtn.onclick = () => {
            if (!audioBlob) return;
            const a = document.createElement('a');
            a.href = audioUrl;
            a.download = `clarissa-${Date.now()}.webm`;
            a.click();
        };
        
        // Send to API
        sendBtn.onclick = async () => {
            if (!audioBlob) return;
            const endpoint = document.getElementById('apiEndpoint').value;
            showStatus('Sending to CLARISSA...');
            sendBtn.disabled = true;
            
            try {
                const formData = new FormData();
                formData.append('audio', audioBlob, 'voice.webm');
                
                const res = await fetch(endpoint, { method: 'POST', body: formData });
                if (!res.ok) throw new Error(`HTTP ${res.status}`);
                
                const data = await res.json();
                showResult(data);
            } catch (err) {
                showError(`API error: ${err.message}`);
                showDemoResult(); // Fallback demo
            }
            sendBtn.disabled = false;
        };
        
        function showResult(data) {
            transcript.textContent = data.transcript || data.text || '-';
            transcript.classList.remove('placeholder');
            
            if (data.intent) {
                intentBox.classList.remove('hidden');
                intentType.textContent = data.intent.type || data.intent;
                const conf = data.intent.confidence || 0.95;
                confidence.textContent = `${Math.round(conf * 100)}%`;
                confidence.classList.toggle('low', conf < 0.7);
                intentSlots.textContent = JSON.stringify(data.intent.slots || {}, null, 2);
            }
            
            if (data.response) {
                responseBox.classList.remove('hidden');
                responseText.textContent = data.response;
            }
            
            showStatus('Done!');
        }
        
        function showDemoResult() {
            transcript.textContent = '[Demo - no backend]';
            transcript.classList.remove('placeholder');
            intentBox.classList.remove('hidden');
            intentType.textContent = 'visualize_property';
            confidence.textContent = '95%';
            intentSlots.textContent = '{"property": "permeability"}';
            responseBox.classList.remove('hidden');
            responseText.textContent = 'Showing permeability in 3D.';
            showStatus('Demo mode (connect backend for real processing)');
        }
        
        function showStatus(msg) { status.textContent = msg; errorDiv.classList.add('hidden'); }
        function showError(msg) { errorDiv.textContent = msg; errorDiv.classList.remove('hidden'); }
        
        // Events
        micBtn.onclick = () => isRecording ? stopRecording() : startRecording();
        document.onkeydown = e => {
            if (e.code === 'Space' && e.target === document.body) {
                e.preventDefault();
                micBtn.click();
            }
        };
        
        init();
    </script>
</body>
</html>
