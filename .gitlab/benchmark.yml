# Runner Benchmark Jobs
# Triggered manually to compare runner performance

.benchmark_base:
  stage: test
  timeout: 10 minutes
  script:
    - echo "=== Runner Benchmark ==="
    - echo "Runner $CI_RUNNER_DESCRIPTION"
    - date
    - echo "--- CPU Benchmark (primes to 500k) ---"
    - python3 -c "import time; s=time.time(); n=500000; sieve=[1]*n; [sieve.__setitem__(i,0) for p in range(2,int(n**.5)+1) if sieve[p] for i in range(p*p,n,p)]; print(f'{sum(sieve)-2} primes in {time.time()-s:.2f}s')"
    - echo "--- Disk I/O (write 100MB) ---"
    - dd if=/dev/zero of=/tmp/testfile bs=1M count=100 2>&1 || true
    - rm -f /tmp/testfile
    - echo "--- Pip install requests ---"
    - pip install requests --quiet 2>/dev/null || echo "pip skip"
    - echo "=== Done ==="
    - date
  rules:
    - when: manual

benchmark-mac-group-shell:
  extends: .benchmark_base
  tags: [mac, shell]

benchmark-mac-docker:
  extends: .benchmark_base
  tags: [docker]
  image: python:3.11-slim

benchmark-mac-k8s:
  extends: .benchmark_base
  tags: [mac-k8s]
  image: python:3.11-slim

benchmark-gcp-shell:
  extends: .benchmark_base
  tags: [gcp, shell]

benchmark-gcp-k8s:
  extends: .benchmark_base
  tags: [gcp, k8s]
  image: python:3.11-slim
