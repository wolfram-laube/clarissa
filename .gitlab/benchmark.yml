# Runner Benchmark - All 12 Runners

.benchmark_base:
  stage: test
  timeout: 10 minutes
  script:
    - echo "=== BENCHMARK START ==="
    - echo "Runner - $CI_RUNNER_DESCRIPTION"
    - hostname
    - date
    - echo "--- CPU Test ---"
    - python3 -c "import time; start=time.time(); sum(1 for n in range(2,500000) if all(n%i!=0 for i in range(2,int(n**0.5)+1)))[:1000]; print(f'Done in {time.time()-start:.2f}s')" || echo "Python benchmark skipped"
    - echo "--- Disk Test ---"
    - dd if=/dev/zero of=/tmp/test bs=1M count=50 2>&1 || true
    - rm -f /tmp/test
    - echo "=== BENCHMARK END ==="
  rules:
    - when: manual

# Mac #1
benchmark-mac-group-shell:
  extends: .benchmark_base
  tags: [mac-group-shell]

benchmark-mac-docker:
  extends: .benchmark_base
  tags: [mac-docker]
  image: python:3.11-slim

benchmark-mac-k8s:
  extends: .benchmark_base
  tags: [mac-k8s]
  image: python:3.11-slim

# Mac #2
benchmark-mac2-shell:
  extends: .benchmark_base
  tags: [mac2-shell]

benchmark-mac2-docker:
  extends: .benchmark_base
  tags: [mac2-docker]
  image: python:3.11-slim

benchmark-mac2-k8s:
  extends: .benchmark_base
  tags: [mac2-k8s]
  image: python:3.11-slim

# Linux Yoga
benchmark-linux-shell:
  extends: .benchmark_base
  tags: [linux-shell]

benchmark-linux-docker:
  extends: .benchmark_base
  tags: [linux-docker]
  image: python:3.11-slim

benchmark-linux-k8s:
  extends: .benchmark_base
  tags: [linux-k8s]
  image: python:3.11-slim

# GCP VM
benchmark-gcp-shell:
  extends: .benchmark_base
  tags: [gcp-shell]

benchmark-gcp-docker:
  extends: .benchmark_base
  tags: [gcp-docker]
  image: python:3.11-slim

benchmark-gcp-k8s:
  extends: .benchmark_base
  tags: [gcp-k8s]
  image: python:3.11-slim
