# Runner Benchmark Jobs
# Triggered manually to compare runner performance

.benchmark_base:
  stage: test
  script:
    - echo "=== Runner Benchmark ==="
    - echo "Runner: $CI_RUNNER_DESCRIPTION"
    - echo "Executor: $CI_RUNNER_EXECUTABLE_ARCH"
    - echo "Start: $(date)"
    - |
      # CPU Benchmark - calculate primes
      START=$(date +%s.%N)
      python3 -c "
      import time
      def sieve(n):
          primes = [True] * (n+1)
          p = 2
          while p * p <= n:
              if primes[p]:
                  for i in range(p * p, n+1, p):
                      primes[i] = False
              p += 1
          return sum(primes) - 2
      
      start = time.time()
      result = sieve(1000000)
      elapsed = time.time() - start
      print(f'Primes up to 1M: {result} in {elapsed:.2f}s')
      "
      END=$(date +%s.%N)
      echo "CPU Benchmark: $(echo "$END - $START" | bc)s"
    - |
      # Disk I/O Benchmark
      START=$(date +%s.%N)
      dd if=/dev/zero of=/tmp/testfile bs=1M count=100 2>&1 | tail -1
      rm /tmp/testfile
      END=$(date +%s.%N)
      echo "Disk Write 100MB: $(echo "$END - $START" | bc)s"
    - |
      # Pip install benchmark
      START=$(date +%s.%N)
      pip install requests --quiet --disable-pip-version-check 2>/dev/null || true
      END=$(date +%s.%N)
      echo "Pip install requests: $(echo "$END - $START" | bc)s"
    - echo "=== Benchmark Complete ==="
    - echo "End: $(date)"
  rules:
    - when: manual

benchmark-mac-group-shell:
  extends: .benchmark_base
  tags:
    - mac
    - shell

benchmark-mac-docker:
  extends: .benchmark_base
  tags:
    - docker
  image: python:3.11-slim

benchmark-mac-k8s:
  extends: .benchmark_base
  tags:
    - mac-k8s
  image: python:3.11-slim

benchmark-gcp-shell:
  extends: .benchmark_base
  tags:
    - gcp
    - shell

benchmark-gcp-k8s:
  extends: .benchmark_base
  tags:
    - gcp
    - k8s
  image: python:3.11-slim
