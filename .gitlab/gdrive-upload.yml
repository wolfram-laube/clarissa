# Google Drive Upload Pipeline for Benchmark Reports, Notebooks and Config
#
# Supports both regular folders AND Shared Drives
# Uses Service Account: claude-assistant@myk8sproject-207017.iam.gserviceaccount.com

.gdrive_base:
  image: python:3.11-slim
  tags:
    - gcp-docker
  before_script:
    - pip install google-auth google-api-python-client --quiet

# Upload benchmark report to Google Drive
gdrive:upload-benchmark:
  extends: .gdrive_base
  stage: deploy
  rules:
    - if: $UPLOAD_BENCHMARK == "true"
      when: always
    - when: manual
      allow_failure: true
  needs: []
  variables:
    BENCHMARK_FOLDER_NAME: "Benchmarks"
  script:
    - python3 scripts/gdrive_upload_benchmark.py
  artifacts:
    paths:
      - gdrive_upload_summary.json
    expire_in: 1 week

# Sync notebooks to GDrive for Colab access
gdrive:sync-notebooks:
  extends: .gdrive_base
  stage: deploy
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      changes:
        - docs/tutorials/*.ipynb
      when: always
    - when: manual
      allow_failure: true
  needs: []
  script:
    - python3 scripts/sync_notebooks_gdrive.py
  artifacts:
    paths:
      - notebook_colab_urls.json
    expire_in: 1 week

# Sync Colab config (credentials) to GDrive
gdrive:sync-config:
  extends: .gdrive_base
  stage: deploy
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      changes:
        - config/clarissa_colab_config.json
      when: always
    - when: manual
      allow_failure: true
  needs: []
  script:
    - python3 scripts/sync_colab_config.py
  artifacts:
    paths:
      - config_sync_result.json
    expire_in: 1 week

# List Google Drive contents (with Shared Drive support)
gdrive:list:
  extends: .gdrive_base
  stage: .pre
  rules:
    - when: manual
      allow_failure: true
  script:
    - python3 scripts/gdrive_list.py
  artifacts:
    paths:
      - gdrive_listing.json
    expire_in: 1 day
