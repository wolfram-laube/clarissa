# Include additional CI configurations
include:
  - local: 'conference/spe-europe-2026/ci/document-merge.gitlab-ci.yml'
    rules:
      - changes:
          - conference/spe-europe-2026/**/*

workflow:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: always
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      when: always
    # Trigger on semantic version tags (v1.0.0, v2.1.3, etc.)
    - if: '$CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/'
      when: always
    # Allow manual trigger via "Run pipeline" button
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: always
    # Allow scheduled pipelines (billing automation)
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: always
    - when: never

stages:
  - build
  - test
  - classify
  - automation
  - deploy

# ----------------------------
# Anchors (infrastructure hygiene)
# ----------------------------
.python_base: &python_base
  image: python:3.11
  variables:
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  cache:
    key: pip-cache
    paths:
      - .cache/pip

.install_dev_deps: &install_dev_deps
  before_script:
    - python -V
    - python -m pip install --upgrade pip
    - python -m pip install -e ".[dev]"

.pytest_run: &pytest_run
  script:
    - python -m pytest -q --junitxml=junit.xml
  artifacts:
    when: always
    reports:
      junit: junit.xml
    paths:
      - junit.xml
      - .pytest_cache/

.rerun_rules: &rerun_rules
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: on_failure
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      when: on_failure
    - when: never

.issue_bot_rules: &issue_bot_rules
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      when: on_success
    - when: never

.recovery_bot_rules: &recovery_bot_rules
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      when: on_success
    - when: never

.mr_bot_rules: &mr_bot_rules
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: on_success
    - when: never

# ----------------------------
# Build Stage - Docker Images
# ----------------------------
build_opm_image:
  stage: build
  image: docker:24
  services:
    - docker:24-dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: "$DOCKER_TLS_CERTDIR/client"
    IMAGE_BASE: $CI_REGISTRY_IMAGE/opm-flow
  before_script:
    - docker info
    - echo "$CI_REGISTRY_PASSWORD" | docker login -u "$CI_REGISTRY_USER" --password-stdin $CI_REGISTRY
  script:
    - |
      echo "Building OPM Flow image..."
      
      # Always tag with commit SHA for traceability
      docker build -t $IMAGE_BASE:$CI_COMMIT_SHORT_SHA -f src/clarissa/simulators/opm/Dockerfile src/clarissa/simulators/opm/
      
      # Tag strategy based on context (ADR-012)
      if [ -n "$CI_COMMIT_TAG" ]; then
        # Release: semantic version tag (e.g., v1.2.3)
        echo "Release build: tagging as $CI_COMMIT_TAG"
        docker tag $IMAGE_BASE:$CI_COMMIT_SHORT_SHA $IMAGE_BASE:$CI_COMMIT_TAG
        docker tag $IMAGE_BASE:$CI_COMMIT_SHORT_SHA $IMAGE_BASE:latest
        
        # Push all tags
        docker push $IMAGE_BASE:$CI_COMMIT_SHORT_SHA
        docker push $IMAGE_BASE:$CI_COMMIT_TAG
        docker push $IMAGE_BASE:latest
        
        echo "IMAGE_TAG=$IMAGE_BASE:$CI_COMMIT_TAG" >> build.env
      else
        # Development: SHA + latest
        echo "Development build: tagging as $CI_COMMIT_SHORT_SHA and latest"
        docker tag $IMAGE_BASE:$CI_COMMIT_SHORT_SHA $IMAGE_BASE:latest
        
        docker push $IMAGE_BASE:$CI_COMMIT_SHORT_SHA
        docker push $IMAGE_BASE:latest
        
        echo "IMAGE_TAG=$IMAGE_BASE:$CI_COMMIT_SHORT_SHA" >> build.env
      fi
      
      echo "IMAGE_LATEST=$IMAGE_BASE:latest" >> build.env
  artifacts:
    reports:
      dotenv: build.env
  rules:
    # Build on MRs if OPM files changed
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - src/clarissa/simulators/opm/**/*
        - Dockerfile*
      when: on_success
    # Build on main if OPM files changed
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - src/clarissa/simulators/opm/**/*
        - Dockerfile*
      when: on_success
    # Always build on version tags (releases)
    - if: '$CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/'
      when: always
    # Manual trigger always available
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true
    - when: never

# ----------------------------
# Test Stage
# ----------------------------
tests:
  stage: test
  <<: *python_base
  <<: *install_dev_deps
  script:
    - python -m pytest -q --ignore=tests/integration --junitxml=junit.xml
  artifacts:
    when: always
    reports:
      junit: junit.xml
    paths:
      - junit.xml
      - .pytest_cache/
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
    - if: '$CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/'
    - when: never

integration_tests_opm:
  stage: test
  image: docker:24
  services:
    - docker:24-dind
  needs:
    - job: build_opm_image
      artifacts: true
      optional: true
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: "$DOCKER_TLS_CERTDIR/client"
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  before_script:
    - apk add --no-cache python3 py3-pip
    - python3 -m pip install --break-system-packages -e ".[dev]"
    - echo "$CI_REGISTRY_PASSWORD" | docker login -u "$CI_REGISTRY_USER" --password-stdin $CI_REGISTRY
    - |
      # Pull the image we just built, or try latest
      if [ -n "$IMAGE_TAG" ]; then
        docker pull $IMAGE_TAG && docker tag $IMAGE_TAG opm-flow:latest
      else
        docker pull $CI_REGISTRY_IMAGE/opm-flow:latest && docker tag $CI_REGISTRY_IMAGE/opm-flow:latest opm-flow:latest || echo "No image available, tests will skip"
      fi
  script:
    - |
      # Register custom pytest marker to avoid warnings
      echo "[pytest]" > pytest.ini
      echo "markers = docker: marks tests as requiring docker" >> pytest.ini
      python3 -m pytest -v tests/integration/test_opm_flow.py --junitxml=junit_integration.xml || true
  artifacts:
    when: always
    reports:
      junit: junit_integration.xml
    paths:
      - junit_integration.xml
  rules:
    # Only run when OPM-related files change
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - src/clarissa/simulators/opm/**/*
        - tests/integration/test_opm_flow.py
      when: on_success
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - src/clarissa/simulators/opm/**/*
        - tests/integration/test_opm_flow.py
      when: on_success
    # Always run on version tags
    - if: '$CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/'
      when: on_success
    - when: never
  allow_failure: true

snapshot_tests:
  stage: test
  <<: *python_base
  <<: *install_dev_deps
  script:
    - |
      set -e
      mkdir -p tests/golden tests/golden/snapshots tests/golden/diffs

      echo '# Snapshot diffs' > tests/golden/summary.md
      echo '' >> tests/golden/summary.md
      echo '_No snapshot diffs produced._' >> tests/golden/summary.md
      echo '' >> tests/golden/summary.md

      python -m pytest -q \
        tests/golden/test_cli_help_snapshot.py \
        tests/golden/test_cli_demo_snapshot.py || EXIT=$?

      if [ -d tests/golden/diffs ] && ls -1 tests/golden/diffs/*.diff >/dev/null 2>&1; then
        echo '# Snapshot diffs' > tests/golden/summary.md
        echo '' >> tests/golden/summary.md
        for f in tests/golden/diffs/*.diff; do
          echo "## $(basename "$f")" >> tests/golden/summary.md
          echo '```diff' >> tests/golden/summary.md
          cat "$f" >> tests/golden/summary.md
          echo '```' >> tests/golden/summary.md
          echo '' >> tests/golden/summary.md
        done
      fi

      if [ -n "${EXIT:-}" ]; then exit "$EXIT"; fi
  artifacts:
    when: on_failure
    paths:
      - tests/golden/snapshots/
      - tests/golden/summary.md
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
    - if: '$CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/'
    - when: never

contract_tests:
  stage: test
  <<: *python_base
  <<: *install_dev_deps
  script:
    - |
      set -e
      mkdir -p tests/contracts
      python -m pytest -q tests/contracts 2>&1 | tee pytest_contracts.log || EXIT=$?
      python scripts/generate_contract_summary.py || true
      if [ -n "${EXIT:-}" ]; then exit "$EXIT"; fi
  artifacts:
    when: on_failure
    paths:
      - tests/contracts/summary.md
      - pytest_contracts.log
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
    - if: '$CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/'
    - when: never

governance_impact:
  stage: test
  <<: *python_base
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: on_success
    - when: never
  script:
    - mkdir -p tests/governance
    - python scripts/detect_governance_impact.py
  artifacts:
    when: always
    paths:
      - tests/governance/impact.md

architecture_graphs:
  stage: test
  image:
    name: ghcr.io/mermaid-js/mermaid-cli/mermaid-cli:latest
    entrypoint: [""]
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: on_success
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      when: on_success
    - when: never
  script:
    - mkdir -p docs/architecture/diagrams docs/architecture/rendered
    - mmdc --version || true
    - bash scripts/render_mermaid.sh || echo "Mermaid render failed; keeping sources."
  artifacts:
    when: always
    paths:
      - docs/architecture/diagrams/
      - docs/architecture/rendered/
  allow_failure: true


mkdocs_nav_check:
  stage: test
  image: python:3.11-slim
  script:
    - pip install pyyaml -q
    - python scripts/check_mkdocs_nav.py
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
    - when: never

tests_rerun:
  stage: test
  <<: *python_base
  <<: *install_dev_deps
  <<: *rerun_rules
  needs:
    - job: tests
      artifacts: true
      optional: true
  script:
    - |
      set +e
      python -m pytest -q \
        --last-failed \
        --last-failed-no-failures=none \
        --maxfail=${CI_BOT_RERUN_MAXFAIL:-1} \
        -x \
        --junitxml=junit_rerun.xml
      echo $? > rerun_exit_code.txt
      exit 0
  artifacts:
    when: always
    paths:
      - junit_rerun.xml
      - rerun_exit_code.txt

# ----------------------------
# Classify Stage
# ----------------------------
ci_classify:
  stage: classify
  <<: *python_base
  needs:
    - job: tests
      artifacts: true
      optional: true
    - job: tests_rerun
      artifacts: true
      optional: true
  script:
    - python scripts/ci_classify.py
  artifacts:
    reports:
      dotenv: ci_classify.env
    paths:
      - ci_classify.env
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
    - when: never

# ----------------------------
# Automation Stage
# ----------------------------
mr_report:
  stage: automation
  <<: *python_base
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: on_success
    - when: never
  needs:
    - job: snapshot_tests
      artifacts: true
      optional: true
    - job: contract_tests
      artifacts: true
      optional: true
    - job: governance_impact
      artifacts: true
      optional: true
    - job: architecture_graphs
      artifacts: true
      optional: true
    - job: integration_tests_opm
      artifacts: true
      optional: true
  script:
    - mkdir -p reports
    - python scripts/generate_mr_report.py
    - python scripts/render_report_html.py || true
  artifacts:
    when: always
    paths:
      - reports/mr_report.md
      - reports/mr_report.html

ci_flaky_ledger:
  stage: automation
  <<: *python_base
  <<: *issue_bot_rules
  needs:
    - job: ci_classify
      artifacts: true
      optional: true
  script:
    - python scripts/gitlab_flaky_ledger_bot.py

ci_issue_on_failure:
  stage: automation
  <<: *python_base
  <<: *issue_bot_rules
  needs:
    - job: ci_classify
      artifacts: true
      optional: true
  script:
    - python scripts/gitlab_issue_bot.py

ci_issue_on_recovery:
  stage: automation
  <<: *python_base
  <<: *recovery_bot_rules
  needs:
    - job: ci_classify
      artifacts: true
      optional: true
  script:
    - python scripts/gitlab_recovery_bot.py

mr_comment_on_failure:
  stage: automation
  <<: *python_base
  <<: *mr_bot_rules
  needs:
    - job: ci_classify
      artifacts: true
      optional: true
  script:
    - python scripts/gitlab_mr_bot.py

# ----------------------------
# Deploy Stage
# ----------------------------
pages:
  stage: deploy
  image: python:3.11
  needs:
    - job: build_paper
      optional: true
      artifacts: true
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      when: on_success
    - when: never
  before_script:
    - pip install mkdocs mkdocs-material pymdown-extensions jinja2 pyyaml
  script:
    - python scripts/build_i18n_docs.py
    - mkdocs build --site-dir public
    - mkdir -p public/guides/contributing
    - cp docs/guides/contributing/*.html public/guides/contributing/ 2>/dev/null || true
    - echo "ðŸ“„ Setting up publication PDFs..."
    - mkdir -p public/publications/ijacsa-2026 public/publications/spe-europe-2026
    - cp conference/ijacsa-2026/CLARISSA_Paper_IJACSA.pdf public/publications/ijacsa-2026/ 2>/dev/null || echo "IJACSA PDF not in artifacts"
    - cp conference/spe-europe-2026/abstract-with-diagrams.pdf public/publications/spe-europe-2026/ 2>/dev/null || true
    - cp conference/spe-europe-2026/abstract-corrected-v2.html public/publications/spe-europe-2026/ 2>/dev/null || true
    - cp conference/spe-europe-2026/abstract.pdf public/publications/spe-europe-2026/ 2>/dev/null || true
    - python3 -c "html='''<!DOCTYPE html><html><head><title>CLARISSA Publications</title><style>body{font-family:sans-serif;max-width:800px;margin:50px auto;padding:20px}h1{color:#333}.p{background:#f5f5f5;padding:20px;margin:20px 0;border-radius:8px}.p h2{margin-top:0;color:#1a73e8}a{color:#1a73e8}</style></head><body><h1>CLARISSA Publications</h1><p>Review copies for internal distribution.</p><div class=\"p\"><h2>IJACSA 2026</h2><p>CLARISSA - Conversational Language Agent for Reservoir Simulation</p><a href=\"ijacsa-2026/CLARISSA_Paper_IJACSA.pdf\">Full Paper PDF</a></div><div class=\"p\"><h2>SPE Europe 2026</h2><p>CLARISSA - Conversational UI for Reservoir Simulation</p><a href=\"spe-europe-2026/abstract-with-diagrams.pdf\">Abstract PDF</a> | <a href=\"spe-europe-2026/abstract-corrected-v2.html\">Interactive HTML</a></div></body></html>''';open('public/publications/index.html','w').write(html)"
    - find public/publications -type f
  artifacts:
    paths:
      - public
    expire_in: 1 week

llm_sync_package:
  stage: deploy
  image: python:3.11
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: on_success
    - if: '$CI_PIPELINE_SOURCE == "push"'
      when: on_success
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true
    - when: never
  script:
    - |
      BRANCH="${CI_MERGE_REQUEST_SOURCE_BRANCH_NAME:-${CI_COMMIT_BRANCH:-${CI_COMMIT_TAG:-main}}}"
      echo "Generating sync package for branch: $BRANCH"
      cd scripts
      python llm_sync_generator.py --branch "$BRANCH" --lite -o ../clarissa_sync_lite.md
      python llm_sync_generator.py --branch "$BRANCH" --medium -o ../clarissa_sync_medium.md
      python llm_sync_generator.py --branch "$BRANCH" --lite --since ${CI_COMMIT_BEFORE_SHA:-HEAD~5} -o ../clarissa_sync_diff.md || true
  artifacts:
    paths:
      - clarissa_sync_lite.md
      - clarissa_sync_medium.md
      - clarissa_sync_diff.md
    expire_in: 4 weeks

# ----------------------------
# Manual Trigger Jobs
# ----------------------------
# These jobs can be triggered via:
#   1. GitLab UI: CI/CD â†’ Pipelines â†’ Run Pipeline â†’ Select job
#   2. API: POST /projects/:id/pipeline with variables

rebuild_docs:
  stage: deploy
  image: python:3.11
  rules:
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
    - when: never
  before_script:
    - pip install mkdocs mkdocs-material pymdown-extensions jinja2 pyyaml
  script:
    - echo "Rebuilding documentation..."
    - python scripts/build_i18n_docs.py
    - mkdocs build --site-dir public
    - |
      mkdir -p public/guides/contributing
      cp docs/guides/contributing/*.html public/guides/contributing/ 2>/dev/null || true
  artifacts:
    paths:
      - public
    expire_in: 1 day
  environment:
    name: docs-preview
    url: https://wolfram_laube.gitlab.io/blauweiss_llc/irena/

rebuild_opm_image:
  stage: build
  image: docker:24
  services:
    - docker:24-dind
  rules:
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
    - when: never
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: "$DOCKER_TLS_CERTDIR/client"
    IMAGE_BASE: $CI_REGISTRY_IMAGE/opm-flow
  before_script:
    - docker info
    - echo "$CI_REGISTRY_PASSWORD" | docker login -u "$CI_REGISTRY_USER" --password-stdin $CI_REGISTRY
  script:
    - |
      echo "Manual rebuild of OPM Flow image..."
      docker build --no-cache -t $IMAGE_BASE:$CI_COMMIT_SHORT_SHA -f src/clarissa/simulators/opm/Dockerfile src/clarissa/simulators/opm/
      docker tag $IMAGE_BASE:$CI_COMMIT_SHORT_SHA $IMAGE_BASE:latest
      docker push $IMAGE_BASE:$CI_COMMIT_SHORT_SHA
      docker push $IMAGE_BASE:latest
      echo "âœ… Pushed: $IMAGE_BASE:$CI_COMMIT_SHORT_SHA"
      echo "âœ… Pushed: $IMAGE_BASE:latest"

rerun_all_tests:
  stage: test
  <<: *python_base
  <<: *install_dev_deps
  rules:
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
    - when: never
  script:
    - echo "Running full test suite (manual trigger)..."
    - python -m pytest -v --junitxml=junit_manual.xml
  artifacts:
    when: always
    reports:
      junit: junit_manual.xml
    paths:
      - junit_manual.xml

build_paper:
  stage: build
  image: texlive/texlive:latest
  tags:
    - docker
  rules:
    # Auto-run when paper files change
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - conference/**/*
      when: on_success
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - conference/**/*
      when: on_success
    # Manual trigger always available
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
    - when: never
  script:
    - cd conference/ijacsa-2026
    - echo "Copying figures to build directory..."
    - cp figures/*.png . 2>/dev/null || echo "No figures to copy"
    - ls -la *.png 2>/dev/null || echo "No PNG files found"
    - echo "Building CLARISSA paper..."
    - pdflatex -interaction=nonstopmode CLARISSA_Paper_IJACSA.tex || true
    - pdflatex -interaction=nonstopmode CLARISSA_Paper_IJACSA.tex  # Second pass for references
    - echo "âœ… Paper built successfully"
    - ls -la *.pdf
  artifacts:
    paths:
      - conference/ijacsa-2026/CLARISSA_Paper_IJACSA.pdf
    expire_in: 4 weeks

# =============================================================================
# BILLING AUTOMATION: Monthly Timesheet Generation
# =============================================================================
# Trigger: Scheduled pipeline (1st of month) or manual with GENERATE_TIMESHEETS=true
# Setup: GitLab CI/CD > Schedules > Cron: "0 6 1 * *" > Variable: BILLING_RUN=true
# =============================================================================
generate_timesheets:
  stage: build
  image: python:3.11-slim
  variables:
    GITLAB_PROJECT_PATH: "wolfram_laube/blauweiss_llc/irena"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $BILLING_RUN == "true"'
      when: on_success
    - if: '$CI_PIPELINE_SOURCE == "web" && $GENERATE_TIMESHEETS == "true"'
      when: on_success
    - when: never
  before_script:
    - pip install pyyaml requests -q
  script:
    - |
      echo "=== Monthly Timesheet Generation ==="
      if [ -n "$BILLING_PERIOD" ]; then
        PERIOD="$BILLING_PERIOD"
      else
        PERIOD=$(date -d "last month" +%Y-%m)
      fi
      echo "Period: $PERIOD"
      cd billing/scripts
      for CLIENT in nemensis; do
        echo "--- Client: $CLIENT ---"
        python generate_timesheet.py --client "$CLIENT" --period "$PERIOD" --all-consultants || echo "No entries for $CLIENT"
      done
      ls -la ../output/*.typ 2>/dev/null || echo "No timesheets generated"
  artifacts:
    paths:
      - billing/output/*.typ
      - billing/output/*.sync.json
    expire_in: 8 weeks

build_invoice:
  stage: build
  image: alpine:latest
  rules:
    # Auto-run when invoice templates change
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - billing/templates/**/*
        - billing/output/**/*.typ
      when: on_success
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - billing/templates/**/*
        - billing/output/**/*.typ
      when: on_success
    # Manual trigger always available
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
    - when: never
  before_script:
    - apk add --no-cache curl tar xz fontconfig ttf-liberation
    # Install Poppins font
    - mkdir -p /usr/share/fonts/poppins
    - curl -L "https://github.com/google/fonts/raw/main/ofl/poppins/Poppins-Regular.ttf" -o /usr/share/fonts/poppins/Poppins-Regular.ttf
    - curl -L "https://github.com/google/fonts/raw/main/ofl/poppins/Poppins-Bold.ttf" -o /usr/share/fonts/poppins/Poppins-Bold.ttf
    - curl -L "https://github.com/google/fonts/raw/main/ofl/poppins/Poppins-Medium.ttf" -o /usr/share/fonts/poppins/Poppins-Medium.ttf
    - fc-cache -fv
    # Install Typst
    - curl -L "https://github.com/typst/typst/releases/download/v0.12.0/typst-x86_64-unknown-linux-musl.tar.xz" -o /tmp/typst.tar.xz
    - tar xf /tmp/typst.tar.xz -C /tmp
    - mv /tmp/typst-x86_64-unknown-linux-musl/typst /usr/local/bin/
    - typst --version
  script:
    - echo "Building invoices with Typst..."
    - cd billing
    - cp templates/logo.jpg output/ 2>/dev/null || true
    - |
      cd output
      for f in *.typ; do
        if [ -f "$f" ]; then
          echo "Compiling $f..."
          typst compile --root .. "$f"
        fi
      done
    - echo "âœ… Invoices built"
    - ls -la *.pdf 2>/dev/null || echo "No PDFs generated"
  artifacts:
    paths:
      - billing/output/*.pdf
    expire_in: 8 weeks

# Upload billing documents to Google Drive
upload_invoice:
  stage: deploy
  image: python:3.11-slim
  needs:
    - job: build_invoice
      artifacts: true
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"'
      changes:
        - billing/output/**/*.typ
      when: on_success
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true
    - when: never
  script:
    - pip install google-auth google-api-python-client -q
    - python billing/scripts/upload_to_drive.py billing/output/*.pdf
# =============================================================================
# LLM Relay: Claude â†” IRENA Communication
# =============================================================================

relay:irena:
  stage: automation
  image: python:3.11-slim
  rules:
    - changes:
        - handoffs/handoff_to_irena.md
      when: always
    - when: never
  before_script:
    - pip install openai requests --quiet
    - apt-get update && apt-get install -y curl --quiet
  script:
    - echo "ðŸ“¥ Processing handoff to IRENA..."
    - python scripts/relay.py --process
    - |
      if [ -f handoffs/handoff_to_claude.md ]; then
        echo "ðŸ“¤ Pushing IRENA response..."
        ENCODED_CONTENT=$(base64 -w 0 handoffs/handoff_to_claude.md)
        curl --silent --request PUT \
          --header "PRIVATE-TOKEN: ${GITLAB_TOKEN}" \
          --header "Content-Type: application/json" \
          --data "{\"branch\": \"main\", \"encoding\": \"base64\", \"content\": \"${ENCODED_CONTENT}\", \"commit_message\": \"feat(relay): IRENA auto-response [skip ci]\"}" \
          "https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/repository/files/handoffs%2Fhandoff_to_claude.md"
        echo "âœ… Response pushed!"
      else
        echo "âŒ No response generated"
        exit 1
      fi
  variables:
    OPENAI_API_KEY: ${OPENAI_API_KEY}
    GITLAB_TOKEN: ${GITLAB_TOKEN}

# ============================================
# Google Drive Sync
# ============================================

sync_infrastructure:
  stage: deploy
  image: python:3.11-slim
  rules:
    - changes:
        - docs/infrastructure.md
      when: always
    - when: never
  before_script:
    - pip install google-auth google-api-python-client --quiet
    - echo "${GOOGLE_SERVICE_ACCOUNT_KEY}" > /tmp/service_account.json
  script:
    - |
      python3 << 'PYTHON'
      from google.oauth2 import service_account
      from googleapiclient.discovery import build
      from googleapiclient.http import MediaFileUpload
      
      SCOPES = ['https://www.googleapis.com/auth/drive.file']
      FOLDER_ID = '1qh0skTeyRNs4g9KwAhpd3J8Yj_XENIFs'
      
      creds = service_account.Credentials.from_service_account_file(
          '/tmp/service_account.json', scopes=SCOPES)
      service = build('drive', 'v3', credentials=creds)
      
      results = service.files().list(
          q=f"name='infrastructure.md' and '{FOLDER_ID}' in parents and trashed=false",
          fields="files(id)"
      ).execute()
      files = results.get('files', [])
      
      media = MediaFileUpload('docs/infrastructure.md', mimetype='text/markdown')
      
      if files:
          service.files().update(fileId=files[0]['id'], media_body=media).execute()
          print("âœ… Updated infrastructure.md in Google Drive")
      else:
          service.files().create(
              body={'name': 'infrastructure.md', 'parents': [FOLDER_ID]},
              media_body=media
          ).execute()
          print("âœ… Created infrastructure.md in Google Drive")
      PYTHON


# =============================================================================
# DOCUMENT MERGE: LLM-Powered Multi-Author Collaboration (ADR-014)
# =============================================================================
# Enables Doug (DOCX) + Mike/Wolfram (Markdown) to collaborate on SPE abstract
# Pipeline triggers on changes to conference/spe-europe-2026/sources/
# =============================================================================

# Doc Merge Pipeline - Shell Runner Compatible
# Works on Mac runners without Docker

# Doc Merge Pipeline - Docker Runner Compatible
# Uses proper Docker images for each job

doc_merge:normalize:
  stage: build
  image: debian:bookworm-slim
  tags:
    - docker
  before_script:
    - apt-get update -qq && apt-get install -y -qq pandoc > /dev/null 2>&1
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - conference/spe-europe-2026/sources/**/*
      when: on_success
    - if: '$CI_PIPELINE_SOURCE == "web" && $DOC_MERGE == "true"'
      when: on_success
    - when: never
  script:
    - |
      mkdir -p normalized
      DOC_PATH="conference/spe-europe-2026/sources"
      
      echo "=== Normalizing DOCX files ==="
      for docx in ${DOC_PATH}/doug/*.docx; do
        [ -f "$docx" ] || continue
        name=$(basename "$docx" .docx)
        echo "Converting: $docx"
        pandoc "$docx" -t markdown -o "normalized/doug-${name}.md" --wrap=none
      done
      
      echo "=== Copying MD files ==="
      for md in ${DOC_PATH}/*/*.md; do
        [ -f "$md" ] || continue
        author=$(basename $(dirname "$md"))
        name=$(basename "$md" .md)
        echo "Copying: $md"
        cp "$md" "normalized/${author}-${name}.md"
      done
      
      echo "=== Normalized files ==="
      ls -la normalized/
  artifacts:
    paths:
      - normalized/
    expire_in: 1 day

doc_merge:compare:
  stage: test
  image: python:3.11-slim
  tags:
    - docker
  needs:
    - job: doc_merge:normalize
      artifacts: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - conference/spe-europe-2026/sources/**/*
      when: on_success
    - if: '$CI_PIPELINE_SOURCE == "web" && $DOC_MERGE == "true"'
      when: on_success
    - when: never
  script:
    - pip install --quiet anthropic openai
    - python3 conference/spe-europe-2026/scripts/doc_compare.py normalized/ comparison-report.json
    - echo "=== Comparison Report ==="
    - cat comparison-report.json
  artifacts:
    paths:
      - comparison-report.json
    expire_in: 1 week

doc_merge:merge:
  stage: automation
  image: python:3.11-slim
  tags:
    - docker
  needs:
    - job: doc_merge:normalize
      artifacts: true
    - job: doc_merge:compare
      artifacts: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - conference/spe-europe-2026/sources/**/*
      when: manual
    - if: '$CI_PIPELINE_SOURCE == "web" && $DOC_MERGE == "true"'
      when: manual
    - when: never
  script:
    - pip install --quiet anthropic openai
    - python3 conference/spe-europe-2026/scripts/doc_do_merge.py normalized/ merged-output.md merge-log.json
    - echo "=== Merge Log ==="
    - cat merge-log.json
  artifacts:
    paths:
      - merged-output.md
      - merge-log.json
    expire_in: 1 week

doc_merge:generate:
  stage: deploy
  image: node:20-bookworm
  tags:
    - docker
  needs:
    - job: doc_merge:merge
      artifacts: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - conference/spe-europe-2026/sources/**/*
      when: on_success
    - if: '$CI_PIPELINE_SOURCE == "web" && $DOC_MERGE == "true"'
      when: on_success
    - when: never
  before_script:
    - apt-get update -qq && apt-get install -y -qq pandoc texlive-xetex texlive-fonts-recommended texlive-latex-extra python3 chromium librsvg2-bin > /dev/null 2>&1
    - npm install -g @mermaid-js/mermaid-cli > /dev/null 2>&1
    - export PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium
  script:
    - |
      mkdir -p doc-outputs diagrams
      
      if [ ! -f merged-output.md ]; then
        echo "No merged document found"
        exit 1
      fi
      
      echo "=== Rendering Mermaid diagrams to SVG ==="
      python3 conference/spe-europe-2026/scripts/render_mermaid_images.py \
        merged-output.md \
        doc-outputs/for-pdf.md \
        diagrams
      
      echo "=== Generating PDF with rendered diagrams ==="
      cp -r diagrams doc-outputs/
      cd doc-outputs
      pandoc for-pdf.md -o abstract-merged.pdf \
        --pdf-engine=xelatex \
        -V geometry:margin=2.5cm \
        -V fontsize=11pt \
        -V mainfont="DejaVu Serif" \
        -V sansfont="DejaVu Sans" \
        -V monofont="DejaVu Sans Mono" || \
      pandoc for-pdf.md -o abstract-merged.pdf \
        --pdf-engine=pdflatex \
        -V geometry:margin=2.5cm \
        -V fontsize=11pt
      cd ..
      
      echo "=== Generating HTML with Mermaid.js ==="
      python3 conference/spe-europe-2026/scripts/preprocess_mermaid.py \
        merged-output.md \
        doc-outputs/for-html.md
      pandoc doc-outputs/for-html.md -o doc-outputs/abstract-merged.html \
        --standalone \
        --template=conference/spe-europe-2026/templates/mermaid-template.html \
        --metadata title="CLARISSA - SPE Europe 2026"
      
      echo "=== Generating DOCX ==="
      pandoc merged-output.md -o doc-outputs/abstract-merged.docx
      
      echo "=== Copying canonical MD ==="
      cp merged-output.md doc-outputs/abstract-canonical.md
      
      echo "=== Generated files ==="
      ls -la doc-outputs/
      ls -la diagrams/
  artifacts:
    paths:
      - doc-outputs/
      - diagrams/
    expire_in: 4 weeks
